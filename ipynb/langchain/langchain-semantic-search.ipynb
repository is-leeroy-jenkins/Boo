{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pinecone\n",
    "import sentence_transformers\n",
    "import pinecone_notebooks\n",
    "import pinecone_datasets"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7Lc9I6taO3k"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/docs/semantic-search.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/docs/semantic-search.ipynb)\n",
    "\n",
    "# Semantic Search\n",
    "\n",
    "In this walkthrough we will see how to use Pinecone for semantic search. To begin we must install the required prerequisite libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q03L1BYEZQfe"
   },
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xmobBcgqKEL"
   },
   "source": [
    "---\n",
    "\n",
    "ðŸš¨ _Note: the above `pip install` is formatted for Jupyter notebooks. If running elsewhere you may need to drop the `!`._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrSfFiIC5roI"
   },
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kujS_e8s55oJ"
   },
   "source": [
    "In this notebook we will skip the data preparation steps as they can be very time consuming and jump straight into it with the prebuilt dataset from *Pinecone Datasets*.\n",
    "\n",
    "The dataset we are working with represents embeddings of [400K question pairs from Quora](https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs). The embeddings were created using the `all-MiniLM-L6-v2` model from Hugging Face via the `sentence-transformers` package.\n",
    "\n",
    "If you'd rather see how it's all done, please refer to [this notebook](https://github.com/pinecone-io/examples/blob/master/learn/search/semantic-search/semantic-search.ipynb).\n",
    "\n",
    "Let's go ahead and download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "lOgjRG52Zqqz",
    "outputId": "26a44f5f-5a6a-429f-8cec-72b86d99f380"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading documents parquet files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:15<00:00, 13.52s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>values</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240000</th>\n",
       "      <td>515997</td>\n",
       "      <td>[-0.00531694, 0.06937869, -0.0092854, 0.003286...</td>\n",
       "      <td>{'text': ' Why is a \"law of sciences\" importan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240001</th>\n",
       "      <td>515998</td>\n",
       "      <td>[-0.09243751, 0.065432355, -0.06946959, 0.0669...</td>\n",
       "      <td>{'text': ' Is it possible to format a BitLocke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240002</th>\n",
       "      <td>515999</td>\n",
       "      <td>[-0.021924071, 0.032280188, -0.020190848, 0.07...</td>\n",
       "      <td>{'text': ' Can formatting a hard drive stress ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240003</th>\n",
       "      <td>516000</td>\n",
       "      <td>[-0.120020054, 0.024080949, 0.10693012, -0.018...</td>\n",
       "      <td>{'text': ' Are the new Samsung Galaxy J7 and J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240004</th>\n",
       "      <td>516001</td>\n",
       "      <td>[-0.095293395, -0.048446465, -0.017618902, -0....</td>\n",
       "      <td>{'text': ' I just watched an add for Indonesia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                             values  \\\n",
       "240000  515997  [-0.00531694, 0.06937869, -0.0092854, 0.003286...   \n",
       "240001  515998  [-0.09243751, 0.065432355, -0.06946959, 0.0669...   \n",
       "240002  515999  [-0.021924071, 0.032280188, -0.020190848, 0.07...   \n",
       "240003  516000  [-0.120020054, 0.024080949, 0.10693012, -0.018...   \n",
       "240004  516001  [-0.095293395, -0.048446465, -0.017618902, -0....   \n",
       "\n",
       "                                                 metadata  \n",
       "240000  {'text': ' Why is a \"law of sciences\" importan...  \n",
       "240001  {'text': ' Is it possible to format a BitLocke...  \n",
       "240002  {'text': ' Can formatting a hard drive stress ...  \n",
       "240003  {'text': ' Are the new Samsung Galaxy J7 and J...  \n",
       "240004  {'text': ' I just watched an add for Indonesia...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone_datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('quora_all-MiniLM-L6-bm25')\n",
    "\n",
    "# The metadata we need is actually stored in the \"blob\" column so let's rename it\n",
    "dataset.documents.drop(['metadata'], axis=1, inplace=True)\n",
    "dataset.documents.rename(columns={'blob': 'metadata'}, inplace=True)\n",
    "\n",
    "# We don't need sparse_values for this demo either so let's drop those as well\n",
    "dataset.documents.drop(['sparse_values'], axis=1, inplace=True)\n",
    "\n",
    "# To speed things up in this demo, we will use 80K rows of the dataset between rows 240K -> 320K\n",
    "dataset.documents.drop(dataset.documents.index[320_000:], inplace=True)\n",
    "dataset.documents.drop(dataset.documents.index[:240_000], inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "conuh2Uo-mwR",
    "outputId": "13347486-2a77-47b6-f1c2-6b9287fdc867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in dataset: 80000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rows in dataset: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlEn3viQJHK5"
   },
   "source": [
    "Let's take a closer look at one of these rows to see what we're dealing with. In the metadata we have stored the original question text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQCc8nwzJHK6",
    "outputId": "553f8756-44b8-4426-e96a-61a884d9fb23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These embeddings have dimension 384\n"
     ]
    }
   ],
   "source": [
    "row1 = dataset.documents.iloc[0:1].to_dict(orient=\"row_count\")[0]\n",
    "dimension = len(row1['target_values'])\n",
    "print(f\"These embeddings have dimension {dimension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-8iEHJxJHK8",
    "outputId": "3e09b3fc-bc97-49a5-cb87-7956a58b38e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some example questions in the data set:\n",
      "\n",
      "  - Why is a \"law of sciences\" important for our life?\n",
      "  - Is it possible to format a BitLocker or FileVault protected drive?\n",
      "  - Can formatting a hard drive stress it out?\n",
      "  - Are the new Samsung Galaxy J7 and J5 worth their price?\n",
      "  - I just watched an add for Indonesia 2026 World Cup bid in YouTube, is it viable?\n",
      "  - I am an 18 year old college student. Is it a viable idea to play poker in order to pay for my college tuition?\n",
      "  - If the French monarchy had never been abolished, who would be the current king/queen?\n",
      "  - Who was the best French King?\n",
      "  - How do I obtain a free United States phone number using the Internet?\n",
      "  - What is the change in your opinion about PM Narendra Modi after demonetization of 1000 and 500 rupees currency notes?\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are some example questions in the data set:\\n\")\n",
    "for r in dataset.documents.iloc[0:10].to_dict(orient=\"row_count\"):\n",
    "    print(\"  -\" + r['metadata']['path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebd7XSamfMsC"
   },
   "source": [
    "## Creating an Index\n",
    "\n",
    "Now the data is ready, we can set up our index to store it.\n",
    "\n",
    "We begin by instantiating the Pinecone client. To do this we need a [free API key](https://app.pinecone.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Z1qIndgJHK-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.environ.get(\"PINECONE_API_KEY\"):\n",
    "    from pinecone_notebooks.colab import Authenticate\n",
    "    Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mc66NEBAcQHY"
   },
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "# Initialize client\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdaTip6CfllN"
   },
   "source": [
    "Now we create a new index called `semantic-search-fast`. It's important that we align the index `dimension` and `metric` parameters with those required by the `MiniLM-L6` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9O1TT9gGJHLA"
   },
   "source": [
    "### Creating a Pinecone Index\n",
    "\n",
    "When creating the index we need to define several configuration properties.\n",
    "\n",
    "- `name` can be anything we like. The name is used as an identifier for the index when performing other operations such as `describe_index`, `delete_index`, and so on.\n",
    "- `metric` specifies the similarity metric that will be used later when you make queries to the index.\n",
    "- `dimension` should correspond to the dimension of the dense vectors produced by your embedding model. In this quick start, we are using made-up data so a small value is simplest.\n",
    "- `spec` holds a specification which tells Pinecone how you would like to deploy our index. You can find a list of all [available providers and regions here](https://docs.pinecone.io/docs/projects).\n",
    "\n",
    "There are more configurations available, but this minimal set will get us started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kT8pfoO46Iwg",
    "outputId": "0fec19be-c74d-4602-bec6-24d61cfc5bb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'dotproduct',\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "index_name = 'semantic-search-fast'\n",
    "\n",
    "# Check if index already exists (it shouldn't if this is first time running the demo)\n",
    "if not pc.has_index(name=index_name):\n",
    "    # If does not exist, create_small_embedding index\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384, # dimensionality of MiniLM\n",
    "        metric='dotproduct',\n",
    "        spec = ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Initialize index client\n",
    "index = pc.Index(name=index_name)\n",
    "\n",
    "# View index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ha_Uozs_JHLB"
   },
   "source": [
    "## Upserting data into the Pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "6c9efda7c7394404814e7466d4a9108c",
      "ee94a2a6c50b4abd89fdea7dc2c51b0b",
      "1af0d3d6e7a0465a91fd27a916a0508a",
      "86cf0f742de14c4f95fa5ddb74e07985",
      "ab1007c06e414b2da35507a90e91e8cb",
      "640ee2f088814e6c80014be268749820",
      "e1d5e0366eee4a96bf4a52ee84698c6a",
      "726dc10996c5403d8b0d661a3a6cdb63",
      "1e213f554e8f4c18a96bc71b56d8582a",
      "c62d67ae4d0e498fbf330db34ca8f9e3",
      "15e5e36e202c40fba34e92adfe8aa8de"
     ]
    },
    "id": "RhR6WOi1huXZ",
    "outputId": "9ae50bfe-3ebf-4d8b-e28e-3230aed0e1d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting records batch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [05:45<00:00,  2.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for start in tqdm(range(0, len(dataset.documents), batch_size), \"Upserting row_count batch\"):\n",
    "    batch = dataset.documents.iloc[start:start + batch_size].to_dict(orient=\"row_count\")\n",
    "    index.upsert(vectors=batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrK_IN079Vuu"
   },
   "source": [
    "## Making Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rr4unPAq9alb"
   },
   "source": [
    "Now that our index is populated we can begin making queries. We are performing a semantic search for *similar questions*, so we should embed and search with another question. Let's begin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 679,
     "referenced_widgets": [
      "5c7bfc7456044e13ad2dddde1de476a4",
      "470962290b704753aca8f82962427114",
      "3e2c8272a23f450ea9503f88f9768522",
      "67721b1eb6b24e23acb93857e1125d3b",
      "56afdc49e9814c2ebe714de6f699f979",
      "edcf42a10df04eb68ca9d47964563d12",
      "bf6a6ec4547d487c945e630470d29023",
      "3747ba54c92a4e0cb765c4184e5d283c",
      "cbfe92685133447db429843c9226e508",
      "8ab11a9389374718a7c0560010b74b77",
      "dab0bd9c930b45c49cd39e0efb69633b",
      "531d04b4e98d44ef9140f805711caf3e",
      "c40c233c0cf34beb9a167990add58ca6",
      "291895bcc50d4321bfaf7e9a57bca93d",
      "c7e1df314e1041d99cf18c758fa4a544",
      "63935fd8e36c4f72b0d809342aefb8d8",
      "ff764601d417454e9da700108f7feef6",
      "de219d4642174108b6e3b1f4d4014588",
      "a406fcbe5676447987585e00e75f05ac",
      "8b2951a9fa084050b4a1e6a33456bd3f",
      "a3e060a472a94ca18c2684f11392a97d",
      "67a36f0845904e92b402738cefdaa548",
      "c3858c293f1d426a9ecfd998b72b0c40",
      "96fd7159ce144c38906f8824a63e6f4d",
      "6dc94ee437e840c1becb1030e05e4d4e",
      "3ceac8444e2b4321a66759c6d757cbbd",
      "4a3f86a0adf54b6499e1668f554df24c",
      "2dc8a390073b4cc386f429346f16e5db",
      "65c7e349761145359548ff503444b5f7",
      "0d6d7e55ecc3439fa28e32d16e510f50",
      "e0325e59448e4370b280059ec5ff45f9",
      "cb61b7a2b41e47be9101b7c10d20da4a",
      "1f54d4ddc2844bce9d5ff58f58dd004f",
      "b3dbeda50aaa40c8a23e2d87ea9f3d52",
      "f82559c15ce8416f8894d7b1d7e15137",
      "0b870a86e8ce49c0887117aa414cf8b0",
      "2054d000cc2a426db779588996254986",
      "7d7b625490fb444194a1ae030d6a9a50",
      "9c400d7250b84be9b3d0f0a758f88f6e",
      "20962fcf3f8549e197fd9aded998cbca",
      "69a23fe4de4f4043bdf7dabf79f6f811",
      "e6b1cf47ac74441a932393af86362b50",
      "687eb2f0e61e49ac9cd60b90b4d7554c",
      "792f6776da314cbea7bc7ea89fe46731",
      "b9fcc9fe7ba64086888084d3d28cf2df",
      "ba38f2272d9c476baea73ecbe18f021a",
      "0533b610e6a04669af4eb7a5ce2d08de",
      "69ba30b79a5648cba99d6a32dd4dfb61",
      "126e301be6c643c2b2fb8a7505ff77d2",
      "c58471a598ce459d94f120fc98308cda",
      "8ea0d5f890ab46ffa07a2ebd61c45c15",
      "8ebc9aaeb37747d98d7d7db80dd9b142",
      "d84abf7b20f6476ca707f59fafec4c5c",
      "db17ce56f8954fc986c26e860046a511",
      "3494430020114bc9a729f6c4b671cf77",
      "2b6091f988c6462088f7ae3160748d5d",
      "665e820272024d4fb7bec0feefa83e81",
      "c2cb1e81a2d248e7b228f7b536171e38",
      "b176ee9ac1174bc7a1dc23f128877bed",
      "a69a84f259c64210a59f5f4814902947",
      "90557cca74564522adb18e54695a55b1",
      "7adf6168b5614cd89201f8cafebe5ef3",
      "419d5fb5311447d0aea4628931da1989",
      "91a9d98dd1bd4e34983ada913425adf0",
      "4b5f4c7b9d524807ad7224f4fcec1d98",
      "1e81bf8feadf47ef8e41f2b99e51598a",
      "32f366def7624f6c8ac3316455f88236",
      "da12ece4d50849e891b8abeedaff794a",
      "61a1c39332ce40dc859f05ba93456fa0",
      "f97cc4a8f6ee4a06b249e4b16adb3168",
      "7a92de434c92424a8cb2a4a480b72ab2",
      "6398c224172640b29fb95fbd82117cc4",
      "f43a37f884574a059e29e48e828a469f",
      "b0e29055399c43e9ac6d7f00b72a12a5",
      "0466e351af354595bd04433d723ff6e1",
      "8d7a2b7c770c4042a10bbc4a94d5703b",
      "35a5d627fe80489b9a01d9adffa72554",
      "2e0e4035ff884950b1b69d9629d73cae",
      "d33bc78817e94ff4af86d92baa8e62e6",
      "a034164558b0428d84b678c95167399f",
      "b86ca4661d0b42f692007027f32be1fe",
      "3e606add11104153ad533371f389835f",
      "d6e9e4ab4a734b90bb540a4cdba04f1f",
      "1aeb7f7a72814e759d8d2d2a63c12659",
      "b167c2c0021f4ec49d983335de6fdb6f",
      "51768e650c334fe9810bf7af6dda23aa",
      "99e048df115342af808f930e7f5935a0",
      "52c52091dabf4de6929a2dae2e00387f",
      "d187e47c6aba4d31b3f6a6edfbb63cf9",
      "b25796c7825f43bab30dc2595383e640",
      "a479290cec6b4361a710d3a6ef52c261",
      "cfcde24e9d8c42f8a85d5e57ba435ce9",
      "bc64c4c17a7c40a6b14cf909af1e8489",
      "c19b21eef6b74087903d69efb6d22593",
      "875e50f9324b4c8186695e75bbf17f1c",
      "8718e60bf312462085d4fbd2eb84cf19",
      "53a4a1e45f7048c5b2dad1eaecd47a81",
      "5a51e9f61a3b4342899ffa2da63da259",
      "468ffd8250fa41248f62ef108575e608",
      "94b00ca7d394438e8b669c14ee37828f",
      "8ed5026db6f14d438597e98d6bfb86fb",
      "d168774364e340e38270e49cdcef110c",
      "a2afa61190af45728590a54890acaf32",
      "f73218dc64bf4fcba7af9455423571b5",
      "0f79e45b4b4b4e80ab70585f79dcac0f",
      "4b21a4f81e7f4f009b7c331d2398cfd1",
      "eef43c63316e4f319059e487dddbfbe2",
      "9bdf6c56441b4b859c67a29a52f02621",
      "b7df85a218f841b5a136d34a4fbf79cb",
      "aa5eba5800ad476db1c28a12973b0d21",
      "f5884dd736004044b67bd633ba6cbfcc",
      "13a6656c00334b4db8339286ccf36008",
      "13774ba270194ec694624c3e251e0538",
      "42d2cfb925814edda51d2484e16f569c",
      "8cee449952274852bc2f7719761664cc",
      "48eaa65f1c4f44a6a553225d90fdd57c",
      "be4c0e463f694f5dbfa43474f355865c",
      "25b4702d10ed450186ffef738d416ac7",
      "58146f58dd5a43b5b96e4b351b66b93f",
      "121e98adb6d74a3a99aa4d6edc33df11",
      "9ff705f552ac49c0808f1ec4eb5f028b",
      "c384ffc6144041028850e861a7b65fb2",
      "97c5784721a243f4a2aa19be26622129",
      "f841905de8ff4f1c93e8f3f540b02fb7",
      "a776bf36d5a6412fb01dbfaf117de9a5",
      "8bf049ca6373418b9abf0b13d01a2cc6",
      "482f97c9fb524a5f805f389988b2979d",
      "cdbdd65c185049d8bf777a30bc5a3e21",
      "5f686a4f380a480d81e2d45dfe62b4b1",
      "1d7dd1b1a96445cb818d8e0252593c14",
      "7cab95cf72c44164a3129a5c43e6f0e0",
      "62055d56f8be4391b6996a48162b8abe",
      "ba07ea6232424d26898fe03ceed64efb",
      "a8272ce3114a4a829243abcdd37c9050",
      "fca8dfe3808e437f8baa881c4e449597",
      "86a819b05d1e4924b98e2962cd8801f1",
      "963ef8c9a7ee49bf813fb2527366fb3e",
      "f9852df438414e58b1c289b7a43aec58",
      "a825f2ccdf3141f1907546ad3a0fd45e",
      "eabbe467d55c4f31a7e0acf872bfff78",
      "b2d1aae111264a3a96bd21251d62cd2d",
      "686aec60ca454da099f981f459154b18",
      "9a543168eafa428f8ea707d6866f73ec",
      "fcc0ded8483c4af5ac074ff4a4e57f62",
      "cfbf4ac4cc5e432e999f675c5041722e",
      "e6a57ba24239454a8cf07e6869f8232d",
      "8ee1147298c148db8b94f83719c0dcd9",
      "41b24e0881fa460d86f16245a4f906cd",
      "9465699406694de2a28e3907b4e22ddb",
      "d0d2453b3a274c5395136f3ef9c3b483",
      "4d6f734fe74140659624715611935f06",
      "8211e0cd7117440f8570f65633ea77db",
      "5264427cf7d64adc8c2690835771185f",
      "47298aba73ad458da7c804460c24fd6c"
     ]
    },
    "id": "Fqo_hMRZiubM",
    "outputId": "de4b4489-6f66-4ea0-b373-df1b88260c7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MP2-unZ--XJ9"
   },
   "source": [
    "Now let's use this model to embed our question and find similar questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWcO7jAK-N_1"
   },
   "outputs": [],
   "source": [
    "def find_similar_questions(question):\n",
    "    # Embed the question into a query vector\n",
    "    xq = model.encode(question).tolist()\n",
    "\n",
    "    # Now query Pinecone to find similar questions\n",
    "    return index.query(vector=xq, top_k=5, include_metadata=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQ_RFOkLJHLG",
    "outputId": "a48e7841-7296-4fc3-943c-12c711c1282a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/third_party/ideep/mkl-dnn/src/cpu/aarch64/xbyak_aarch64/src/util_impl_linux.h, 451: Can't read MIDR_EL1 sysfs entry\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '69331',\n",
       "              'metadata': {'text': \" What's the world's largest city?\"},\n",
       "              'score': 0.785789311,\n",
       "              'values': []},\n",
       "             {'id': '69332',\n",
       "              'metadata': {'text': ' What is the biggest city?'},\n",
       "              'score': 0.727474,\n",
       "              'values': []},\n",
       "             {'id': '84749',\n",
       "              'metadata': {'text': \" What are the world's most advanced \"\n",
       "                                   'cities?'},\n",
       "              'score': 0.709189653,\n",
       "              'values': []},\n",
       "             {'id': '109231',\n",
       "              'metadata': {'text': ' Where is the most beautiful city in the '\n",
       "                                   'world?'},\n",
       "              'score': 0.695605934,\n",
       "              'values': []},\n",
       "             {'id': '109230',\n",
       "              'metadata': {'text': ' What is the greatest, most beautiful city '\n",
       "                                   'in the world?'},\n",
       "              'score': 0.657157958,\n",
       "              'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 6}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Which city has the highest population in the world?\"\n",
    "xc = find_similar_questions(question)\n",
    "xc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XwOWcgo_QtI"
   },
   "source": [
    "In the returned response `xc` we can see the most relevant questions to our particular query â€” we don't have any exact matches but we can see that the returned questions are similar in the topics they are asking about. We can reformat this response to be a little easier to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gy7isg_f-vWg",
    "outputId": "dbcc8119-28d2-41de-dd19-a1b181fe6800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79:  What's the world's largest city?\n",
      "0.73:  What is the biggest city?\n",
      "0.71:  What are the world's most advanced cities?\n",
      "0.7:  Where is the most beautiful city in the world?\n",
      "0.66:  What is the greatest, most beautiful city in the world?\n"
     ]
    }
   ],
   "source": [
    "def print_query_results(results):\n",
    "    for result in results['matches']:\n",
    "        print(f\"{round(result['score'], 2)}: {result['metadata']['path']}\")\n",
    "\n",
    "print_query_results(xc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JK5yApl_5fE"
   },
   "source": [
    "These are good results, let's try and modify the words being used to see if we still surface similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dJbjE-iq_yMr",
    "outputId": "ec6b9122-ff76-4696-8dfe-12a81cb81ead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64:  What is the biggest city?\n",
      "0.6:  What is the most dangerous city in USA?\n",
      "0.59:  What's the world's largest city?\n",
      "0.59:  What is the most dangerous city in USA? Why?\n",
      "0.58:  What are the world's most advanced cities?\n"
     ]
    }
   ],
   "source": [
    "question2 = \"Which metropolis has the highest num of people?\"\n",
    "\n",
    "xc2 = find_similar_questions(question2)\n",
    "print_query_results(xc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIAxOPb-A2w_"
   },
   "source": [
    "Here we used different terms in our query than that of the returned documents. We substituted **\"city\"** for **\"metropolis\"** and **\"populated\"** for **\"number of people\"**.\n",
    "\n",
    "Despite these very different terms and *lack* of term overlap between query and returned documents â€” we get highly relevant results â€” this is the power of *semantic search*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Er4J02mZJHLK"
   },
   "source": [
    "## Demo Cleanup\n",
    "\n",
    "You can go ahead and ask more questions above. When you're done, delete the index to save resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-cWdeKzhAtww"
   },
   "outputs": [],
   "source": [
    "pc.delete_index(name=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2B0zxR6hbf5d"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
