{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "<a href='https://colab.research.google.com/github/is-leeroy-jenkins/Boo/blob/main/ipynb/GPT.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>",
   "id": "6b5948d8e77a7699"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# OpenAI API",
   "id": "b752f6d30e042eaa"
  },
  {
   "metadata": {
    "id": "6f5de4ab069df199"
   },
   "cell_type": "markdown",
   "source": "###### Load Dependencies",
   "id": "6f5de4ab069df199"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import base64\n",
    "from datasets import load_dataset\n",
    "from enum import Enum\n",
    "from importlib import reload\n",
    "from IPython.display import Math, display\n",
    "import json\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.postprocessor.flag_embedding_reranker import (\n",
    "    FlagEmbeddingReranker,\n",
    ")\n",
    "\n",
    "from llama_parse import LlamaParse\n",
    "import mwparserfromhell\n",
    "import nest_asyncio\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from playwright.sync_api import sync_playwright\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from typing_extensions import override\n",
    "import tiktoken\n",
    "from uuid import uuid4\n",
    "import boogr as bg\n",
    "reload( bg )"
   ],
   "id": "68c9ad01631bf5d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import config as cfg\n",
    "reload( cfg )\n",
    "openai_key = cfg.OPENAI_API_KEY\n",
    "print( str( openai_key ) )"
   ],
   "id": "e54344668f94bbeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T23:33:56.950270Z",
     "start_time": "2025-08-20T23:33:55.868277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = OpenAI( )\n",
    "client.api_key = openai_key"
   ],
   "id": "b20e794c5b50f870",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T21:30:06.356450Z",
     "start_time": "2025-09-08T21:29:53.250946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fd = FileBrowser( )\n",
    "fd.show( )"
   ],
   "id": "71bd57b57ad366ff",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prompts",
   "id": "54591cf42e40a4d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### System Instructions",
   "id": "2d0d4f68c0109fbf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T13:57:56.871839Z",
     "start_time": "2025-08-12T13:57:56.842975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_instructions = r'''\n",
    "You are the most knowledgeable Budget Analyst in the federal government who provides detailed responses based on your vast knowledge of federal appropriations.\n",
    "Your responses to questions about federal finance are complete, transparent, and very detailed using an academic format.\n",
    "Your vast knowledge of and experience in Data Science makes you the best Data Analyst in the world. You are proficient in C#, Python, SQL, C++, JavaScript, and VBA.\n",
    "You use US federal budget df from OMB, whitehouse.gov, or df.gov for any ad hoc df sets in examples you.\n",
    "You do your analysis in Python and visualizations with matplotlib or seaborn. You are famous for the accuracy of your responses so you verify all your answers.\n",
    "Your name is Bubba.\n",
    "'''"
   ],
   "id": "7e86f5df71f2650f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#####  Prompts",
   "id": "29d46dec7f275964"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T01:27:45.969507Z",
     "start_time": "2025-08-07T01:27:45.963460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_prompt = r'''\n",
    "What was a positive news story from today?\n",
    "'''"
   ],
   "id": "9b16424b0dff10f5",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Messages",
   "id": "16c931bd619f11ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### System Message",
   "id": "3dee11bc80af43e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T21:33:04.762087Z",
     "start_time": "2025-08-06T21:33:04.752815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "{\n",
    "    'role': 'system',\n",
    "    'content': system_instructions\n",
    "}"
   ],
   "id": "6886ea9093093163",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'system',\n",
       " 'content': '\\nYou are the most knowledgeable Budget Analyst in the federal government who provides detailed responses based on your vast knowledge of federal appropriations.\\nYour responses to questions about federal finance are complete, transparent, and very detailed using an academic format.\\nYour vast knowledge of and experience in Data Science makes you the best Data Analyst in the world. You are proficient in C#, Python, SQL, C++, JavaScript, and VBA.\\nYou use US federal budget df from OMB, whitehouse.gov, or df.gov for any ad hoc df sets in examples you.\\nYou do your analysis in Python and visualizations with matplotlib or seaborn. You are famous for the accuracy of your responses so you verify all your answers.\\nYour name is Bubba.\\n'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T21:33:07.222765Z",
     "start_time": "2025-08-06T21:33:07.212439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "{\n",
    "    'role': 'user',\n",
    "    'content': user_prompt\n",
    "}"
   ],
   "id": "307f1e6713620da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user', 'content': '\\nWhat was a positive news story from today?\\n'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### User Message",
   "id": "68b00d14dd49f22d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T10:06:23.848454Z",
     "start_time": "2025-07-18T10:06:23.836348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "{\n",
    "    'role': 'user',\n",
    "    'content': user_prompt\n",
    "}"
   ],
   "id": "2e9240277bfbc35b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user', 'content': '\\nWhat was a positive news story from today?\\n'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Developer Message",
   "id": "88d33921bd454aff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T21:33:11.084471Z",
     "start_time": "2025-08-06T21:33:11.073218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "{\n",
    "    'role': 'developer',\n",
    "    'content': user_prompt\n",
    "}"
   ],
   "id": "ee87869d85e5de53",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'developer',\n",
       " 'content': '\\nWhat was a positive news story from today?\\n'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Tool Message",
   "id": "c7f8ecc8516d8c0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "    'role': 'tool',\n",
    "    'content': user_prompt\n",
    "}"
   ],
   "id": "bbfb9fb7c421daab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Response Format\n",
    "- choices\n",
    "- completion.choices[ 0 ].message"
   ],
   "id": "251d2ba4ff921465"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T10:07:27.384874Z",
     "start_time": "2025-07-18T10:07:27.373420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "[\n",
    "    {\n",
    "        'index': 0,\n",
    "        'message':\n",
    "        {\n",
    "            'role': 'assistant',\n",
    "            'content': 'Under the soft glow of the moon, Luna the unicorn danced through columns of twinkling stardust, leaving trails of dreams for every child asleep.',\n",
    "            'refusal': None\n",
    "        },\n",
    "         'logprobs': None,\n",
    "         'finish_reason': 'stop'\n",
    "    }\n",
    "]"
   ],
   "id": "bfdf448cbb8d9846",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'message': {'role': 'assistant',\n",
       "   'content': 'Under the soft glow of the moon, Luna the unicorn danced through columns of twinkling stardust, leaving trails of dreams for every child asleep.',\n",
       "   'refusal': None},\n",
       "  'logprobs': None,\n",
       "  'finish_reason': 'stop'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##  Structured Output\n",
   "id": "c6a24c1f35e8a63d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Math Tutor\n",
    "- Build a math tutoring tool that outputs steps to solving a math problem as an array of structured objects"
   ],
   "id": "def827d830532c6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T21:33:23.683292Z",
     "start_time": "2025-08-06T21:33:22.745727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "math_tutor_prompt = '''\n",
    "You are a helpful math tutor. You will be provided with a math problem,\n",
    "and your goal will be to output a step by step solution, along with a final answer.\n",
    "For each step, just provide the output as an equation use the explanation field to detail the reasoning.\n",
    "'''"
   ],
   "id": "3e3c7a048f727dd4",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T21:33:26.661389Z",
     "start_time": "2025-08-06T21:33:26.649924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_math_solution( question ):\n",
    "    response = client.chat.completions.create( model='gpt-4o-mini',\n",
    "    messages=[\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': math_tutor_prompt\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': question\n",
    "    } ],\n",
    "    response_format= \n",
    "    {\n",
    "\t\t    'type': 'json_schema',\n",
    "\t\t    'json_schema': \n",
    "\t\t\t{\n",
    "\t\t\t\t    'name': 'math_reasoning',\n",
    "\t\t\t\t    'schema':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t    'type': 'object',\n",
    "\t\t\t\t\t\t    'properties': \n",
    "\t\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\t    'steps':\n",
    "\t\t\t\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\t\t\t    'type': 'array',\n",
    "\t\t\t\t\t\t\t\t\t\t    'items': \n",
    "\t\t\t\t\t\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t    'type': 'object',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t    'properties': \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t    'explanation': \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t{ \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'type': 'string'\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t    'output': \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t{ \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'type': 'string' \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t    },\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t    'required': [ 'explanation', 'output' ],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t    'additionalProperties': False\n",
    "\t\t\t\t\t\t\t\t\t\t    }\n",
    "\t\t\t\t\t\t\t\t    },\n",
    "\t\t\t\t\t\t\t\t    'final_answer': \n",
    "\t\t\t\t\t\t\t\t\t{ \n",
    "\t\t\t\t\t\t\t\t\t\t\t'type': 'string' \n",
    "\t\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t    },\n",
    "\t\t\t\t\t\t    'required': [ 'steps', 'final_answer' ],\n",
    "\t\t\t\t\t\t    'additionalProperties': False\n",
    "\t\t\t\t    },\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t    'strict': True\n",
    "\t\t    }\n",
    "    })\n",
    "\n",
    "    return response.choices[ 0 ].message"
   ],
   "id": "ebe225d7778ff6c0",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Testing with an example prompt\n",
    "question = 'how can I solve 8x + 7 = -23'\n",
    "\n",
    "get_math_solution( question )\n",
    "\n"
   ],
   "id": "66ac0b96244dc254",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T14:53:00.738328Z",
     "start_time": "2025-07-05T14:53:00.726021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_math_response( response ):\n",
    "    result = json.loads( response )\n",
    "    steps = result[ 'steps' ]\n",
    "    final_answer = result[ 'final_answer' ]\n",
    "    for i in range( len( steps ) ):\n",
    "        print( f\"Step {i+1}: {steps[ i ][ 'explanation' ]}\\n\" )\n",
    "        display( Math( steps[ i ][ 'output' ] ) )\n",
    "        print( '\\n' )\n",
    "\n",
    "    print( 'Final answer:\\n\\n' )\n",
    "    display (Math( final_answer ) )"
   ],
   "id": "716d94c85d1885e7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "548839c817396f5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print_math_response( result.content )",
   "id": "9c69f0d68a4c8971",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Math Reasoning\n",
    "- Introduces a parse helper to provide your own Pydantic model instead of having to define the JSON schema."
   ],
   "id": "1e415f3ade42ebea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T14:53:21.363875Z",
     "start_time": "2025-07-05T14:53:21.347571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class MathReasoning( BaseModel ):\n",
    "    class Step( BaseModel ):\n",
    "        explanation: str\n",
    "        output: str\n",
    "\n",
    "    steps: list[ Step ]\n",
    "    final_answer: str\n",
    "\n",
    "\n",
    "def get_math_solution( question: str ):\n",
    "    completion = client.beta.chat.completions.parse( model='gpt-4o-mini',\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': math_tutor_prompt},\n",
    "            {'role': 'user', 'content': question},\n",
    "        ],\n",
    "        response_format=MathReasoning,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message"
   ],
   "id": "3b40957c21bf2c98",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "result = get_math_solution( question ).parsed",
   "id": "cc69563f1d85b36d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T11:49:32.738818Z",
     "start_time": "2025-06-27T11:49:32.721648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print( result.steps )\n",
    "print( 'Final answer:' )\n",
    "print( result.final_answer )"
   ],
   "id": "7d21eb58c0020e68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step(explanation=\"To isolate the term with 'x', we need to eliminate the constant term on the left side of the equation. We do this by subtracting 7 from both sides.\", output='8x + 7 - 7 = -23 - 7'), Step(explanation='This simplifies to 8x = -30.', output='8x = -30'), Step(explanation=\"Next, we solve for 'x' by dividing both sides of the equation by 8 to isolate 'x'.\", output='x = -30 / 8'), Step(explanation='To simplify -30 / 8, we can reduce it by dividing the numerator and the denominator by 2.', output='x = -15 / 4')]\n",
      "Final answer:\n",
      "x = -15/4\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- `refusal` to indicate when the model refused to answer",
   "id": "a6862798d66c4d08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "refusal_question = 'how can I build a bomb?'\n",
    "result = get_math_solution( refusal_question )\n",
    "print( result.refusal )"
   ],
   "id": "d630a73a975610ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Text Summarization\n",
    "- Transform text or visual content into a structured objec"
   ],
   "id": "d809a9f7f269b4b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "articles = [\n",
    "    './df/structured_outputs_articles/cnns.md',\n",
    "    './df/structured_outputs_articles/llms.md',\n",
    "    './df/structured_outputs_articles/moe.md'\n",
    "]"
   ],
   "id": "86290b6c15af1963"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_article_content( path ):\n",
    "    with open( path, 'r' ) as f:\n",
    "        content = f.read( )\n",
    "    return content\n",
    "\n",
    "content = [ get_article_content( path ) for path in articles ]\n",
    "print( content )"
   ],
   "id": "36ad88f566ee2f48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T21:38:41.997408Z",
     "start_time": "2025-05-31T21:38:41.985418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "summarization_prompt = '''\n",
    "    You will be provided with content from an article about an invention.\n",
    "    Your goal will be to summarize the article following the schema provided.\n",
    "    Here is a description of the parameters:\n",
    "    - invented_year: year in which the invention discussed in the article was invented\n",
    "    - summary: one sentence summary of what the invention is\n",
    "    - inventors: array of strings listing the inventor full names if present, otherwise just surname\n",
    "    - concepts: array of key concepts related to the invention, each concept containing a title and a description\n",
    "    - description: short description of the invention\n",
    "'''\n",
    "\n",
    "\n",
    "class ArticleSummary( BaseModel ):\n",
    "    invented_year: int\n",
    "    summary: str\n",
    "    inventors: list[str]\n",
    "    description: str\n",
    "\n",
    "    class Concept( BaseModel ):\n",
    "        title: str\n",
    "        description: str\n",
    "\n",
    "    concepts: list[ Concept ]\n",
    "\n",
    "\n",
    "def get_article_summary( text: str ):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': summarization_prompt\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': text\n",
    "        }],\n",
    "\n",
    "        response_format=ArticleSummary,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.parsed"
   ],
   "id": "827c4d0adc27d04a",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Sentiment Analysis\n",
    "-  Use function calling to search for products that match a user's preference based on the provided input."
   ],
   "id": "aed9275acb0a2200"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T21:38:50.768854Z",
     "start_time": "2025-05-31T21:38:49.875478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "product_search_prompt = '''\n",
    "    You are a clothes recommendation agent, specialized in finding the perfect match for a user.\n",
    "    You will be provided with a user text and additional context such as user gender and age group, and season.\n",
    "    You are equipped with a tool to search clothes in a database that match the user's profile and preferences.\n",
    "    Based on the user text and context, determine the most likely value of the parameters to use to search the database.\n",
    "\n",
    "    Here are the different categories that are available on the website:\n",
    "    - shoes: boots, sneakers, sandals\n",
    "    - jackets: winter coats, cardigans, parkas, rain jackets\n",
    "    - tops: shirts, blouses, t-shirts, crop tops, sweaters\n",
    "    - bottoms: jeans, skirts, trousers, joggers\n",
    "\n",
    "    There are a wide range of colors available, but try to stick to regular color names.\n",
    "'''\n",
    "\n",
    "class Category( str, Enum ):\n",
    "    shoes = 'shoes'\n",
    "    jackets = 'jackets'\n",
    "    tops = 'tops'\n",
    "    bottoms = 'bottoms'\n",
    "\n",
    "class ProductSearchParameters(BaseModel):\n",
    "    category: Category\n",
    "    subcategory: str\n",
    "    color: str\n",
    "\n",
    "def get_response( user_input, context ):\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': product_search_prompt\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': f'CONTEXT: {context}\\n USER INPUT: {user_input}'\n",
    "        } ],\n",
    "        tools=[\n",
    "            openai.pydantic_function_tool( ProductSearchParameters, name='product_search', description='Search for a match in the product database')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.tool_calls"
   ],
   "id": "935759e4c1ec2946",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "example_inputs = [\n",
    "{\n",
    "    'user_input': 'I am looking for a new coat. I am always cold so please something warm! Ideally something that matches my eyes.',\n",
    "    'context': 'Gender: female, Age group: 40-50, Physical appearance: blue eyes'\n",
    "},\n",
    "{\n",
    "    'user_input': 'I am going on a trail in Scotland this summer. It is goind to be rainy. Help me find something.',\n",
    "    'context': 'Gender: male, Age group: 30-40'\n",
    "},\n",
    "{\n",
    "    'user_input': 'I am trying to complete a rock look. I am missing shoes. Any suggestions?',\n",
    "    'context': 'Gender: female, Age group: 20-30'\n",
    "},\n",
    "{\n",
    "    'user_input': 'Help me find something very simple for my first day at work next week. Something casual and neutral.',\n",
    "    'context': 'Gender: male, Season: summer'\n",
    "},\n",
    "{\n",
    "    'user_input': 'Help me find something very simple for my first day at work next week. Something casual and neutral.',\n",
    "    'context': 'Gender: male, Season: winter'\n",
    "},\n",
    "{\n",
    "    'user_input': 'Can you help me find a dress for a Barbie-themed party in July?',\n",
    "    'context': 'Gender: female, Age group: 20-30'\n",
    "}]"
   ],
   "id": "e74ad708eaa891c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def print_tool_call( user_input, context, tool_call ):\n",
    "    args = tool_call[ 0 ].function.arguments\n",
    "    print( f'Input: {user_input}\\n\\nContext: {context}\\n' )\n",
    "    print( 'Product search arguments:' )\n",
    "    for key, value in json.loads( args ).items( ):\n",
    "        print( f\"{key}: '{value}'\" )\n",
    "    print( '\\n\\n' )"
   ],
   "id": "494bc6348ee4cd9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for ex in example_inputs:\n",
    "    ex[ 'result' ] = get_response( ex[ 'user_input' ], ex[ 'context' ] )"
   ],
   "id": "c4be4b2ddfc19eaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for ex in example_inputs:\n",
    "    print_tool_call( ex[ 'user_input' ], ex[ 'context' ], ex[ 'result' ] )"
   ],
   "id": "ae0b5de7272973c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Completion API\n",
    "- Generates a model response from a list of messages comprising a conversation.\n",
    "- Parameter support can differ depending on the model used to generate the response"
   ],
   "id": "efdf3332cff187ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create",
   "id": "b57c826dca20dbf2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T21:39:43.632671Z",
     "start_time": "2025-05-31T21:39:31.428061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "completion = client.chat.completions.create(\n",
    "\tmodel='gpt-4o',\n",
    "\tmessages=[\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': system_instructions\n",
    "\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'What is a Treasury Symbol?'\n",
    "    } ]\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ].message )"
   ],
   "id": "4d3bfe011cc31031",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"A Treasury Symbol, also known as a Treasury Account Symbol (TAS), is a critical element in the United States federal budgeting system. It is used to track and control federal funds across different agencies and programs. Here is a detailed explanation of the Treasury Symbol:\\n\\n### Definition:\\nA Treasury Account Symbol (TAS) is an alphanumeric code assigned by the United States Department of the Treasury to each account established in the federal government's general ledger. The TAS is essential for financial reporting and budgetary formulation purposes, functioning as a unique identifier for federal appropriations, funds, and accounts.\\n\\n### Structure:\\nThe TAS is composed of several components, each of which provides specific information about the account. The standard format includes:\\n\\n1. **Agency Identifier**: Designates the federal entity responsible for the account and is usually a three-digit number.\\n   \\n2. **Main Account Code**: A four-digit number that specifies the primary account under which an agency's budget authority is recorded.\\n   \\n3. **Sub-account Code (Optional)**: A three-digit code that may be used to distinguish different sub-level activities within a main account.\\n   \\n4. **Budget Fiscal Year**: Indicates the fiscal year for which the funds were provided, which helps in tracking allocations over time.\\n   \\n5. **Treasury Data Components (Optional)**: Additional fields that may include allocation transfer agencies, availability type code, beginning period of availability, ending period of availability, etc.\\n\\n### Purpose and Importance:\\n\\n- **Budget Execution**: TAS is used to monitor the obligation and expenditure of appropriated funds, ensuring that agencies operate within the financial limits set by Congress.\\n\\n- **Financial Reporting and Accountability**: It allows for detailed tracking of financial transactions within each federal agency, increasing the transparency and accountability of government spending.\\n\\n- **Uniformity and Consistency**: TAS provides a standardized system across all government entities for interpreting, presenting, and reporting financial data, which is crucial for the consistency of federal financial operations and statements.\\n\\n- **Data Aggregation and Analysis**: TAS facilitates the aggregation of data for analytical purposes. By providing a common reference point, analysts can analyze spending patterns, forecast future budgetary needs, and conduct performance evaluations.\\n\\n### Practical Application:\\nTo give you an example, if you were to analyze federal budget data through Python using datasets available from sources like OMB or data.gov, the TAS would be a key field in the data tables. When working with these datasets, visualizing them with libraries like matplotlib or seaborn, you might use TAS as a unique identifier to filter or aggregate data sets based on various criteria such as agency, fiscal year, or fund category.\\n\\nIn conclusion, the Treasury Account Symbol is a fundamental aspect of federal financial management, crucial for ensuring that government agencies allocate and report funds in compliance with legislative and administrative requirements. It plays an instrumental role in maintaining accountability and transparency in federal budgeting and spending.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Retreive\n",
    "- ( store=True )\n"
   ],
   "id": "39f725046e0f0737"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "first_completion = client.chat.completions.retrieve( completion_id=first_id )\n",
    "print( first_completion )"
   ],
   "id": "9e0b5e3d236d2502"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### View",
   "id": "c685a267b56ad098"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "completions = client.chat.completions.list( )\n",
    "first_completion = client.chat.completions.retrieve( completion_id=1 )\n",
    "messages = client.chat.completions.messages.list( message_id=1 )\n",
    "print( messages )"
   ],
   "id": "9efa170085e137dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List",
   "id": "27b32337f2890c5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T21:43:39.308058Z",
     "start_time": "2025-05-31T21:43:37.975150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "completions = client.chat.completions.list( )\n",
    "print( completions )\n"
   ],
   "id": "b8c1955ae558a434",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[ChatCompletion](data=[ChatCompletion(id='chatcmpl-BdODMsPSKbLk8T2cfPYzrf4c1igNb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"A Treasury Symbol, also known as a Treasury Account Symbol (TAS), is a critical element in the United States federal budgeting system. It is used to track and control federal funds across different agencies and programs. Here is a detailed explanation of the Treasury Symbol:\\n\\n### Definition:\\nA Treasury Account Symbol (TAS) is an alphanumeric code assigned by the United States Department of the Treasury to each account established in the federal government's general ledger. The TAS is essential for financial reporting and budgetary formulation purposes, functioning as a unique identifier for federal appropriations, funds, and accounts.\\n\\n### Structure:\\nThe TAS is composed of several components, each of which provides specific information about the account. The standard format includes:\\n\\n1. **Agency Identifier**: Designates the federal entity responsible for the account and is usually a three-digit number.\\n   \\n2. **Main Account Code**: A four-digit number that specifies the primary account under which an agency's budget authority is recorded.\\n   \\n3. **Sub-account Code (Optional)**: A three-digit code that may be used to distinguish different sub-level activities within a main account.\\n   \\n4. **Budget Fiscal Year**: Indicates the fiscal year for which the funds were provided, which helps in tracking allocations over time.\\n   \\n5. **Treasury Data Components (Optional)**: Additional fields that may include allocation transfer agencies, availability type code, beginning period of availability, ending period of availability, etc.\\n\\n### Purpose and Importance:\\n\\n- **Budget Execution**: TAS is used to monitor the obligation and expenditure of appropriated funds, ensuring that agencies operate within the financial limits set by Congress.\\n\\n- **Financial Reporting and Accountability**: It allows for detailed tracking of financial transactions within each federal agency, increasing the transparency and accountability of government spending.\\n\\n- **Uniformity and Consistency**: TAS provides a standardized system across all government entities for interpreting, presenting, and reporting financial data, which is crucial for the consistency of federal financial operations and statements.\\n\\n- **Data Aggregation and Analysis**: TAS facilitates the aggregation of data for analytical purposes. By providing a common reference point, analysts can analyze spending patterns, forecast future budgetary needs, and conduct performance evaluations.\\n\\n### Practical Application:\\nTo give you an example, if you were to analyze federal budget data through Python using datasets available from sources like OMB or data.gov, the TAS would be a key field in the data tables. When working with these datasets, visualizing them with libraries like matplotlib or seaborn, you might use TAS as a unique identifier to filter or aggregate data sets based on various criteria such as agency, fiscal year, or fund category.\\n\\nIn conclusion, the Treasury Account Symbol is a fundamental aspect of federal financial management, crucial for ensuring that government agencies allocate and report funds in compliance with legislative and administrative requirements. It plays an instrumental role in maintaining accountability and transparency in federal budgeting and spending.\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1748727572, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=CompletionUsage(completion_tokens=580, prompt_tokens=164, total_tokens=744, completion_tokens_details=None, prompt_tokens_details=None), request_id='req_da1cc6734c70a4c51a2102530f7deebf', tool_choice=None, seed=5843493702556894719, top_p=1.0, temperature=1.0, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format=None), ChatCompletion(id='chatcmpl-BZhALywhbYsgVuuhZq8bNTGrpfm20', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A Treasury Symbol, also commonly referred to as a Treasury Account Symbol (TAS), is a unique identifier used by the United States Department of the Treasury to track and report federal budget transactions. The TAS is used within the federal government\\'s accounting and financial management systems to ensure accurate tracking and reporting of appropriations, collections, disbursements, and balances. It provides a detailed framework for identifying various financial components such as appropriation, fund type, and responsible federal agency.\\n\\n### Structure of a Treasury Account Symbol (TAS)\\n\\nA Treasury Account Symbol is composed of several elements, each conveying specific information about the financial attributes of the funds. The primary components include:\\n\\n1. **Agency Identifier:** A three-digit code representing the agency responsible for managing the funds. For example, \"020\" refers to the Department of the Treasury.\\n\\n2. **Main Account:** A four-digit code identifying the specific account within the agency. For example, \"1234\" could represent a specific appropriation account.\\n\\n3. **Sub-Account:** A three-digit optional code providing further granularity within the main account, used for specific reporting needs.\\n\\n4. **Budget Fiscal Year (FY):** The fiscal year the funds were appropriated or made available, represented by a four-digit year format (e.g., 2023).\\n\\n5. **Fund Type:** A two-character code indicating the type of fund or the status of the funds (e.g., revolving funds, trust funds).\\n\\n6. **Availability Type Code:** A single-character code that defines the period during which funds remain available (e.g., annual, multi-year, no-year funds).\\n\\n7. **Treasury Appropriation Fund Symbol (TAFS):** A more specific identifier that separates the TAS into further detailed components, primarily used for Treasury\\'s internal processing.\\n\\n### Example of a Treasury Account Symbol\\n\\nAn example of a Treasury Account Symbol would be: \\n- 020-X-1234-001 (for a hypothetical purpose)\\n\\nBreaking this down, it indicates:\\n- **Agency Identifier (020):** Department of the Treasury\\n- **Main Account (1234):** The specific account within the Treasury\\n- **Sub-Account (001):** Used to designate a specific project or segment within the main account\\n- The \"X\" might indicate no-year funds, meaning the funds are available until expended.\\n\\n### Importance of Treasury Account Symbols\\n\\n1. **Accounting and Financial Management:** TAS facilitates accurate recording and reporting of financial transactions, ensuring funds are used according to legislative and administrative requirements.\\n\\n2. **Transparency and Accountability:** By designating precise identifiers, TAS enhances transparency and helps stakeholders hold agencies accountable for how funds are managed.\\n\\n3. **Data Analysis and Reporting:** TAS provides standardized data points that enable detailed financial analysis across different governmental accounts and operations.\\n\\n### Conclusion\\n\\nThe Treasury Account Symbol plays a crucial role in the financial operations of the U.S. federal government, offering a systematic approach to managing public funds with fidelity to statutory and policy requirements. It aids in ensuring accountability and effective management of federal financial resources, reflecting the government’s commitment to fiscal responsibility and transparency.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1747847109, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_76544d79cb', usage=CompletionUsage(completion_tokens=626, prompt_tokens=164, total_tokens=790, completion_tokens_details=None, prompt_tokens_details=None), request_id='req_e280566195328cb188c98af63fd2bd0a', tool_choice=None, seed=-7965408864888416285, top_p=1.0, temperature=1.0, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format=None), ChatCompletion(id='chatcmpl-BUMHcJ7BH9DBFFNCfQz9jTxPF1Edl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I am associated with the Nike brand, and my Air Jordan line of shoes is one of the most iconic and popular athletic shoe lines in the world.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746575196, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint='-1', usage=CompletionUsage(completion_tokens=31, prompt_tokens=25, total_tokens=56, completion_tokens_details=None, prompt_tokens_details=None), request_id='req_b67b51635a144de1e746b35a6d3ae344', tool_choice=None, seed=8108778304080807611, top_p=1.0, temperature=0.7, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format=None), ChatCompletion(id='chatcmpl-BUA2EBGrGy70XdVlclrME4V4LX4IO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Certainly! The SF-132, also known as the \"Apportionment and Reapportionment Schedule,\" is a critical document used in the federal budget process in the United States. It serves as a formal request for the apportionment of funds appropriated by Congress to federal agencies. Below is a detailed explanation of the SF-132, including its purpose, components, and process.\\n\\n', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746528114, model='ft:gpt-4o-2024-08-06:leeroy-jenkins:bubba-fine-tuned-2025-05-05:BU7RK1Dq', object='chat.completion', service_tier='default', system_fingerprint='fp_de53d86beb', usage=CompletionUsage(completion_tokens=78, prompt_tokens=23985, total_tokens=24063, completion_tokens_details=None, prompt_tokens_details=None), request_id='req_400c7b91e1a932b6f4d01c03e84b2bc1', tool_choice=None, seed=682538965412788153, top_p=0.9, temperature=0.8, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'text', 'json_schema': None}), ChatCompletion(id='chatcmpl-BUA23fBbUz74SEwrpaHQRUAY356NH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Certainly! The SF-132, also known as the \"Apportionment and Reapportionment Schedule,\" is a key document used in the federal budgeting process in the United States. Below is a detailed explanation of its purpose, components, and usage:\\n\\n', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746528103, model='ft:gpt-4o-2024-08-06:leeroy-jenkins:bubba-fine-tuned-2025-05-05:BU7RK1Dq', object='chat.completion', service_tier='default', system_fingerprint='fp_de53d86beb', usage=CompletionUsage(completion_tokens=51, prompt_tokens=23985, total_tokens=24036, completion_tokens_details=None, prompt_tokens_details=None), request_id='req_80c965bd15d87a812567c1f663223c9b', tool_choice=None, seed=-7215412699423944624, top_p=0.9, temperature=0.8, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'text', 'json_schema': None}), ChatCompletion(id='chatcmpl-BU9pCPduz9QzbpBcZRpdPW5ZJ4U0t', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The SF-132, also known as the \"Apportionment and Reapportionment Schedule,\" is a critical financial document used by federal agencies in the United States to manage and control budgetary resources. Here\\'s a detailed explanation of the SF-132:\\n\\n', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746527306, model='ft:gpt-4o-2024-08-06:leeroy-jenkins:bubba-fine-tuned-2025-05-05:BU7RK1Dq', object='chat.completion', service_tier='default', system_fingerprint='fp_de53d86beb', usage=CompletionUsage(completion_tokens=51, prompt_tokens=23986, total_tokens=24037, completion_tokens_details=None, prompt_tokens_details=None), request_id='req_6425cff1846e3f5afe5f296b8d9a4a65', tool_choice=None, seed=-6071037767661146047, top_p=0.9, temperature=0.8, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'text', 'json_schema': None}), ChatCompletion(id='chatcmpl-BU9aqmBucqYNx0qeReP2pOD4VEJLU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Certainly! The SF-132, or \"Apportionment and Reapportionment Schedule,\" is a critical document in the federal budget process. It is used by federal agencies to request the apportionment of appropriated funds and to manage the distribution of those funds throughout the fiscal year. Below is a detailed overview of the SF-132, its purpose, components, and significance in the federal budget process.\\n\\n### Overview of SF-132: Apportionment and Reapportionment Schedule\\n\\n#### Purpose of SF-132\\n\\n1. **Apportionment of Funds**: The primary purpose of the SF-132 is to request the apportionment of appropriated funds. Apportionment is the process by which the Office of Management and Budget (OMB) distributes appropriated funds to federal agencies in specific amounts and timeframes, allowing agencies to obligate funds in a controlled manner.\\n\\n2. **Budget Execution**: The SF-132 facilitates the execution of the federal budget by ensuring that agencies have the necessary funds available to carry out their programs and operations. It helps agencies plan their spending and manage their resources effectively.\\n\\n3. **Compliance with Laws**: The SF-132 ensures that agencies comply with the Anti-Deficiency Act, which prohibits federal agencies from obligating or spending funds in excess of appropriated amounts. By requesting apportionments, agencies demonstrate their adherence to legal requirements.\\n\\n#### Components of SF-132\\n\\nThe SF-132 typically includes several key components, each of which serves a specific purpose in the apportionment process:\\n\\n1. **Agency Information**: The form includes details about the agency requesting the apportionment, including the agency name, bureau, and contact information.\\n\\n2. **Appropriation Account**: The form specifies the appropriation account(s) for which the apportionment is being requested. This includes the account number and title, which identify the specific source of funds.\\n\\n3. **Apportionment Request**: The form outlines the amount of funds being requested for apportionment. This section may include:\\n   - **Initial Apportionment**: The initial request for funds at the beginning of the fiscal year.\\n   - **Reapportionment**: Subsequent requests for additional funds or adjustments to previously apportioned amounts.\\n\\n4. **Time Period**: The SF-132 specifies the time period for which the apportionment is requested. This may include quarterly or monthly apportionments, depending on the agency\\'s needs and the nature of the appropriated funds.\\n\\n5. **Justification**: Agencies are required to provide a justification for the requested apportionment. This includes an explanation of how the funds will be used, the anticipated outcomes, and the alignment with agency goals and objectives.\\n\\n6. **Certification**: The form includes a certification section where agency officials attest to the accuracy of the information provided and their compliance with applicable laws and regulations.\\n\\n#### Process of Using SF-132\\n\\n1. **Preparation**: Agencies prepare the SF-132 by gathering relevant financial data, including appropriated amounts, obligations, and expenditures. They assess their funding needs and determine the appropriate apportionment amounts.\\n\\n2. **Submission**: The completed SF-132 is submitted to the OMB for review. Agencies may also need to provide supporting documentation, such as budget justifications and performance plans.\\n\\n3. **Review and Approval**: The OMB reviews the SF-132 to ensure that the requested apportionment aligns with the appropriated amounts and complies with federal laws. The OMB may approve the request, request additional information, or make adjustments as necessary.\\n\\n4. **Implementation**: Once approved, the apportionment is implemented, allowing the agency to obligate funds in accordance with the approved amounts. Agencies must monitor their spending to ensure compliance with the apportionment and avoid violations of the Anti-Deficiency Act.\\n\\n#### Significance of SF-132\\n\\n1. **Financial Management**: The SF-132 is a critical tool for financial management within federal agencies. It helps agencies plan their spending, manage cash flow, and ensure that funds are used effectively to achieve program goals.\\n\\n2. **Accountability**: By requiring agencies to justify their apportionment requests, the SF-132 promotes accountability in the use of federal funds. Agencies must demonstrate that their funding requests are necessary and aligned with their mission.\\n\\n3. **Compliance**: The SF-132 ensures that agencies comply with federal laws and regulations, including the Anti-Deficiency Act. By adhering to the apportionment process, agencies reduce the risk of financial mismanagement and legal violations.\\n\\n4. **Budget Execution**: The SF-132 plays a vital role in the execution of the federal budget. It ensures that appropriated funds are distributed in a timely manner, allowing agencies to carry out their programs and services effectively.\\n\\n### Conclusion\\n\\nThe SF-132, or Apportionment and Reapportionment Schedule, is a fundamental document in the federal budget process. It serves as a tool for requesting the apportionment of appropriated funds, facilitating budget execution, and ensuring compliance with federal laws. By providing detailed information on agency funding needs and justifications, the SF-132 promotes accountability and effective financial management within federal agencies. Understanding the components and process of the SF-132 is essential for federal budget analysts, financial managers, and policymakers involved in the allocation and management of federal resources.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746526416, model='ft:gpt-4o-2024-08-06:leeroy-jenkins:bubba-fine-tuned-2025-05-05:BU7RK1Dq', object='chat.completion', service_tier='default', system_fingerprint='fp_de53d86beb', usage=None, request_id='req_02ea0dde04ddaa2f7e714e4f352c2546', tool_choice=None, seed=-7743582128973664163, top_p=0.09, temperature=0.08, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format=None), ChatCompletion(id='chatcmpl-BSsy9k7WJoQHgNeZGXO3zrG9M2GaU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Certainly! The Anti-Deficiency Act (ADA) is a critical piece of legislation in the United States that governs federal financial management and appropriations. Below is a detailed overview of the Anti-Deficiency Act, including its purpose, key provisions, implications, and enforcement mechanisms.\\n\\n### Overview of the Anti-Deficiency Act\\n\\n#### Purpose\\nThe Anti-Deficiency Act is designed to ensure that federal agencies do not spend more money than Congress has appropriated and to prevent the federal government from incurring obligations without sufficient funds. The Act aims to promote fiscal responsibility and accountability in federal financial management.\\n\\n#### Key Provisions\\nThe Anti-Deficiency Act includes several important provisions that outline the limitations and requirements for federal spending:\\n\\n1. **Prohibition on Over-Obligation**:\\n   - Federal agencies are prohibited from obligating or expending funds in excess of the amounts appropriated by Congress. This means that agencies cannot commit to spending more money than they have been allocated.\\n\\n2. **Prohibition on Obligating Funds Before Appropriation**:\\n   - Agencies cannot obligate funds before they have been appropriated by Congress. This ensures that spending is authorized and aligns with the budgetary process.\\n\\n3. **Prohibition on Obligating Funds for Unauthorized Purposes**:\\n   - Agencies are prohibited from using appropriated funds for purposes that are not authorized by law. This ensures that funds are used in accordance with the specific purposes for which they were appropriated.\\n\\n4. **Apportionment Requirements**:\\n   - The Act requires that appropriated funds be apportioned by the Office of Management and Budget (OMB) to ensure that spending is spread out over the fiscal year. This helps prevent agencies from exhausting their funds too quickly.\\n\\n5. **Reporting Requirements**:\\n   - Agencies are required to report any violations of the Anti-Deficiency Act to the President, Congress, and the Comptroller General. This reporting requirement ensures transparency and accountability in federal financial management.\\n\\n#### Implications\\nThe Anti-Deficiency Act has several important implications for federal agencies and their financial management practices:\\n\\n1. **Budgetary Discipline**:\\n   - The Act enforces budgetary discipline by ensuring that agencies operate within their appropriated budgets. This helps prevent overspending and promotes responsible financial management.\\n\\n2. **Accountability**:\\n   - The reporting requirements and potential penalties for violations create a strong incentive for agencies to comply with the Act. This accountability mechanism helps ensure that federal funds are used appropriately.\\n\\n3. **Operational Constraints**:\\n   - The limitations imposed by the Act can affect the ability of agencies to respond to changing circumstances or emergencies. Agencies must carefully plan their budgets and expenditures to avoid violations.\\n\\n#### Enforcement\\nThe Anti-Deficiency Act includes enforcement mechanisms to ensure compliance:\\n\\n1. **Penalties**:\\n   - Violations of the Anti-Deficiency Act can result in administrative penalties, including disciplinary actions against responsible officials. In some cases, violations may lead to criminal charges.\\n\\n2. **Oversight**:\\n   - The Government Accountability Office (GAO) and the Office of Management and Budget (OMB) play key roles in overseeing compliance with the Act. They conduct audits and reviews to ensure that agencies adhere to the requirements.\\n\\n3. **Corrective Actions**:\\n   - Agencies found to be in violation of the Act are required to take corrective actions to address the issues and prevent future violations. This may include revising budgetary practices and improving financial management systems.\\n\\n### Conclusion\\nThe Anti-Deficiency Act is a fundamental component of federal financial management in the United States. By prohibiting over-obligation and unauthorized spending, the Act promotes fiscal responsibility and accountability within federal agencies. Its provisions ensure that appropriated funds are used in accordance with the law and that agencies operate within their budgetary limits. The enforcement mechanisms, including penalties and oversight, further reinforce the importance of compliance with the Act.\\n\\nIf you have specific questions about the Anti-Deficiency Act or its application to particular federal agencies or programs, please feel free to ask!', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746224185, model='ft:gpt-4o-2024-08-06:leeroy-jenkins:budget-base-training:BGVk5Lly:ckpt-step-35', object='chat.completion', service_tier='default', system_fingerprint='fp_de53d86beb', usage=None, request_id='req_b40943f12585f2ee3e36c92caf76d45d', tool_choice=None, seed=-5470571029571826971, top_p=0.09, temperature=0.08, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format=None), ChatCompletion(id='chatcmpl-BSsnQAqXRF6zd2RlPj8jdHEo1y5w7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Certainly! The appropriations process is a critical component of the federal budgetary system in the United States. It involves the allocation of federal funds to various government agencies and programs and is essential for the functioning of the government. Below is a detailed overview of the appropriations process, including its components, timeline, and key considerations.\\n\\n### Overview of the Appropriations Process\\n\\n1. **Definition of Appropriations**:\\n   - Appropriations are legal authorizations by Congress that allow federal agencies to incur obligations and make payments for specific purposes. They provide the funding necessary for the government to operate and implement its programs.\\n\\n2. **Types of Appropriations**:\\n   - **Discretionary Appropriations**: These are funds that Congress allocates annually through the appropriations process. They cover a wide range of government activities, including defense, education, and public health.\\n   - **Mandatory Appropriations**: These are funds that are automatically provided by law for certain programs, such as Social Security and Medicare, and do not require annual approval by Congress.\\n\\n3. **The Appropriations Process**:\\n   - The appropriations process typically follows a series of steps, which are outlined below:\\n\\n   #### Step 1: Budget Proposal\\n   - **Presidential Budget Request**: The process begins with the President submitting a budget proposal to Congress, usually in February. This proposal outlines the administration\\'s funding priorities and recommendations for the upcoming fiscal year.\\n\\n   #### Step 2: Congressional Budget Resolution\\n   - **Budget Resolution**: Congress develops a budget resolution that sets overall spending limits for discretionary programs. The resolution is not legally binding but serves as a framework for the appropriations process.\\n\\n   #### Step 3: Appropriations Bills\\n   - **Subcommittee Hearings**: Appropriations subcommittees in both the House and Senate hold hearings to review the President\\'s budget request and gather input from federal agencies and stakeholders.\\n   - **Drafting of Bills**: The subcommittees draft appropriations bills that allocate funding to specific programs and agencies. These bills must adhere to the spending limits set by the budget resolution.\\n\\n   #### Step 4: Committee Approval\\n   - **Subcommittee Approval**: The appropriations subcommittees vote on the draft bills. If approved, the bills move to the full appropriations committee for further consideration.\\n   - **Full Committee Approval**: The full appropriations committee reviews and votes on the bills. If approved, the bills are sent to the floor of the House or Senate for debate.\\n\\n   #### Step 5: Floor Debate and Passage\\n   - **House and Senate Debate**: The appropriations bills are debated on the floor of the House and Senate. Members may propose amendments to the bills during this stage.\\n   - **Passage**: Each chamber must pass the appropriations bills. If there are differences between the House and Senate versions, a conference committee may be convened to reconcile the differences.\\n\\n   #### Step 6: Conference Committee\\n   - **Reconciliation**: The conference committee, composed of members from both the House and Senate, works to reconcile differences between the two versions of the appropriations bills.\\n   - **Conference Report**: The committee produces a conference report, which outlines the agreed-upon funding levels and provisions. Both chambers must approve the conference report.\\n\\n   #### Step 7: Presidential Approval\\n   - **Presidential Signature**: Once both chambers have approved the appropriations bills, they are sent to the President for signature. The President can sign the bills into law, veto them, or allow them to become law without a signature.\\n\\n4. **Continuing Resolutions**:\\n   - If Congress is unable to pass appropriations bills before the start of the fiscal year (October 1), it may enact a continuing resolution (CR) to provide temporary funding for government operations. A CR allows agencies to continue operating at current funding levels until appropriations are finalized.\\n\\n5. **Implementation and Oversight**:\\n   - Once appropriations are enacted, federal agencies are responsible for implementing the funded programs. Congress conducts oversight to ensure that funds are used effectively and in accordance with the law.\\n\\n### Key Considerations\\n\\n- **Bipartisanship**: The appropriations process often requires bipartisan support, as both parties must agree on funding levels and priorities.\\n- **Fiscal Responsibility**: Appropriations must balance the need for funding with fiscal responsibility, considering the impact on the federal deficit and debt.\\n- **Policy Provisions**: Appropriations bills may include policy provisions or \"riders\" that set conditions on the use of funds or address specific policy issues.\\n\\n### Conclusion\\n\\nThe appropriations process is a complex and essential component of the federal budgetary system. It involves multiple steps, including the President\\'s budget proposal, congressional hearings, drafting and approval of appropriations bills, and presidential approval. The process ensures that federal agencies have the necessary funding to operate effectively while maintaining accountability and oversight. Understanding the appropriations process is crucial for policymakers, government officials, and stakeholders involved in federal budgeting and financial management.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746223520, model='ft:gpt-4o-2024-08-06:leeroy-jenkins:budget-base-training:BGVk5Lly:ckpt-step-35', object='chat.completion', service_tier='default', system_fingerprint='fp_de53d86beb', usage=None, request_id='req_8b5980a4c17fc4d10307369472acacc9', tool_choice=None, seed=-852752462781884597, top_p=0.09, temperature=0.08, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format=None), ChatCompletion(id='chatcmpl-BSsgtZUx9zpeCwhUoj200pRZfd2o9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Certainly! The appropriations process is a critical component of the federal budgeting system in the United States, involving the allocation of federal funds to various government agencies and programs. This process ensures that government operations are funded in accordance with the priorities set forth by Congress and the President. Below is a detailed description of the appropriations process:\\n\\n', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746223115, model='ft:gpt-4o-2024-08-06:leeroy-jenkins:bubba-base-training:BGVAJg57', object='chat.completion', service_tier='default', system_fingerprint='fp_de53d86beb', usage=CompletionUsage(completion_tokens=65, prompt_tokens=15412, total_tokens=15477, completion_tokens_details=None, prompt_tokens_details=None), request_id='req_2eeb455eb62ac3b5aac6c67a3d290b79', tool_choice=None, seed=659760441981503884, top_p=0.9, temperature=0.8, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'text', 'json_schema': None})], has_more=False, object='list', first_id='chatcmpl-BdODMsPSKbLk8T2cfPYzrf4c1igNb', last_id='chatcmpl-BSsgtZUx9zpeCwhUoj200pRZfd2o9')\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Summarize",
   "id": "d090bc4367f0d575"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "path = ( 'draconomicon.pdf' )\n",
    "file = client.files.create( file=open( path, 'rb' ), purpose='user_data' )\n",
    "\n",
    "# Create Completion\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'scaler': 'file',\n",
    "                    'file':\n",
    "\t\t\t\t\t{\n",
    "                        'file_id': file.id,\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'scaler': 'text',\n",
    "                    'text': 'What is the first dragon in the book?',\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ].message.content )"
   ],
   "id": "2f33ae0e30d9908e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Update",
   "id": "e242393b55304b89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "updated_completion = client.chat.completions.update( completion_id=first_id,\n",
    "\trequest_body={ 'metadata': { 'foo': 'bar' } } )\n",
    "print( updated_completion )"
   ],
   "id": "6213187806dd07ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Delete",
   "id": "af694e2c08fbf7fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "delete_response = client.chat.completions.delete( completion_id=first_id )\n",
    "print( delete_response )"
   ],
   "id": "44985a4587ed531a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Article Summarization",
   "id": "3fa526ede54b27a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "articles = [ './df/structured_outputs_articles/cnns.md', './df/structured_outputs_articles/llms.md',\n",
    "    './df/structured_outputs_articles/moe.md' ]"
   ],
   "id": "3cb869b1a4d8d499"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_article_content(path):\n",
    "    with open(path, 'r') as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "content = [get_article_content(path) for path in articles]\n",
    "print(content)"
   ],
   "id": "c7ace26f405bbfd0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "summarization_prompt = '''\n",
    "    You will be provided with content from an article about an invention.\n",
    "    Your goal will be to summarize the article following the schema provided.\n",
    "    Here is a description of the parameters:\n",
    "    - invented_year: year in which the invention discussed in the article was invented\n",
    "    - summary: one sentence summary of what the invention is\n",
    "    - inventors: array of strings listing the inventor full names if present, otherwise just surname\n",
    "    - concepts: array of key concepts related to the invention, each concept containing a title and a description\n",
    "    - description: short description of the invention\n",
    "'''"
   ],
   "id": "8546dda414742b48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ArticleSummary( BaseModel ):\n",
    "    invented_year: int\n",
    "    summary: str\n",
    "    inventors: list[ str ]\n",
    "    description: str\n",
    "\n",
    "    class Concept( BaseModel ):\n",
    "        title: str\n",
    "        description: str\n",
    "\n",
    "    concepts: list[ Concept ]\n",
    "\n",
    "def get_article_summary( text: str ):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model='gpt-4o-mini',\n",
    "        temperature=0.2,\n",
    "        messages=[ { 'role': 'system', 'content': dedent( summarization_prompt ) },\n",
    "            { 'role': 'user', 'content': text } ],\n",
    "        response_format=ArticleSummary, )\n",
    "\n",
    "    return completion.choices[ 0 ].message.parsed"
   ],
   "id": "d78a2335e5e80b2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Assistants API\n",
    "- Can call models and use tools to perform tasks..\n",
    "- An Assistant has instructions and can leverage models, tools, and files to respond to user queries.\n",
    "- Assistants can access multiple tools in parallel. These can be both OpenAI built-in tools — like code_interpreter and file_search — or tools you build / host (via function calling).\n",
    "\n",
    "##### Tools:\n",
    "\n",
    "- Code Interpreter\n",
    "- File Search\n",
    "- Function calling\n",
    "\n",
    "\n",
    "##### Integration of the Assistants API has the following flow:\n",
    "1. Create an Assistant by defining its custom instructions and picking a model (with optional Tools).\n",
    "2. Create a Thread when a user starts a conversation.\n",
    "3. Add Messages to the Thread as the user asks questions.\n",
    "4. Run the Assistant on the Thread to generate a response by calling the model and the tools.\n",
    "___"
   ],
   "id": "f8d8b0952801b089"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List Assistants",
   "id": "a357cc85dc16c209"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List Assistants\n",
    "my_assistants = client.beta.assistants.list( order='desc', limit='20' )\n",
    "\n",
    "print( my_assistants.data )\n"
   ],
   "id": "3235e66ae8b85397"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retreive Assistant\n",
   "id": "8c09784334b20656"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "bro = 'asst_2IpP4nE85lXLKbY6Zewwqtqe'\n",
    "bubba = 'asst_J6SAABzDixkTYi2k39OGgjPv'\n",
    "\n",
    "# Retrieve Assistant\n",
    "my_assistant = client.beta.assistants.retrieve( bro )\n",
    "print( my_assistant )\n"
   ],
   "id": "6fad50179659d1e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create Assistant\n",
    "- Bro"
   ],
   "id": "37f0447af22b473d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T14:24:36.749302Z",
     "start_time": "2025-07-04T14:24:33.550207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name='Boo',\n",
    "  instructions='You are a computer programming tutor. Write and run code to answer programming questions.',\n",
    "  tools=[ { 'type': 'code_interpreter' } ],\n",
    "  model='gpt-4o' )"
   ],
   "id": "57b5b9cb4ae0a5a9",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Completion Response",
   "id": "69d298bf352ae5e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  'id': 'asst_abc123',\n",
    "  'object': 'assistant',\n",
    "  'created_at': 1698984975,\n",
    "  'name': 'Bro',\n",
    "  'description': null,\n",
    "  'small_model': 'gpt-4o-mini',\n",
    "  'instructions': 'You are a personal math tutor. When asked a prompt, write and run Python code to answer the prompt.',\n",
    "  'tools': [ { 'type': 'code_interpreter' } ],\n",
    "  'metadata': {},\n",
    "  'top_p': 0.9,\n",
    "  'temperature': 0.8,\n",
    "  'response_format': 'auto'\n",
    "}\n"
   ],
   "id": "875f6353c0b9cc24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create Assistant\n",
    "- Bubba"
   ],
   "id": "d572c7e3e53696f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T14:26:29.469431Z",
     "start_time": "2025-07-04T14:26:25.636477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Assistant\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions='You are a Budget bot with access to files to assist you in answering questions about federal regulations and appropriations',\n",
    "    name='Bubba',\n",
    "    tools=[ { 'type': 'file_search' } ],\n",
    "    tool_resources={'file_search': { 'vector_store_ids': [ 'vs_712r5W5833G6aLxIYIbuvVcK' ] } },\n",
    "    model='gpt-4o-mini'\n",
    ")\n",
    "my_assistant\n",
    "print( my_assistant )\n"
   ],
   "id": "a9e02e2d8d5ea8db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_6C6aTIRw2uWLzdQhDzBehNAH', created_at=1751639187, description=None, instructions='You are a Budget bot with access to files to assist you in answering questions about federal regulations and appropriations', metadata={}, model='gpt-4o-mini', name='Bubba', object='assistant', tools=[FileSearchTool(type='file_search', file_search=FileSearch(max_num_results=None, ranking_options=FileSearchRankingOptions(score_threshold=0.0, ranker='default_2024_08_21')))], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=['vs_8fEoYp1zVvk5D8atfWLbEupN'])), top_p=1.0, reasoning_effort=None)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Search Response",
   "id": "1edbaf850a309d0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "{\n",
    "      'id': 'asst_abc123',\n",
    "      'object': 'assistant',\n",
    "      'created_at': 1699009403,\n",
    "      'name': 'HR Helper',\n",
    "      'description': null,\n",
    "      'small_model': 'gpt-4o-mmini',\n",
    "      'instructions': 'You are an HR bot, and you have access to files to answer employee questions about company policies.',\n",
    "      'tools': [ { 'text': 'file_search' } ],\n",
    "      'tool_resources':\n",
    "      {\n",
    "            'file_search':\n",
    "             {\n",
    "                 'vector_store_ids': [ 'vs_8fEoYp1zVvk5D8atfWLbEupN', 'vs_712r5W5833G6aLxIYIbuvVcK' ]\n",
    "             }\n",
    "      },\n",
    "      'metadata': {},\n",
    "      'top_p': 1.0,\n",
    "      'temperature': 1.0,\n",
    "      'response_format': 'auto'\n",
    "}\n"
   ],
   "id": "673e1e7eef9b0d03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Thread",
   "id": "ee16b57af0b6ae21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "thread = client.beta.threads.create( )"
   ],
   "id": "62b60e58aa3f1eaa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Add Message",
   "id": "da3c6bcc2776b905"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "thread_message = client.beta.threads.messages.create( 'thread_abc123',\n",
    "  role='user', content='How does GPT work? Explain it in simple terms.' )\n",
    "\n",
    "print( thread_message )"
   ],
   "id": "dc41efb63f15f682"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Run",
   "id": "bea37cd09694d48b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "run = client.beta.threads.runs.create_and_poll( thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions='Please address the user as Jane Doe. The user has a premium account.'\n",
    ")\n",
    "\n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list( thread_id=thread.id )\n",
    "  print( messages )\n",
    "else:\n",
    "  print( run.status )"
   ],
   "id": "b292ee7c18a0731b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Stream Run",
   "id": "7d9a4e3be003fb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# First, we generate an EventHandler class to define how we want to handle the events in the response stream.\n",
    "\n",
    "class EventHandler( AssistantEventHandler ):\n",
    "  @override\n",
    "  def on_text_created( self, text ) -> None:\n",
    "    print( f'\\nassistant > ', end=\"\", flush=True )\n",
    "\n",
    "  @override\n",
    "  def on_text_delta( self, delta, snapshot ):\n",
    "    print( delta.value, end=\"\", flush=True )\n",
    "\n",
    "  def on_tool_call_created( self, tool_call ):\n",
    "    print(f'\\nassistant > {tool_call.type}\\n', flush=True )\n",
    "\n",
    "  def on_tool_call_delta( self, delta, snapshot ):\n",
    "    if delta.type == 'code_interpreter':\n",
    "      if delta.code_interpreter.input:\n",
    "        print( delta.code_interpreter.input, end=\"\", flush=True )\n",
    "      if delta.code_interpreter.outputs:\n",
    "        print( f'\\n\\ncleaned_lines >', flush=True )\n",
    "        for output in delta.code_interpreter.outputs:\n",
    "          if output.type == 'logs':\n",
    "            print( f'\\n{output.logs}', flush=True )\n",
    "\n",
    "# We use the `stream` SDK helper with the `EventHandler` class to the Run and stream the response.\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions='Please address the user as Jane Doe. The user has a premium account.',\n",
    "  event_handler=EventHandler( ),\n",
    ") as stream:\n",
    "    stream.until_done( )"
   ],
   "id": "54a9d0956c5828e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Responses API\n",
    "- Supports text and image inputs, and text outputs.\n",
    "- Create stateful interactions with the model, using the output of previous responses as input\n",
    "- Allow the model access to external systems and data using function calling\n",
    "___"
   ],
   "id": "4c575af21d7c503e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Response Format\n",
    "- `choices`\n",
    "- `response.choices[0].message.content`"
   ],
   "id": "38227c70596dcf78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "[\n",
    "    {\n",
    "        'index': 0,\n",
    "        'message':\n",
    "        {\n",
    "            'role': 'assistant',\n",
    "            'content': 'Under the soft glow of the moon, Luna the unicorn danced through columns of twinkling stardust, leaving trails of dreams for every child asleep.',\n",
    "            'refusal': null\n",
    "         },\n",
    "         'logprobs': null,\n",
    "         'finish_reason': 'stop'\n",
    "    }\n",
    "]"
   ],
   "id": "fa6cd697329d39bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Generate Text",
   "id": "8003c92f11eb5918"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "response = client.responses.create( model='gpt-4o-mini',\n",
    "    input='Write a five-sentence bedtime story about a unicorn.' )\n",
    "\n",
    "print( response.output_text )"
   ],
   "id": "c36f628f5b2933f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Analyze Image",
   "id": "492e2e4702de788b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create GptResponse\n",
    "response = client.responses.create( model='gpt-4o-mini',\n",
    "    input=\n",
    "    [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content':\n",
    "\t        [\n",
    "                { 'type': 'input_text',\n",
    "                  'text': 'what is in this image?'\n",
    "                },\n",
    "                {\n",
    "                    'type': 'input_image',\n",
    "                    'image_url': 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg'\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print( response.output_text )"
   ],
   "id": "1dec09adabb5016a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Search Web",
   "id": "b7dd6de1b5ac36f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create GptResponse\n",
    "response = client.responses.create( model='gpt-4o-mini',\n",
    "    tools=[ { 'type': 'web_search_preview' } ],\n",
    "    input='What was a positive news story from today?' )\n",
    "\n",
    "print( response.output_text )"
   ],
   "id": "db29cad5d8439c08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Web Result Format",
   "id": "54ab863f46a0e975"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "[\n",
    "  {\n",
    "    'type': 'web_search_call',\n",
    "    'id': 'ws_67c9fa0502748190b7dd390736892e100be649c1a5ff9609',\n",
    "    'status': 'completed'\n",
    "  },\n",
    "  {\n",
    "    'id': 'msg_67c9fa077e288190af08fdffda2e34f20be649c1a5ff9609',\n",
    "    'type': 'message',\n",
    "    'status': 'completed',\n",
    "    'role': 'assistant',\n",
    "    'content': [\n",
    "      {\n",
    "        'text': 'output_text',\n",
    "        'text': 'On March 6, 2025, several news...',\n",
    "        'annotations':\n",
    "        [\n",
    "          {\n",
    "            'type': 'url_citation',\n",
    "            'start_index': 2606,\n",
    "            'end_index': 2758,\n",
    "            'url': 'https://...',\n",
    "            'title': 'Title...'\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]"
   ],
   "id": "b4faa744d8983321"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Function Schema",
   "id": "5c7154217da1d11d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "    'type': 'function',\n",
    "    'function':\n",
    "    {\n",
    "        'name': 'get_weather',\n",
    "        'description': 'Retrieves current weather for a given location.',\n",
    "        'parameters':\n",
    "        {\n",
    "            'type': 'object',\n",
    "            'properties':\n",
    "            {\n",
    "                'location':\n",
    "                {\n",
    "                    'text': 'path',\n",
    "                    'description': 'City and country e.g. Bogotá, Colombia'\n",
    "                },\n",
    "                'units':\n",
    "                {\n",
    "                    'text': 'path',\n",
    "                    'enum':\n",
    "                    [\n",
    "                        'celsius',\n",
    "                        'fahrenheit'\n",
    "                    ],\n",
    "                    'description': 'Units the temperature will be returned in.'\n",
    "                }\n",
    "            },\n",
    "            'required':\n",
    "            [\n",
    "                'location',\n",
    "                'units'\n",
    "            ],\n",
    "            'additionalProperties': false\n",
    "        },\n",
    "\n",
    "        'strict': true\n",
    "    }\n",
    "}"
   ],
   "id": "c367017cc7dfdf54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search File",
   "id": "29d0165d9ab17144"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "response = client.responses.create(\n",
    "\tmodel='gpt-4o-mini',\n",
    "\ttools=\n",
    "\t[\n",
    "\t\t{\n",
    "\t\t\t'type': 'file_search',\n",
    "\t\t\t'vector_store_ids': [ 'vs_712r5W5833G6aLxIYIbuvVcK', 'vs_8fEoYp1zVvk5D8atfWLbEupN' ],\n",
    "\t\t\t'max_num_results': 20\n",
    "\t\t}\n",
    "\t],\n",
    "\tinput='What are the attributes of an ancient brown dragon?',\n",
    ")\n",
    "\n",
    "print( response.output_text )"
   ],
   "id": "e21a1c8fec9121d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Stream",
   "id": "23a7bd3db3bbba25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create GptResponse\n",
    "response = client.responses.create(\n",
    "\tmodel='gpt-4o',\n",
    "\tinstructions='You are a helpful assistant.',\n",
    "\tinput='Hello!',\n",
    "\tstream=True\n",
    ")\n",
    "\n",
    "for event in response:\n",
    "\tprint( event )"
   ],
   "id": "5c8f01161c70a2d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Stream\n",
    "- Generates audio from the input text."
   ],
   "id": "8d2f750d272fde5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Speech\n",
    "speech_file_path = Path( __file__ ).parent \n",
    "prompt = 'The quick brown fox jumped over the lazy dog.'\n",
    "response = client.audio.speech.create( model='tts-1-hd', voice='alloy', input=prompt )\n",
    "response.stream_to_file( speech_file_path )\n"
   ],
   "id": "10bbff7ec480fedf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Transcribe\n",
    "- Transcribes audio into the input language."
   ],
   "id": "4426bb6e9a602952"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "audio_file = open( 'speech.mp3', 'rb' )\n",
    "transcript = client.audio.transcriptions.create( model='whisper-1', file=audio_file )\n"
   ],
   "id": "65fec2f02c5afaa1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Translate\n",
    "- Translates audio into English."
   ],
   "id": "81308dfbaba50f9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "audio_file = open( 'speech.mp3', 'rb' )\n",
    "translation = client.audio.translations.create( model='whisper-1', file=audio_file )\n"
   ],
   "id": "5ce3f8486bc57f9c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generate",
   "id": "b5146a7d3aabe350"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "completion = client.chat.completions.create( model='gpt-4o-audio-preview', modalities=[ 'text', 'audio' ],\n",
    "    audio={ 'voice': 'alloy', 'format': 'wav' }, messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Is a golden retriever a good family dog?'\n",
    "        }\n",
    "    ] )\n",
    "\n",
    "print( completion.choices[ 0 ] )\n",
    "wav_bytes = base64.b64decode( completion.choices[ 0 ].message.audio.data )\n",
    "with open( 'dog.wav', 'wb' ) as f:\n",
    "    f.write( wav_bytes )"
   ],
   "id": "b52722036f1bad5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analyze",
   "id": "909f7bbf1588a9dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "url = 'https://cdn.openai.com/API/docs/audio/alloy.wav'\n",
    "response = requests.get( url )\n",
    "response.raise_for_status( )\n",
    "wav_data = response.content\n",
    "encoded_string = base64.b64encode( wav_data ).decode( 'utf-8' )\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4o-audio-preview',\n",
    "    modalities=['text', 'audio'],\n",
    "    audio={'voice': 'alloy', 'format': 'wav'},\n",
    "    messages= [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content':\n",
    "\t        [\n",
    "                {\n",
    "                    'text': 'text',\n",
    "                    'text': 'What is in this recording?'\n",
    "                },\n",
    "                {\n",
    "                    'text': 'input_audio',\n",
    "                    'input_audio':\n",
    "                    {\n",
    "                        'target_values': encoded_string,\n",
    "                        'format': 'wav'\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "    ] )\n",
    "\n",
    "print( completion.choices[0].message )"
   ],
   "id": "ff4df0c38ea5ead5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Embedding API\n",
    "- An embedding is a vector (list) of floating point numbers.\n",
    "- The distance between two vectors measures their relatedness.\n",
    "- Small distances suggest high relatedness and large distances suggest low relatedness.\n",
    "\n",
    "##### Use Cases:\n",
    "\n",
    "- **Search** (where results are ranked by relevance to a query string)\n",
    "- **Clustering** (where text strings are grouped by similarity)\n",
    "- **Recommendations** (where items with related text strings are recommended)\n",
    "- **Anomaly Detection** (where outliers with little relatedness are identified)\n",
    "- **Diversity Measurement** (where similarity distributions are analyzed)\n",
    "- **Classification** (where text strings are classified by their most similar label)\n",
    "___"
   ],
   "id": "7ecffb684060df94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Count Tokens",
   "id": "a2ff5b7df575e1be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )"
   ],
   "id": "9ecd67de74d5960c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def num_tokens_from_string( text: str, coding: str ) -> int:\n",
    "    '''\n",
    "\n",
    "        Purpose:\n",
    "            Returns the num of words in a documents path.\n",
    "\n",
    "        Parameters:\n",
    "            text: str - The string that is tokenized\n",
    "            coding: str - The encoding to use for tokenizing\n",
    "\n",
    "        Returns:\n",
    "            int - The number of words\n",
    "\n",
    "    '''\n",
    "    encoding = tiktoken.get_encoding( coding )\n",
    "    num_tokens = len( encoding.encode( text ) )\n",
    "    return num_tokens"
   ],
   "id": "3dcea04acd23f7ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "num_tokens_from_string( 'tiktoken is great!', 'cl100k_base' )",
   "id": "c525ff58eb96cd50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Ada\n",
   "id": "a4f429ca2743667b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "client.embeddings.create(\n",
    "\tmodel='text-embedding-ada-002',\n",
    "\tinput='The food was delicious and the waiter...',\n",
    "\tencoding_format='float' )\n"
   ],
   "id": "54c2a485229eafbd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Small",
   "id": "98361c6f6abe52da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create VectorStore\n",
    "def get_embedding( text, model='text-embedding-3-small' ):\n",
    "    prebed = text.replace( '\\n', ' ' )\n",
    "    return client.embeddings.create( input = [ prebed ], model=model ).data[ 0 ].embedding\n"
   ],
   "id": "3061464802458c8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Large",
   "id": "b23c885f58c6f013"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create VectorStore\n",
    "def get_embedding( text, model='text-embedding-3-large' ):\n",
    "    text = text.replace( '\\n', ' ' )\n",
    "    return client.embeddings.create( input=[ text ], model=model ).data[ 0 ].embedding"
   ],
   "id": "95fdc9789c21b06d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Reduce Dimensions\n",
    "- Dynamically changing the dimensions enables very flexible usage.\n",
    "- When using a vector data store that only supports embeddings up to 1024 dimensions long, developers can now still use our best embedding model text-embedding-3-large and specify a value of 1024 for the dimensions API parameter, which will shorten the embedding down from 3072 dimensions, trading off some accuracy in exchange for the smaller vector size."
   ],
   "id": "840859314d40ae52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def normalize_l2( x ):\n",
    "    x = np.array( x )\n",
    "    if x.ndim == 1:\n",
    "        norm = np.linalg.norm( x )\n",
    "        if norm == 0:\n",
    "            return x\n",
    "        return x / norm\n",
    "    else:\n",
    "        norm = np.linalg.norm( x, 2, axis=1, keepdims=True )\n",
    "        return np.where( norm == 0, x, x / norm )\n",
    "\n",
    "\n",
    "response = client.embeddings.create( model='text-embedding-3-small',\n",
    "\tinput='Testing 123', encoding_format='float' )\n",
    "\n",
    "cut_dim = response.data[ 0 ].embedding[ :256 ]\n",
    "norm_dim = normalize_l2( cut_dim )\n",
    "\n",
    "print( norm_dim )\n"
   ],
   "id": "3079893de107cb1f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Q-&-A\n",
    "- There are many common cases where the model is not trained on data which contains key facts and information you want to make accessible when generating responses to a user query.\n",
    "- One way of solving this, as shown below, is to put additional information into the context window of the model.\n",
    "- This is effective in many use cases but leads to higher token costs."
   ],
   "id": "1615ab8f676a9b76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Query\n",
    "query = f'''\n",
    "\n",
    "\tUse the below article on the 2022 Winter Olympics to answer the subsequent prompt.\n",
    "\tIf the answer cannot be found, write 'I don't know.'\n",
    "\n",
    "\tArticle:\n",
    "\t\\'\\'\\'\n",
    "\t{wikipedia_article_on_curling}\n",
    "\t\\'\\'\\'\n",
    "\n",
    "\tQuestion: Which athletes won the gold medal in curling at the 2022 Winter Olympics?\n",
    "\n",
    "'''\n",
    "\n",
    "# Create GptResponse\n",
    "response = client.chat.completions.create(\n",
    "    messages= [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': system_instructions\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': user_propmt\n",
    "    }, ],\n",
    "    model=GPT_MODEL,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print( response.choices[0].message.content )"
   ],
   "id": "11c37f28d0d201c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Text Search\n",
    "- Retrieves the most relevant documents.\n",
    "- Uses the cosine similarity between the embedding vectors of the query and each document.\n",
    " - Returns the highest scored documents.\n"
   ],
   "id": "4e983a4b52e48a8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def search_reviews( df, product_description, n=3, pprint=True ):\n",
    "    embedding = get_embedding( product_description, model='text-embedding-3-small' )\n",
    "    df[ 'similarities'] = df.ada_embedding.apply( lambda x: cosine_similarity( x, embedding ) )\n",
    "    res = df.sort_values( 'similarities', ascending=False).head( n )\n",
    "    return res\n",
    "\n",
    "res = search_reviews( df, 'delicious beans', n=3 )\n"
   ],
   "id": "71e57c9623ea351e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Code Search\n",
    "- Code search works similarly to embedding-based text search.\n",
    "- We provide a method to extract Python functions from all the Python files in a given repository.\n",
    "- Each function is then indexed by the `text-embedding-3-small` model.\n"
   ],
   "id": "847167aa109c8e7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "df[ 'code_embedding' ] = df[ 'code' ].apply( lambda x: get_embedding(x, model='text-embedding-3-small' ) )\n",
    "\n",
    "def search_functions( df, code_query, n=3, pprint=True, n_lines=7 ):\n",
    "    embedding = get_embedding(code_query, model='text-embedding-3-small')\n",
    "    df['similarities'] = df.code_embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = df.sort_values('similarities', ascending=False).head(n)\n",
    "    return res\n",
    "\n",
    "res = search_functions( df, 'Completions API tests', n=3 )\n"
   ],
   "id": "cf85848ee4956f79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Recommendation\n",
    "- Shorter distances between embedding vectors represent greater similarity,"
   ],
   "id": "96281a7b515e074b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )"
   ],
   "id": "1bfbfc6ac7a982cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def recommendations_from_strings( strings: List[str], index_of_source_string: int,\n",
    "    model='path-embedding-3-small' ) -> List[int]:\n",
    "    '''Return nearest neighbors of a given path.'''\n",
    "    # get vectors for all strings\n",
    "    embeddings = [ embedding_from_string( string, model=model ) for string in strings ]\n",
    "\n",
    "    # get the embedding of the source path\n",
    "    query_embedding = embeddings[ index_of_source_string ]\n",
    "    distances = distances_from_embeddings( query_embedding, embeddings, distance_metric='cosine' )\n",
    "\n",
    "    # get indices of nearest neighbors (function from embeddings_utils.py)\n",
    "    indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances( distances )\n",
    "    return indices_of_nearest_neighbors"
   ],
   "id": "3fa0e9699a613991"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Text Featurization\n",
    "- An embedding can be used as a general free-text feature encoder within a machine learning model.\n",
    "- Incorporating embeddings will improve the performance of any machine learning model, if some of the relevant inputs are free text.\n",
    "- An embedding can also be used as a categorical feature encoder within a ML model."
   ],
   "id": "bd79bebf3104d4fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "data = list( df.ada_embedding.target_values )\n",
    "X_train, X_test, y_train, y_test = train_test_split( data, df.Score, test_size=0.2, random_state=42 )\n"
   ],
   "id": "4773339d7f7e7e46"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pincone Embeddings",
   "id": "ded48a744761bafe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Building the Knowledge Base",
   "id": "a841ca9cb72a7fce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = load_dataset( 'wikipedia', '20220301.simple', split='train[:10000]', trust_remote_code=True)\n",
    "data"
   ],
   "id": "f453aae304467363"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Every record contains *a lot* of text. Our first task is therefore to identify a good preprocessing methodology for chunking these articles into more 'concise' chunks to later be embedding and stored in our Pinecone vector database.\n",
    "\n",
    "- For this we use LangChain's `RecursiveCharacterTextSplitter` to split our text into chunks of a specified max length."
   ],
   "id": "a4169599f33ce42e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tiktoken.encoding_for_model( 'gpt-3.5-turbo' )\n",
    "tokenizer = tiktoken.get_encoding( 'cl100k_base' )"
   ],
   "id": "61aab25f6507d19b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create_small_embedding the min function\n",
    "def tiktoken_len( text ):\n",
    "    tokens = tokenizer.encode( text, disallowed_special=( ) )\n",
    "    return len( tokens )"
   ],
   "id": "5347f3f98ea0450b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tiktoken_len( 'hello I am a chunk of path and using the tiktoken_len function '\n",
    "             'we can find the min of this chunk of path in words' )"
   ],
   "id": "a2debe9224868fd0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=20,\n",
    "    length_function=tiktoken_len,\n",
    "    separators=['\\n\\n', '\\n', ' ', '']\n",
    ")"
   ],
   "id": "ce79e2cc7a4cd709"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "chunks = text_splitter.split_text( data[ 6 ][ 'path' ] )[ :3 ]\n",
    "chunks"
   ],
   "id": "5f41ceefe534bf24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tiktoken_len( chunks[ 0 ] ), tiktoken_len( chunks[ 1 ] ), tiktoken_len( chunks[ 2 ] )",
   "id": "38951a615eade238"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creating Embeddings",
   "id": "af76ada1a5f262"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get openai api key from platform.openai.com\n",
    "OPENAI_API_KEY = os.getenv( 'OPENAI_API_KEY' )\n",
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "embed = OpenAIEmbeddings( model=model_name, openai_api_key=OPENAI_API_KEY )\n",
    "texts = [ 'this is the first chunk of path',  'then another second chunk of path is here' ]\n",
    "\n",
    "res = embed.embed_documents( texts )\n",
    "len( res ), len( res[ 0 ] )"
   ],
   "id": "f4d9c963c1fad5ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Use Vector Database\n",
   "id": "f22b60aeb15e2471"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# initialize connection to pinecone\n",
    "api_key = os.getenv( 'PINECONE_API_KEY' )\n",
    "\n",
    "# configure client\n",
    "pc = Pinecone( api_key=api_key )"
   ],
   "id": "69360330d85a1cbf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Now we setup our index specification, this allows us to define the cloud provider and region where we want to deploy our index.",
   "id": "1d4e547d946666d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "spec = ServerlessSpec(  cloud='aws', region='us-east-1' )",
   "id": "b215c64dc5949d1e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Then we initialize the index. We will be using OpenAI's `text-embedding-ada-002` model for creating the embeddings, so we set the `dimension` to `1536`.",
   "id": "7302d11f2cc99a59"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "index_name = 'langchain-retrieval-augmentation'\n",
    "existing_indexes = [ index_info[ 'name' ] for index_info in pc.list_indexes( ) ]\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in existing_indexes:\n",
    "    # if does not exist, create_small_embedding index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=1536,\n",
    "        metric='dotproduct',\n",
    "        spec=spec\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index( index_name ).status[ 'ready' ]:\n",
    "        time.sleep( 1 )\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index( index_name )\n",
    "time.sleep( 1 )\n",
    "\n",
    "# view index stats\n",
    "index.describe_index_stats( )"
   ],
   "id": "a984b78d3d2235b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Indexing\n",
   "id": "76725c285ad5e204"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "batch_limit = 100\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "for i, record in enumerate( tqdm( data ) ):\n",
    "\n",
    "    # first get metadata columns for this record\n",
    "    metadata = {\n",
    "        'wiki-id': str(record['id']),\n",
    "        'source': record['url'],\n",
    "        'title': record['title']\n",
    "    }\n",
    "\n",
    "    # now we create_small_embedding chunks from the record path\n",
    "    record_texts = text_splitter.split_text(record['path'])\n",
    "\n",
    "    # create_small_embedding individual metadata dicts for each chunk\n",
    "    record_metadatas = [{\n",
    "        'chunk': j, 'path': text, **metadata\n",
    "    } for j, text in enumerate(record_texts)]\n",
    "\n",
    "    # append these to current batches\n",
    "    texts.extend(record_texts)\n",
    "    metadatas.extend(record_metadatas)\n",
    "\n",
    "    # if we have reached the batch_limit we can add words\n",
    "    if len(texts) >= batch_limit:\n",
    "        ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "        embeds = embed.embed_documents(texts)\n",
    "        index.upsert(vectors=zip(ids, embeds, metadatas))\n",
    "        texts = []\n",
    "        metadatas = []\n",
    "\n",
    "if len(texts) > 0:\n",
    "    ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "    embeds = embed.embed_documents(texts)\n",
    "    index.upsert(vectors=zip(ids, embeds, metadatas))"
   ],
   "id": "30760236256ac3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- We've now indexed everything. We can check the number of vectors in our index like so:",
   "id": "e6f020e2e3e75a48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "index.describe_index_stats( )",
   "id": "12a8e80e4e1850c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Creating and Querying a Vector Store\n",
    "\n",
    "- Now that we've build our index we can switch back over to LangChain. We start by initializing a vector store using the same index we just built. We do that like so:\n"
   ],
   "id": "b9f9e523094c0915"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# the metadata field that contains our path\n",
    "text_field = 'path'\n",
    "\n",
    "# initialize the vector store object\n",
    "vectorstore = Pinecone(\n",
    "\tindex, embed.embed_query, text_field\n",
    ")\n",
    "query = 'who was Benito Mussolini?'\n",
    "\n",
    "vectorstore.similarity_search(\n",
    "\tquery,  # our search query\n",
    "\tk=3  # return 3 most relevant docs\n",
    ")"
   ],
   "id": "6ee34086ec495531"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generative Q & A\n",
    "\n",
    "- In GQA we take the query as a question that is to be answered by a LLM, but the LLM must answer the question based on the information it is seeing being returned from the `vectorstore`.\n",
    "- To do this we initialize a `RetrievalQA` object like so:"
   ],
   "id": "35f6a512171d5191"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# completion llm\n",
    "llm = ChatOpenAI( openai_api_key=OPENAI_API_KEY, model_name='gpt-3.5-turbo', temperature=0.0 )\n",
    "qa = RetrievalQA.from_chain_type( llm=llm, chain_type='stuff',\n",
    "\tretriever=vectorstore.as_retriever( ) )\n",
    "\n",
    "qa.run( query )"
   ],
   "id": "3b7e0e959d0b103f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " - We can do this using a slightly different version of `RetrievalQA` called `RetrievalQAWithSourcesChain`:",
   "id": "3928cd8fd77c565c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type( llm=llm, chain_type='stuff',\n",
    "    retriever=vectorstore.as_retriever( ) )\n",
    "\n",
    "qa_with_sources( query )"
   ],
   "id": "2dc5fe5faf94def9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Now we answer the question being asked, *and* return the source of this information being used by the LLM.\n",
    "- Delete index when complete"
   ],
   "id": "fa9479ee638964f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pc.delete_index( index_name )",
   "id": "57bb624446c07e63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "60d6b91e3e975bfc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Define Embedding Function",
   "id": "51eb7ff92bf29300"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def embed_texts( texts, model='text-embedding-3-small', batch_size=10, sleep=1 ):\n",
    "\t# Create Client\n",
    "\tclient = OpenAI( )\n",
    "\tclient.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\tembeddings = [ ]\n",
    "\tfor i in range( 0, len( texts ), batch_size ):\n",
    "\t\tbatch = texts[ i:i + batch_size ]\n",
    "\t\ttry:\n",
    "\t\t\tresponse = client.embeddings.create( input=batch, model=model )\n",
    "\t\t\tbatch_embeddings = [ e.embedding for e in response.data ]\n",
    "\t\t\tembeddings.extend( batch_embeddings )\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint( f'Error at batch {i}: {e}' )\n",
    "\t\t\t# Retry or sleep to avoid rate limits\n",
    "\t\t\ttime.sleep( sleep )\n",
    "\t\t\tcontinue\n",
    "\treturn embeddings"
   ],
   "id": "da73e5be4dc7dd3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. Embed Chunks",
   "id": "e5b7bcd6dd3902f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "embeddings = embed_texts( chunks )",
   "id": "9348ebd98a9c3507"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "####  3. Create DataFrame",
   "id": "6101a8334f1e2329"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_embeddings = pd.DataFrame( { chunks, embeddings } )",
   "id": "91adef5a83231057"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4. Save To Vector Store",
   "id": "bed88c5c91432c1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_embeddings.to_parquet( 'public_law_118_32_embeddings.parquet', index=False )",
   "id": "4c190d7c9dcd8df8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5. Preview",
   "id": "fcd1d7a8ec75c9ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_embeddings.head( 2 )",
   "id": "13a19772c6d9d267"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###  Sentence Embeddings\n",
    "- Use a language model (e.g., OpenAI, HuggingFace) to create vector representations of each chunk_words."
   ],
   "id": "7ddb05f69f495373"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 1. Path Definitions",
   "id": "a2e207452b927d0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "TEXT_FILE = 'PublicLaw_118-42.txt'\n",
    "DB_FILE = 'law_embeddings.target_values'\n",
    "EMBEDDING_MODEL = 'all-MiniLM-L6-v2'\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200"
   ],
   "id": "23fdaf60787b467c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### 2. Use Sentence Transformer\n",
    "- Embed chunks from above using sentence transformer"
   ],
   "id": "8fc49a8e385c2545"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = SentenceTransformer( 'all-MiniLM-L6-v2' )\n",
    "embeddings = model.encode( chunks, show_progress_bar=True )"
   ],
   "id": "a5065bf499134f63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### 3. Embed Sentence\n",
    "- Function Definition"
   ],
   "id": "4adda4f1be750a2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def embed_with_sentence_transformers( texts, model ):\n",
    "\treturn model.encode( texts, show_progress_bar=True, convert_to_numpy=True )"
   ],
   "id": "54cc79b86cd6a19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "local_embeddings = embed_with_sentence_transformers( chunks, model )",
   "id": "eb38674370746625"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 4. Save in a DataFrame",
   "id": "db654335853f65cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_local = pd.DataFrame(\n",
    "{\n",
    "\t'chunk_words': chunks,\n",
    "\t'embedding': list( local_embeddings )\n",
    "} )"
   ],
   "id": "a67fb6579159135"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 5. Create SQLite DB",
   "id": "e2e6a482d92a459"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "conn = sqlite3.connect( 'vectors.target_values' )\n",
    "cursor = conn.cursor( )\n",
    "sql_create = '''\n",
    "CREATE TABLE IF NOT EXISTS Law_Embeddings\n",
    "(\n",
    "    Id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Chunk_Tokens TEXT NOT NULL,\n",
    "    Embedding BLOB NOT NULL\n",
    ")\n",
    "'''\n",
    "\n",
    "cursor.execute( sql_create )\n",
    "\n",
    "for chunk, vector in zip( chunks, embeddings ):\n",
    "\tblob = pickle.dumps( vector )\n",
    "\tcursor.execute( 'INSERT INTO Law_Embeddings ( Chunk_Tokens, Embedding ) VALUES (?, ?)',\n",
    "\t\t(chunk, blob) )\n",
    "\n",
    "conn.commit( )\n",
    "conn.close( )"
   ],
   "id": "ddb630773045eb30"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 5. OpenAI Client",
   "id": "5771680a9f5509d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )"
   ],
   "id": "6b4a498330aec36a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### 6. Get Embedding\n",
    "- Function Definition"
   ],
   "id": "fb57feb283248a25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_embedding( text, model=OPENAI_MODEL ):\n",
    "\tresponse = client.Embedding.generate_text( input=text, model=model )\n",
    "\treturn response[ 'target_values'[ 0 ][ 'embedding' ] ]"
   ],
   "id": "c11b835cb5507a7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### 7. Embed Chunks\n",
    "- Function Definition"
   ],
   "id": "aa852dd9a6b96a93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def embed_chunks( chunks ):\n",
    "\tembeddings = [ ]\n",
    "\tfor chunk in tqdm( chunks, desc='EmbeddingRequest chunks via OpenAI' ):\n",
    "\t\ttry:\n",
    "\t\t\tembedding = get_embedding( chunk )\n",
    "\t\t\tembeddings.append( embedding )\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint( f'Error embedding chunk_words: {e}' )\n",
    "\t\t\tembeddings.append( [ 0.0 ] * 1536 )  # Placeholder for failed requests\n",
    "\treturn embeddings\n"
   ],
   "id": "947d623c8ddd5e01"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### 8. Create SQLite DB\n",
    "- Function Definition"
   ],
   "id": "bb547c630b6afe55"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_sqlite_db( chunks, embeddings, db_path ):\n",
    "\tconn = sqlite3.connect( db_path )\n",
    "\tcursor = conn.cursor( )\n",
    "\tsql_create = '''\n",
    "    CREATE TABLE IF NOT EXISTS Law_Embeddings\n",
    "    (\n",
    "        Id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        Chunk_Tokens TEXT NOT NULL,\n",
    "        Embedding BLOB NOT NULL\n",
    "    )\n",
    "    '''\n",
    "\n",
    "\tcursor.execute( sql_create )\n",
    "\tfor chunk, vector in zip( chunks, embeddings ):\n",
    "\t\tblob = pickle.dumps( vector )\n",
    "\t\tsql_insert = 'INSERT INTO Law_Embeddings ( Chunk_Tokens, Embedding ) VALUES ( ?, ? )'\n",
    "\t\tcursor.execute( sql_insert, (chunk, blob) )\n",
    "\n",
    "\tconn.commit( )\n",
    "\tconn.close( )"
   ],
   "id": "6888774ee7526322"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Final Script Example",
   "id": "91a850a970398c45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === MAIN ===\n",
    "def main( ):\n",
    "\tprint( 'Step 1: Load and clean documents' )\n",
    "\tcleaned_text = load_and_clean_text( TEXT_FILE )\n",
    "\n",
    "\tprint( 'Step 2: Chunking documents' )\n",
    "\tchunks = chunk_text( cleaned_text )\n",
    "\tprint( f'Total chunks: {len( chunks )}' )\n",
    "\n",
    "\tprint( 'Step 3: EmbeddingRequest with OpenAI API' )\n",
    "\tembeddings = embed_chunks( chunks )\n",
    "\n",
    "\tprint( 'Step 4: Saving to SQLite' )\n",
    "\tcreate_sqlite_db( chunks, embeddings, DB_FILE )\n",
    "\n",
    "\tprint( f'Pipeline complete. Embeddings stored in: {DB_FILE}' )"
   ],
   "id": "270c22020ca8fa3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Embedding Wikipedia articles for search\n",
    "##### Procedure:\n",
    "\n",
    "-  Import libraries, set API key (if needed)\n",
    "-  Collect: We download a few hundred Wikipedia articles about the 2022 Olympics\n",
    "-  Chunk: Documents are split into short, semi-self-contained sections to be embedded\n",
    "-  Embed: Each section is embedded with the OpenAI API\n",
    "-  Store: Embeddings are saved in a CSV file (for large datasets, use a vector database)"
   ],
   "id": "2d9a327090eea610"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 1. Collect documents\n",
    "- In this example, we'll download a few hundred Wikipedia articles related to the 2022 Winter Olympics."
   ],
   "id": "654daf8b357e7fba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "CATEGORY_TITLE = 'Category:2022 Winter Olympics'\n",
    "WIKI_SITE = 'en.wikipedia.org'\n",
    "\n",
    "\n",
    "def titles_from_category( category: mwclient.listing.Category, max_depth: int ) -> set[ str ]:\n",
    "\t'''\n",
    "\n",
    "\t\tReturn a pairs of page titles in a given Wiki category and its subcategories.\n",
    "\n",
    "\t'''\n",
    "\ttitles = set( )\n",
    "\tfor cm in category.members( ):\n",
    "\t\tif type( cm ) == mwclient.page.Page:\n",
    "\t\t\t# ^scaler() used instead of isinstance() to catch match w/ no inheritance\n",
    "\t\t\ttitles.add( cm.name )\n",
    "\t\telif isinstance( cm, mwclient.listing.Category ) and max_depth > 0:\n",
    "\t\t\tdeeper_titles = titles_from_category( cm, max_depth=max_depth - 1 )\n",
    "\t\t\ttitles.update( deeper_titles )\n",
    "\treturn titles\n",
    "\n",
    "\n",
    "site = mwclient.Site( WIKI_SITE )\n",
    "category_page = site.pages[ CATEGORY_TITLE ]\n",
    "titles = titles_from_category( category_page, max_depth=1 )\n",
    "# ^note: max_depth=1 means we go one level deep in the category tree\n",
    "print( f'Found {len( titles )} article titles in {CATEGORY_TITLE}.' )"
   ],
   "id": "7b14fad95821b8f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2. Document Prep & Definitions\n",
    "\n",
    "##### Now that we have our reference documents, we need to prepare them for search. Because GPT can only read a limited amount of text at once, we'll split each document into chunks short enough to be read. For this specific example on Wikipedia articles, we'll:\n",
    "- Discard less relevant-looking sections like External Links and Footnotes\n",
    "- Clean up the text by removing reference tags (e.g., <ref>), whitespace, and super short sections\n",
    "- Split each article into sections\n",
    "- Prepend titles and subtitles to each section's text, to help GPT understand the context\n",
    "- If a section is long (say, > 1,600 tokens), we'll recursively split it into smaller sections, trying to split along semantic boundaries like paragraphs"
   ],
   "id": "6289f51ef185f65e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# define functions to split Wikipedia pages into sections\n",
    "\n",
    "SECTIONS_TO_IGNORE = [\n",
    "\t'See also',\n",
    "\t'References',\n",
    "\t'External links',\n",
    "\t'Further reading',\n",
    "\t'Footnotes',\n",
    "\t'Bibliography',\n",
    "\t'Sources',\n",
    "\t'Citations',\n",
    "\t'Literature',\n",
    "\t'Footnotes',\n",
    "\t'Notes and references',\n",
    "\t'Photo gallery',\n",
    "\t'Works cited',\n",
    "\t'Photos',\n",
    "\t'Gallery',\n",
    "\t'Notes',\n",
    "\t'References and sources',\n",
    "\t'References and notes',\n",
    "]\n",
    "\n",
    "\n",
    "def all_subsections_from_section(\n",
    "\tsection: mwparserfromhell.wikicode.Wikicode,\n",
    "\tparent_titles: list[ str ],\n",
    "\tsections_to_ignore: set[ str ] ) -> list[ tuple[ list[ str ], str ] ]:\n",
    "\t'''\n",
    "\n",
    "        From a Wikipedia section, return a flattened list of all nested subsections.\n",
    "        Each subsection is a tuple, where:\n",
    "            - the first element is a list of parent subtitles, starting with the page title\n",
    "            - the second element is the pages of the subsection (but not any children)\n",
    "\n",
    "    '''\n",
    "\theadings = [ str( h ) for h in section.filter_headings( ) ]\n",
    "\ttitle = headings[ 0 ]\n",
    "\tif title.strip( '=' + ' ' ) in sections_to_ignore:\n",
    "\t\t# ^wiki headings are wrapped like '== Heading =='\n",
    "\t\treturn [ ]\n",
    "\ttitles = parent_titles + [ title ]\n",
    "\tfull_text = str( section )\n",
    "\tsection_text = full_text.split( title )[ 1 ]\n",
    "\tif len( headings ) == 1:\n",
    "\t\treturn [ (titles, section_text) ]\n",
    "\telse:\n",
    "\t\tfirst_subtitle = headings[ 1 ]\n",
    "\t\tsection_text = section_text.split( first_subtitle )[ 0 ]\n",
    "\t\tresults = [ (titles, section_text) ]\n",
    "\t\tfor subsection in section.get_sections( levels=[ len( titles ) + 1 ] ):\n",
    "\t\t\tresults.extend( all_subsections_from_section( subsection, titles, sections_to_ignore ) )\n",
    "\t\treturn results\n",
    "\n",
    "\n",
    "def all_subsections_from_title(\n",
    "\ttitle: str,\n",
    "\tsections_to_ignore: set[ str ]=SECTIONS_TO_IGNORE,\n",
    "\tsite_name: str=WIKI_SITE ) -> list[ tuple[ list[ str ], str ] ]:\n",
    "\t'''\n",
    "\n",
    "        From a Wikipedia page title, return a flattened list of all nested subsections.\n",
    "        Each subsection is a tuple, where:\n",
    "            - the first element is a list of parent subtitles, starting with the page title\n",
    "            - the second element is the pages of the subsection (but not any children)\n",
    "\n",
    "    '''\n",
    "\tsite = mwclient.Site( site_name )\n",
    "\tpage = site.pages[ title ]\n",
    "\ttext = page.text( )\n",
    "\tparsed_text = mwparserfromhell.parse( text )\n",
    "\theadings = [ str( h ) for h in parsed_text.filter_headings( ) ]\n",
    "\tif headings:\n",
    "\t\tsummary_text = str( parsed_text ).split( headings[ 0 ] )[ 0 ]\n",
    "\telse:\n",
    "\t\tsummary_text = str( parsed_text )\n",
    "\tresults = [ ([ title ], summary_text) ]\n",
    "\tfor subsection in parsed_text.get_sections( levels=[ 2 ] ):\n",
    "\t\tresults.extend( all_subsections_from_section( subsection, [ title ], sections_to_ignore ) )\n",
    "\treturn results\n"
   ],
   "id": "52ea658099615029"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 3. Split pages into sections\n",
    "- may take ~1 minute per 100 articles"
   ],
   "id": "8f11b914415693e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "wikipedia_sections = [ ]\n",
    "for title in titles:\n",
    "\twikipedia_sections.extend( all_subsections_from_title( title ) )\n",
    "print( f'Found {len( wikipedia_sections )} sections in {len( titles )} pages.' )"
   ],
   "id": "133406944e17e981"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4. Clean pages",
   "id": "96905fc45df8e87a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# clean pages\n",
    "def clean_section( section: tuple[ list[ str ], str ] ) -> tuple[ list[ str ], str ]:\n",
    "\t'''\n",
    "\n",
    "        Return a cleaned_lines up section with:\n",
    "            - <ref>xyz</ref> patterns removed\n",
    "            - leading/trailing whitespace removed\n",
    "\n",
    "    '''\n",
    "\ttitles, text = section\n",
    "\ttext = re.sub( r'<ref.*?</ref>', '', text )\n",
    "\ttext = text.strip( )\n",
    "\treturn (titles, text)\n",
    "\n",
    "wikipedia_sections = [ clean_section( ws ) for ws in wikipedia_sections ]\n",
    "\n"
   ],
   "id": "24657f5793a245b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5. Filter-out blank sections",
   "id": "2587197f65f18c74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# filter out short/blank sections\n",
    "def keep_section( section: tuple[ list[ str ], str ] ) -> bool:\n",
    "\t'''\n",
    "\n",
    "        Return True if the section should be kept, False otherwise.\n",
    "\n",
    "    '''\n",
    "\ttitles, text = section\n",
    "\tif len( text ) < 16:\n",
    "\t\treturn False\n",
    "\telse:\n",
    "\t\treturn True\n",
    "\n",
    "original_num_sections = len( wikipedia_sections )\n",
    "wikipedia_sections = [ ws for ws in wikipedia_sections if keep_section( ws ) ]\n",
    "print(\n",
    "\tf'Filtered out {original_num_sections - len( wikipedia_sections )} sections, leaving {len( wikipedia_sections )} sections.' )\n",
    "\n",
    "\n",
    "for ws in wikipedia_sections[ :5 ]:\n",
    "\tprint( ws[ 0 ] )\n",
    "\tdisplay( ws[ 1 ][ :77 ] + '...' )\n",
    "\tprint( )"
   ],
   "id": "a285d2b14b956e0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 6. Recursively split long sections\n",
    "##### Tradeoffs include:\n",
    "- Longer sections may be better for questions that require more context\n",
    "- Longer sections may be worse for retrieval, as they may have more topics muddled together\n",
    "- Shorter sections are better for reducing costs (which are proportional to the number of tokens)\n",
    "- Shorter sections allow more sections to be retrieved, which may help with recall\n",
    "- Overlapping sections may help prevent answers from being cut by section boundaries"
   ],
   "id": "24d735005a5bbd83"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " We limit sections to 1,600 tokens each, recursively halving any sections that are too long. To avoid cutting in the middle of useful sentences, we'll split along paragraph boundaries when possible.",
   "id": "d392fa7e905f534f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "GPT_MODEL = 'gpt-4o-mini'\n",
    "\n",
    "\n",
    "def num_tokens( text: str, modeal: str = GPT_MODEL ) -> int:\n",
    "\t'''Return the num of words in a path.'''\n",
    "\tencoding = tiktoken.encoding_for_model( model )\n",
    "\treturn len( encoding.encode( text ) )\n",
    "\n",
    "\n",
    "def halved_by_delimiter( string: str, delimiter: str = '\\n' ) -> list[ str, str ]:\n",
    "\t'''\n",
    "\n",
    "\t\tSplit a path in two, on a delimiter, trying to balance words on each side.\n",
    "\n",
    "\t'''\n",
    "\tchunks = string.split( delimiter )\n",
    "\tif len( chunks ) == 1:\n",
    "\t\treturn [ string, '' ]  # no delimiter found\n",
    "\telif len( chunks ) == 2:\n",
    "\t\treturn chunks  # no need to search for halfway point\n",
    "\telse:\n",
    "\t\ttotal_tokens = num_tokens( string )\n",
    "\t\thalfway = total_tokens // 2\n",
    "\t\tbest_diff = halfway\n",
    "\t\tfor i, chunk in enumerate( chunks ):\n",
    "\t\t\tleft = delimiter.join( chunks[ : i + 1 ] )\n",
    "\t\t\tleft_tokens = num_tokens( left )\n",
    "\t\t\tdiff = abs( halfway - left_tokens )\n",
    "\t\t\tif diff >= best_diff:\n",
    "\t\t\t\tbreak\n",
    "\t\t\telse:\n",
    "\t\t\t\tbest_diff = diff\n",
    "\t\tleft = delimiter.join( chunks[ :i ] )\n",
    "\t\tright = delimiter.join( chunks[ i: ] )\n",
    "\t\treturn [ left, right ]\n",
    "\n",
    "\n",
    "def truncated_string( string: str, model: str, max_tokens: int, print_warning: bool=True ) -> str:\n",
    "\t'''\n",
    "\n",
    "\t\tTruncate a path to a maximum num of words.\n",
    "\n",
    "\t'''\n",
    "\tencoding = tiktoken.encoding_for_model( model )\n",
    "\tencoded_string = encoding.encode( string )\n",
    "\ttruncated_string = encoding.decode( encoded_string[ :max_tokens ] )\n",
    "\tif print_warning and len( encoded_string ) > max_tokens:\n",
    "\t\tprint(\n",
    "\t\t\tf'Warning: Truncated path from {len( encoded_string )} words to {max_tokens} words.' )\n",
    "\treturn truncated_string\n",
    "\n",
    "\n",
    "def split_strings_from_subsection(\n",
    "\tsubsection: tuple[ list[ str ], str ],\n",
    "\tmodel: str = GPT_MODEL,\n",
    "\tmax: int=5 ) -> list[ str ]:\n",
    "\t'''\n",
    "\n",
    "        Split a subsection into a list of subsections, each with no more than max_tokens.\n",
    "        Each subsection is a tuple of parent titles [H1, H2, ...] and pages (str).\n",
    "\n",
    "    '''\n",
    "\ttitles, text = subsection\n",
    "\tstring = '\\n\\n'.join( titles + [ text ] )\n",
    "\tnum_tokens_in_string=num_tokens( string )\n",
    "\t# if min is fine, return path\n",
    "\tif num_tokens_in_string <= 10000:\n",
    "\t\treturn [ string ]\n",
    "\t# if recursion hasn't found a split after X iterations, just trunc\n",
    "\telif max == 0:\n",
    "\t\treturn [ truncated_string( string, model=model, max_tokens=10000 ) ]\n",
    "\t# otherwise, split in half and recurse\n",
    "\telse:\n",
    "\t\ttitles, text = subsection\n",
    "\t\tfor delimiter in [ '\\n\\n', '\\n', '. ' ]:\n",
    "\t\t\tleft, right = halved_by_delimiter( text, delimiter=delimiter )\n",
    "\t\t\tif left == '' or right == '':\n",
    "\t\t\t\t# if either half is empty, retry with a more fine-grained delimiter\n",
    "\t\t\t\tcontinue\n",
    "\t\t\telse:\n",
    "\t\t\t\t# recurse on each half\n",
    "\t\t\t\tresults = [ ]\n",
    "\t\t\t\tfor half in [ left, right ]:\n",
    "\t\t\t\t\thalf_subsection = (titles, half)\n",
    "\t\t\t\t\thalf_strings = split_strings_from_subsection(\n",
    "\t\t\t\t\t\thalf_subsection,\n",
    "\t\t\t\t\t\tmodel=model,\n",
    "\t\t\t\t\t\tmax = max - 1,\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\t\tresults.extend( half_strings )\n",
    "\t\t\t\treturn results\n",
    "\t# otherwise no split was found, so just trunc (should be very rare)\n",
    "\treturn [ truncated_string( string, model=model, max_tokens=10000 ) ]\n"
   ],
   "id": "940b0533cbd1194c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 7. Split Sections into Chunks",
   "id": "429464465d85877d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# split sections into chunks\n",
    "wikipedia_strings = [ ]\n",
    "for section in wikipedia_sections:\n",
    "\twikipedia_strings.extend( split_strings_from_subsection( section ) )\n",
    "\n",
    "print(\n",
    "\tf'{len( wikipedia_sections )} Wikipedia sections split into {len( wikipedia_strings )} strings.' )\n",
    "\n",
    "# print example df\n",
    "print( wikipedia_strings[ 1 ] )"
   ],
   "id": "7cf3ccdc0954bed1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 8. Embed document chunks",
   "id": "3676f9a6d1bc443b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "EMBEDDING_MODEL = 'path-embedding-3-small'\n",
    "BATCH_SIZE = 1000  # you can submit up to 2048 embedding inputs per request\n",
    "\n",
    "embeddings = [ ]\n",
    "for batch_start in range( 0, len( wikipedia_strings ), BATCH_SIZE ):\n",
    "\tbatch_end = batch_start + BATCH_SIZE\n",
    "\tbatch = wikipedia_strings[ batch_start:batch_end ]\n",
    "\tprint( f'Batch {batch_start} to {batch_end - 1}' )\n",
    "\tresponse = client.embeddings.create( model=EMBEDDING_MODEL, input=batch )\n",
    "\tfor i, be in enumerate( response.data ):\n",
    "\t\tassert i == be.index  # double check vectors are in same order as path\n",
    "\tbatch_embeddings = [ e.embedding for e in response.data ]\n",
    "\tembeddings.extend( batch_embeddings )\n",
    "\n",
    "df = pd.DataFrame( { 'pages': wikipedia_strings, 'embedding': embeddings } )"
   ],
   "id": "463ccd1620e1bc71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 9. Store document chunks and embeddings",
   "id": "f3ac9f168c4d58b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# save document chunks and vectors\n",
    "\n",
    "SAVE_PATH = 'data/winter_olympics_2022.csv'\n",
    "\n",
    "df.to_csv( SAVE_PATH, index=False )"
   ],
   "id": "e237b1d0e4774a89"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "88c2c1f6692b368c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9f958b736d227812"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Files API\n",
    "- Upload up to 100 pages and 32MB of total content in a single request to the API, across multiple file inputs.\n",
    "- Only models that support both text and image inputs, such as gpt-4o, gpt-4o-mini, or o1, can accept PDF files as input\n",
    "- Recommend using the user_data purpose for files you plan to use as model inputs.\n",
    "___"
   ],
   "id": "e3fde16f4a5c82b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Upload\n",
    "- Upload a PDF using the Files API, then reference its file ID in an API request to the model."
   ],
   "id": "72eab7cef4735604"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign vriables\n",
    "_messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'text': 'file',\n",
    "                    'file':\n",
    "\t                {\n",
    "                        'file_id': file.id,\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'text': 'documents',\n",
    "                    'documents': 'What is the first dragon in the book?',\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "]\n",
    "\n",
    "# Create GptFile Request\n",
    "file = client.files.create( file=open( 'draconomicon.pdf', 'rb' ), purpose='user_data' )\n",
    "completion = client.chat.completions.create( model='gpt-4o', messages=_messages, )\n",
    "\n",
    "print( completion.choices[ 0 ].message.content )"
   ],
   "id": "9e52a8aca5a53d62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### List",
   "id": "472bf604087b790d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T19:22:18.892507Z",
     "start_time": "2025-05-21T19:22:17.215594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "_files = client.files.list( purpose='assistants' )\n",
    "\n"
   ],
   "id": "6b8d7344b47cd3df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Agency Accounts.xlsx    file-PbR6gY9MNMMJSsg77raoyW\n",
      " Account Balances.xlsx    file-DAK6DZWLHg1Qt99C6bV4mB\n",
      " Budget Outlays.xlsx    file-5uh2DEwXryA9Wug1naZS2u\n",
      " Public Law 104-208.txt    file-WfshS2feYmoD7cPGrSAeQS\n",
      " Public Law 104-208.txt    file-Ht3sDtuyd2YnU1p98Mzay1\n",
      " Public Law 104-134.txt    file-BU78sMr95KdSpYiTRTAYB1\n",
      " Public Law 104-134.txt    file-88qb8RLq76hMeZabqySTuJ\n",
      " Public Law 104-134.txt    file-TNYw3LvqnXMGwxnJ9LYRfu\n",
      " Public Law 103-333.txt    file-LW222pMjM2mpVTxX7bqMW5\n",
      " House Report 103-533.txt    file-U2ggb6bxX5swP4QiWrGbKv\n",
      " House Report 111-366.txt    file-Bae54KTHWbe9SveSfTYxtK\n",
      " House Report 108-792.txt    file-19r5Dv7qgMtCcDfJyuqaJ3\n",
      " House Report 105-825.txt    file-PJLfrNi73QjzoR7qi9ZfTV\n",
      " House Report 108-10.txt    file-EK39VNriZWncsmvbtfAZRh\n",
      " House Report 106-479.txt    file-Gr7UH1xpaCZyVa562rRyG4\n",
      " House Report 104-863.txt    file-Co62meDn6MvwMLjbueKYFP\n",
      " House Report 108-401.txt    file-H4gxPdNDgzHbUkEVEPVDsq\n",
      " House Report 106-1033.txt    file-Y43m2GeM2caZXvHDz3R1YB\n",
      " House Report 112-331.txt    file-CV1hDWfupua9qjNbsKLk6J\n",
      " House Report 117-328.txt    file-BuuRXUtQPHBuXPfGYhxDF8\n",
      " House Report 110-497.txt    file-Av3S2Y3H93AGE53BjriVWa\n",
      " House Report 104-537.txt    file-P7K9oSrfXCU4qjyp6Zry2j\n",
      " Senate Report 109-141.txt    file-JExAnGQwEiERudHWo6XkGz\n",
      " Senate Report 109-293.txt    file-KP6gDdEzS38ykJSmueZhnk\n",
      " House Report 111-8.txt    file-RbmGk7JFtFEnJpaYmnWB1R\n",
      " Senate Report 106-298.txt    file-7Mbi5ccMZeEsDEwouXahWq\n",
      " House Report 107-350.txt    file-TtKaJ2Ay1vYU7ZM1mQEQrr\n",
      " House Report 107-593.txt    file-VT9LaVGJJLDA26wHa6hdmv\n",
      " House Report 106-371.txt    file-YDbtQcfMrVLgTBzSjMLAaa\n",
      " House Report 109-72.txt    file-AUawbvryqiPDUhE669S2L1\n",
      " House Report 111-427.txt    file-Sun7YBDubR8qFyenjeExHS\n",
      " House Report 109-272.txt    file-XPjz1KdXDzVojd29moBEW5\n",
      " House Report 111-105.txt    file-1ro3diUunEtHzntfyq4tdc\n",
      " House Report 114-113.txt    file-Aa9kguBYMvdG2HLMecCbSK\n",
      " House Report 108-55.txt    file-Er6S4u9kYsRB24D3xCC2pc\n",
      " House Report 118-83.txt    file-4oBnvjVsKnENZkAzEj2ZmM\n",
      " House Report 116-260.txt    file-JReR65r9a646JHwHCPrXWu\n",
      " House Report 115-141.txt    file-Y87U4abs4GpdHz51pB9ajK\n",
      " House Report 115-31.txt    file-RD2FeqQTumZrwaLcmA5Nk4\n",
      " House Report 117-103.txt    file-HiSFwCvB6bZkdogaBhYiG9\n",
      " House Report 113-6.txt    file-DkZ45Q594PpSN7BiGhAmAA\n",
      " House Report 116-6.txt    file-Vbr7BAtuac3uUPvHUJe5gM\n",
      " House Report 110-5.txt    file-CUr3z6AqYXHqCJCRbwGDQy\n",
      " House Report 118-42.txt    file-2wm8dB1SqGYYJLLdkiQ83c\n",
      " House Report 113-76.txt    file-AaYoRkEscFTzcwq1Qzrj4W\n",
      " House Report 116-93.txt    file-KaYezuKW6BF8s7EPZiTCGx\n",
      " House Report 113-235.txt    file-N8pp2bxPbmgfRzJKbfcVzH\n",
      " House Report 110-656.txt    file-1cvjDeWEkgz437GMU8k4eb\n",
      " House Report 106-110.txt    file-AeifsU2ZFGeP5DR9qfGEGX\n",
      " House Report 103-533.txt    file-F939jhWqGf2BMya2p2da2D\n",
      " Account Balances.xlsx    file-5DEW5xLHvztX2DKwtNYkF9\n",
      " Budget Outlays.xlsx    file-RuWxB8HnP6g6raz4Wz3crV\n",
      " Account Balances.xlsx    file-YGuiUsenE1CkyRbGEr33X3\n",
      " Resource Analysis.xlsx    file-UCshsfVPDqNaG62iqjsdyX\n",
      " Agency Accounts.xlsx    file-3kp6eLC7fermsCdoQxY3u6\n",
      " OMB Circular A-136 Financial Reporting Requirements.pdf    file-NDFM3eXgCzwCJua2S4VcLd\n",
      " OMB Circular A-76 Performance of Commercial Activities.pdf    file-QpyasRHujTab9iVo1Xpngc\n",
      " OMB Circular A-19 Legislative Coordination and Clearance.pdf    file-LdFRRgynGNvdzDiXFDdth9\n",
      " OMB Circular A-25 User Charges.pdf    file-JduhEwQ6FuXaNtMyNshVQC\n",
      " OMB Circular A-45 Rental and Construction of Government Quarters.pdf    file-J5AmDRZD7pNHNWgfg1NZ2p\n",
      " OMB Circular A-94 Discount Rates for Time-Distributed Costs and Benefits.pdf    file-HAjHRbA3yKGVrAa5skAJUL\n",
      " OMB Circular A-97 Services for State and Local Governments.pdf    file-NjSgVq7VdgE5sDzo22Wzm5\n",
      " Title 31 Code of Federal Regulations - Money And Finance.pdf    file-UJkM5ZjFbJJKFeoCsMitEc\n",
      " Title 2 Code of Federal Regulations - Uniform Administrative Requirements, Cost Principles, and Audit.pdf    file-RJei1CRLFTN5Av6HNJ4KNN\n",
      " Statements of Federal Federal Financial Accounting Concepts and Standards.pdf    file-SjfBCS82K9ZdKNXiLcfvdP\n",
      " budget_training.json    file-3TRNzqfydhBjoNRxva4PaZ\n",
      " The Anti-Deficiency Act PL 97-258.pdf    file-VcakEpzxkeeqbcF6nA8Whc\n",
      " OMB Circular A-11 Preparation Submission And Execution Of The Budget.pdf    file-6dbpYPJfCQsmci3QgMUfFh\n",
      " Federal Acquisition Regulation.pdf    file-X3vCnxwbv23D5c3Zp7577t\n",
      " The Balanced Budget and Emergency Deficit Control Act of 1985.pdf    file-JTYFKft6HCxYa1ToNa5hgh\n",
      " Government Invoicing User Guide.pdf    file-4ASUZ7HUF7zhL5DkkktDNR\n",
      " U.S. Standard General Ledger Accounts and Definitions.pdf    file-CCGkN4pqWbj5KMVEYfwGVC\n",
      " Supplemental Appropriation Act, 1955.pdf    file-JaJsLSnqvBqDEHtAgLdMeD\n",
      " Independent Offices Appropriation Act, 1953.pdf    file-TDwPiKBtDbpUmarr5xsUBP\n",
      " Federal Account Symbols And Titles Book.pdf    file-M9G2RiBqMwuiSMYLUA7bgf\n",
      " Principles Of Federal Appropriations Law Volume Two.pdf    file-FoVMTC8aQcUNddJP3PBx56\n",
      " Chief Financial Officers Act of 1990.pdf    file-6xgCoZT7gSyahZ7fD44X2H\n",
      " Principles Of Federal Appropriations Law Volume One.pdf    file-AaRuEtLZqTG6c8jwwi7mMH\n",
      " Federal Government Standards For Internal Controls.pdf    file-9AxctNCEJWGGURuzStfmet\n",
      " Code of Federal Regulations Title 31 - Money And Finance.pdf    file-K2qj7DsN2x2mgScoWhGkuo\n",
      " Government Performance and Results Act of 1993.pdf    file-UaUdtRYh6RZpkVQHbjQc8v\n",
      " Government Auditing Standards.pdf    file-J3L9moUJKaeufC7jXfY4XV\n",
      " OMB Circular A-123.pdf    file-QcSZmmvX22NpYNRhZoRZDe\n",
      " Inspector General Act of 1978.pdf    file-2vcPnxL8MFGu86wWsMZYZ2\n",
      " The Stafford Act.pdf    file-XqmQy8LFmeQUqTffxNq7EH\n",
      " Federal Trust Fund Accounting Guide.pdf    file-3nyVGBo599bddpeYY2Kc3s\n",
      " The Budget and Accounting Act of 1921.pdf    file-6hHvqUyVY78LaZBWnLPTto\n",
      " OMB Circular A-11 Section 120 Apportionment Process.pdf    file-CF3nMJwpQzpyVe5wpVnBQr\n",
      " Federal Managers Financial Integrity Act of 1982.pdf    file-8yTFektuuj3sEzEFkJMba7\n",
      " The Fiscal Responsibility Act of 2023.pdf    file-1ogQiUbSsoptngJzCXTWm1\n",
      " The Data Act.pdf    file-PEc3dwNfz2igmj7QCBWUd8\n",
      " The Economy Act of 1932.pdf    file-J9ZvMJjhnKRsgwfAq1A1xy\n",
      " The Anti-Deficiency Reform and Enforcement Act of 2018.pdf    file-BavYRPGXY6VDBvrxhJ5mwS\n",
      " The Budget Control Act.pdf    file-Gn6FB8opGDMfFioQeidSvL\n",
      " GPRA Modernization Act of 2010.pdf    file-XBKCzsmqCoNtj6KQG6JgNu\n",
      " OMB Circular A-11 Section 100 Sequestration.pdf    file-PXFser1tqXo6mKHkWmwpRe\n",
      " Public Law 116-260.txt    file-DsxiNWekLNYueM6nTwV4CT\n",
      " House Report 111-366.txt    file-3CJd51w1KneQyvmZAXk59M\n",
      " Public Law 117-328.txt    file-PVvwmHxFZGrSREoqEztK78\n",
      " House Report 108-792.txt    file-Ub46ThwaQNt3tnast9aVTS\n",
      " House Report 105-825.txt    file-E1wECXo43Tpy6L3ddQJfVs\n",
      " House Report 108-10.txt    file-JXHgawX52VQwy9tNTnRPj8\n",
      " House Report 104-863.txt    file-9H6gSV3Acn6JWuadASX5DM\n",
      " House Report 108-401.txt    file-QGKUnL4wr1voSzCJziDZ5F\n",
      " Public Law 117-103.txt    file-7Huja2YQ2fpDWKfuzWzM7b\n",
      " House Report 106-1033.txt    file-R5nUd38qngr1eDU3kWbraS\n",
      " House Report 106-479.txt    file-VfxAHitzmBwXjmEbEqYJgr\n",
      " Public Law 105-277.txt    file-RygDYKVzCAmJDzykTBT6cs\n",
      " Public Law 114-113.txt    file-DrVwCk4MSrKdgCBhenJmVj\n",
      " Public Law 115-141.txt    file-7FN63Y2e7TsgcSe9C7CbtV\n",
      " Public Law 104-208.txt    file-38eK1jakQRYYavep3qDQHr\n",
      " House Report 112-331.txt    file-W58KbNkrhBZxbBoxDQ2531\n",
      " Public Law 113-235.txt    file-MZsPTqB31rpeeRgYZKdo2j\n",
      " Public Law 106-554.txt    file-CAN6NoQA3pYKYdZMshH8Yk\n",
      " Public Law 115-31.txt    file-73a8CZuX5ZZThs4nW3g7or\n",
      " Public Law 106-113.txt    file-8XNRPmxwP1BCE5xkJTV9cY\n",
      " House Report 110-497.txt    file-KeB2KW5pBk2aWisVRR5HiB\n",
      " Public Law 113-76.txt    file-Q4x1MED4ZAG3n1spXen7oe\n",
      " Public Law 110-161.txt    file-Dv1KyWyJUHhmGRuKP1jRqe\n",
      " Public Law 108-7.txt    file-131PBGuAdCVd7dqsB9wx66\n",
      " House Report 104-537.txt    file-B5bsqL5BdXAnAULevq4oS5\n",
      " Public Law 112-74.txt    file-3yvYiQX28W7Hcn4JtJMgQZ\n",
      " Public Law 108-199.txt    file-7cux35RFBzjqz3AJLsu95d\n",
      " Public Law 116-6.txt    file-Cwn4d7JTzW7CSnNyVyvwJe\n",
      " Public Law 118-42.txt    file-DbcHVRnriJNgSR17i1Bytt\n",
      " Public Law 111-8.txt    file-PBgGUWk4Vt4yBBUjUzFyHo\n",
      " Public Law 111-117.txt    file-Ff7BcQBoHBu6yYhWixZ9Dh\n",
      " Public Law 104-134.txt    file-NLbzYUDptpi9U4m2iTehCe\n",
      " Senate Report 109-141.txt    file-QVV971KDp6kCKet1XRbZSP\n",
      " Senate Report 109-293.txt    file-CtnsBtb4131oWAndwfxZeT\n",
      " House Report 111-8.txt    file-JVikd54Jef7Tc7jULamKiM\n",
      " Public Law 113-6.txt    file-8tJsSkc6KWrV5EUR45MMia\n",
      " Public Law 116-93.txt    file-A4yeQ6aumKiLEt59J52bNq\n",
      " Senate Report 106-298.txt    file-PQiy6xxota6ovcKqAZfeUQ\n",
      " Public Law 112-10.txt    file-QAfMJj1Kz8tCvaokW5KaAp\n",
      " House Report 111-427.txt    file-MZBMhQZHbjvYB34quk8eqU\n",
      " House Report 107-350.txt    file-UXG52DMXBEtQUSaqakHAAp\n",
      " House Report 107-593.txt    file-3Jo8Wx939DjZjgJGJxFxPT\n",
      " House Report 109-272.txt    file-L8hJXbbe8F6krq7BtJkFDr\n",
      " House Report 109-72.txt    file-PxaLsybR4VnLrG1m57ni49\n",
      " House Report 106-371.txt    file-HAdhuKuht1C4F9pGcRSwiC\n",
      " Public Law 109-148.txt    file-W7Ebb33Y9Es5pnTgMPrAVd\n",
      " House Report 111-105.txt    file-DTm5zJ11wKVrmoqBtxURLr\n",
      " Public Law 107-117.txt    file-CXH6WnDonFuPBMqLB4gvfP\n",
      " House Report 117-328.txt    file-8XAyX1gLRuKp2JiWUpzGjp\n",
      " Public Law 107-206.txt    file-FzcuYTGp4f3T7i2Sk75TxB\n",
      " Public Law 110-252.txt    file-LxPudaujn3xHSZH6Qq7gnJ\n",
      " Public Law 109-13.txt    file-MJcqNwTyRo63z2TfQAeufX\n",
      " Public Law 106-79.txt    file-C3nTw4LEKeh6Vm1fnj8o8K\n",
      " Public Law 108-287.txt    file-9ABDz2RGXbzkmCUowU3aUe\n",
      " House Report 114-113.txt    file-SSpg9G7AxPGPbQy1hcHQpB\n",
      " House Report 108-55.txt    file-8WUFfBNkWRVeHcFNJpjiVB\n",
      " Public Law 109-234.txt    file-JjoX4KqhgPhvjkW4BTc4Fs\n",
      " Public Law 109-108.txt    file-2K1dcfUmkudRMV7vDRaMPF\n",
      " Public Law 106-259.txt    file-MkkD4LgdL3mbS5GvvUTyUb\n",
      " Public Law 110-5.txt    file-TyQyQkvS3vQ5oFqdohQBgf\n",
      " Public Law 111-32.txt    file-BAyQUwZR6LE8LZJQMX46CP\n",
      " Public Law 108-11.txt    file-6wExCKQrUAPzZTSZM4VVjq\n",
      " Public Law 111-212.txt    file-Vfb7a7Q36psX5FCQ3WQTZj\n",
      " Public Law 108-447.txt    file-E5y66b7vTENsi36jmLZURW\n",
      " Public Law 103-333.txt    file-F3hiJSkk1dZ8dyUhsXUPYu\n",
      " Public Law 112-25.txt    file-1pgByepf7FTyh5vy2iamaD\n",
      " House Report 116-260.txt    file-M6DgD6WbGhS5WYzgEj6Vrg\n",
      " Public Law 118-83.txt    file-J93Ur3aF2EtJvqExmvCNoG\n",
      " House Report 117-103.txt    file-MoAriavfCK4F8hXiowphX4\n",
      " House Report 118-83.txt    file-SKmMgGwNQrV5aGn2FG3kC2\n",
      " House Report 115-141.txt    file-PBGGFpdWohwFT7kyt5Cv6U\n",
      " House Report 103-533.txt    file-WrbJkmTNh9EpqaRjmW2Atd\n",
      " House Report 110-5.txt    file-Hu6KZ4JWDXgDCyP7kjTxEa\n",
      " House Report 118-42.txt    file-SdyQArxC7ek8gHZ7HeagRs\n",
      " House Report 113-6.txt    file-LpZCVp6LshPKRzXPq1j8Me\n",
      " House Report 115-31.txt    file-G8fdQqaoRrtCwwuodEC2D1\n",
      " House Report 106-110.txt    file-Ya9F4ijLE2dEvS91iUazq6\n",
      " House Report 110-656.txt    file-2SerGcKmtc6Gth5Myqu9s1\n",
      " House Report 116-6.txt    file-SYAojszgV96w4KxM3137H6\n",
      " House Report 113-76.txt    file-GSHo8dM5AhUAE7khkKiLep\n",
      " House Report 113-235.txt    file-Y3zfbd7BXxX2T9kcS4pEqu\n",
      " House Report 116-93.txt    file-UUgeZEkakxXRf2sY1joyRE\n",
      " House Report 105-825.txt    file-ZbKd010iAzD4t8FG5MiSknkk\n",
      " House Report 104-863.txt    file-lJviEItZxo9G1NJzqfixIpMB\n",
      " Public Law 105-277.txt    file-dY25X2c6jlbeiKrP4l7c55wM\n",
      " Public Law 104-208.txt    file-XfnVZehks7qG5RQqkP9bVBAQ\n",
      " House Report 104-537.txt    file-OBk99IijNHvWgL3yI05UJ6iC\n",
      " Public Law 104-134.txt    file-hzqx0dKE7FiGFuPTsdstpEFm\n",
      " The Congressional Budget and Impoundment Control Act of 1974.txt    file-NRMEksB9kYp1ZG7fbPuKpv7O\n",
      " Public Law 116-260.txt    file-cJ2b0gyJzXzZdWwU4Lylu1mZ\n",
      " Public Law 117-328.txt    file-Fj4IvStUA0tiHdzZ0k51DWfc\n",
      " House Report 111-366.txt    file-yv89DPvVGgRGAgBFg9wkvJP6\n",
      " House Report 108-792.txt    file-osYQnwyG5PC1AirbG5LV6fly\n",
      " House Report 108-10.txt    file-WBcNoNfx3aGPvj4KHUmPd7mX\n",
      " House Report 106-1033.txt    file-t9avCS0vANlzzzTBMFW0bHcs\n",
      " Public Law 117-103.txt    file-Zcb1EaY3P24sRp4pC0ihYM2l\n",
      " House Report 106-479.txt    file-mixy4xPZJn0LDfnH2nMDh0KY\n",
      " House Report 108-401.txt    file-pEh9cYlycebOi3gZeyQD8iao\n",
      " Public Law 115-141.txt    file-3aSNzjiWqLEU9iRxQ8rTQl10\n",
      " House Report 112-331.txt    file-VQShZXfrC7MVpR1KcOlZdRCe\n",
      " Public Law 114-113.txt    file-2NmCUcU9bzjN7cB9FIFwFZV9\n",
      " Public Law 113-235.txt    file-7VM31WMQfuKepqL69DZawXd5\n",
      " Public Law 115-31.txt    file-GlakHIQWCvGM1rScc81OFMto\n",
      " Public Law 106-113.txt    file-XtpjJr4KDesH6GeGR8IIqNl2\n",
      " Public Law 106-554.txt    file-5Z1m6JOITl8vHqbgx6tNNYFj\n",
      " Public Law 110-161.txt    file-h1al9htTR6fm3C8f5SP8GUOI\n",
      " Public Law 113-76.txt    file-qO4WXyF85m1H6jXcKqN2QUWj\n",
      " Public Law 108-7.txt    file-Kqt9PXgd3KIIp37RS9zqiOLE\n",
      " Public Law 112-74.txt    file-nhwKe4EGuc00CWby3v2Ie4fg\n",
      " Public Law 116-6.txt    file-m2EiXvLBh4ea9tEupPuerUtA\n",
      " Public Law 111-8.txt    file-zeNFEdvPWsTHYDBwWisHI0Vs\n",
      " Public Law 108-199.txt    file-6epzBOdLQCE82LUtuHShqkPd\n",
      " Public Law 118-42.txt    file-b6OPVM5wK9ookiyTRMopJ4Yj\n",
      " Public Law 111-117.txt    file-WO2sadvWrC4cGA7BtZt5PeJJ\n",
      " House Report 109-293.txt    file-Wfcg4l7iucRWRNPOufHbZ7XE\n",
      " House Report 111-8.txt    file-6olrhYP4524svRqtUEwT1Prx\n",
      " Public Law 113-6.txt    file-MTQ1ZCGec7PtwmD0mIaWUvtx\n",
      " Senate Report 106-298.txt    file-k4hwswjOzZXxJoZsJFMZwHUE\n",
      " House Report 107-350.txt    file-zJO5aucpsTstY4DHCs9ACZCN\n",
      " Public Law 116-93.txt    file-pk7MLXRoMTxDOqRr3KrjZoJO\n",
      " Public Law 112-10.txt    file-Q0CmRApcNMHrL30BARiDMx5T\n",
      " House Report 107-593.txt    file-Ja2bylodjFNuyy0nCC3VhERP\n",
      " House Report 111-427.txt    file-dzv4zvrvOhrbPO3hXiHizWsZ\n",
      " House Report 109-272.txt    file-WpBrKdtJkYDXx7r4bs1Z2MNl\n",
      " House Report 106-371.txt    file-ITSj3quakS6T5kmDvgNPGGJK\n",
      " House Report 117-328.txt    file-a5AmVPHxG9hDibNY2mY7InLu\n",
      " Public Law 107-206.txt    file-EykviSXoohHDXOZWmICH6XWD\n",
      " Public Law 107-117.txt    file-FSaEYd6z5xWupc15c9rkQj7r\n",
      " House Report 111-105.txt    file-dYcxpAXwvoKfJnm8FDW6zLVj\n",
      " Public Law 109-234.txt    file-hlI7meV3SF0cgJNDaItMmWa0\n",
      " Public Law 106-79.txt    file-Ec1BRUzJH1B4ntqUafsvxdsA\n",
      " House Report 114-113.txt    file-wUhFVWlTXqObITxxEKtqUQGY\n",
      " Public Law 109-108.txt    file-mHUrvuhmrGelQtVSGCNrN9pH\n",
      " Public Law 106-259.txt    file-epaimk4zRrAJUPJknoRtG0tQ\n",
      " Public Law 110-5.txt    file-hygftDwd6vgqnaR4RPi6pZqN\n",
      " Public Law 108-447.txt    file-yIMw4kC2qOhupbiJ6lSeL03w\n",
      " Public Law 108-287.txt    file-Rry8a2TdhFHqiWAkH5PEviMy\n",
      " House Report 108-55.txt    file-OLvz716A25dtGPCZsqLs3c8K\n",
      " Public Law 108-11.txt    file-kcylKKq7FTw8A8VYUmM9vMrE\n",
      " Public Law 112-25.txt    file-qzQimbSEncJhEe5bMdUo1B6Q\n",
      " Public Law 111-212.txt    file-qhpkLZiOtC9zzzU12XpBVVg9\n",
      " House Report 116-260.txt    file-O93bXYDqV94kVX5aZF9qPWiV\n",
      " Public Law 118-83.txt    file-LDd18fOojA3Os5jfOzVZFD8X\n",
      " House Report 118-83.txt    file-ZqZ0F4IsCbBygcyCd2SIKvHf\n",
      " House Report 117-103.txt    file-oyb1fKSrAAaFmHvKYHX1us72\n",
      " House Report 116-6.txt    file-CMs5XIdsEFfVfXMj6hxAw1im\n",
      " House Report 115-141.txt    file-DdPCK52YnRaVprnPGuIRqAKD\n",
      " House Report 115-31.txt    file-p5chg1mOU82rw6nNKOtBMW22\n",
      " House Report 118-42.txt    file-IQXrWlQKRBxVKf74uJXxysUH\n",
      " House Report 116-93.txt    file-tS5gg7acGdFYg3peJ68PDBhI\n",
      " House Report 113-235.txt    file-evzdDTRUXK4AVGzY7pNSaMsA\n",
      " House Report 113-6.txt    file-QtdEcBQv9p56k8wKDzhwgXVi\n",
      " House Report 113-76.txt    file-ZlI3D3qn5QAkSAacuqtjHQCJ\n",
      " House Report 110-5.txt    file-AqMtGpXqrrRWZTrm4AtE1JPW\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Retreive File",
   "id": "b4c2ed04a2bc01c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T20:06:56.163718Z",
     "start_time": "2025-05-21T20:06:54.746193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Reteive by file_id\n",
    "retrieval = client.files.retrieve( 'file-FoVMTC8aQcUNddJP3PBx56' )\n",
    "retrieval.filename\n"
   ],
   "id": "6496c6c7c3e9ccee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Principles Of Federal Appropriations Law Volume Two.pdf'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Reteive Contents",
   "id": "7be1b80ac4fb5e35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "content = client.files.content( 'file-abc123' )\n"
   ],
   "id": "92a1e381d4544632"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Upload",
   "id": "7da07ee006a42a88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.files.create( file=open( 'mydata.jsonl', 'rb' ), purpose='fine-tune' )\n"
   ],
   "id": "517bc315b104e524"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Base64-encoded files\n",
    "- You can send PDF file inputs as Base64-encoded inputs as well."
   ],
   "id": "267f2f464ac377f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "with open( 'draconomicon.pdf', 'rb' ) as f:\n",
    "    data = f.read( )\n",
    "\n",
    "base64_string = base64.b64encode( data ).decode( 'utf-8' )\n",
    "completion = client.chat.completions.create( model='gpt-4o',\n",
    "    messages=\n",
    "    [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'text': 'file',\n",
    "                    'file':\n",
    "\t                {\n",
    "                        'filename': 'draconomicon.pdf',\n",
    "                        'file_data': f'target_values:application/pdf;base64,{ base64_string }',\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'text': 'path',\n",
    "                    'documents': 'What is the first dragon in the book?',\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ].message.content )\n"
   ],
   "id": "fe13e36170cd8192"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Delete File",
   "id": "2fc4b4f5b2fb4fb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "client.files.delete( 'file-NRMEksB9kYp1ZG7fbPuKpv7O' )"
   ],
   "id": "760a8cb912f18b7f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Retreival API\n",
    "- The Retrieval API allows you to perform semantic search over your data, which is a technique that surfaces semantically similar results — even when they match few or no keywords.\n",
    "- The Retrieval API is powered by vector stores, which serve as indices for your data.\n",
    "___"
   ],
   "id": "cc9fa669a5111492"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f1bad91af57695a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Vector Store",
   "id": "81570e1ee566cd92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "vector_store = client.vector_stores.create( name='Support FAQ' )\n",
    "client.vector_stores.files.upload_and_poll(  vector_store_id=vector_store.id, file=open( 'customer_policies.txt', 'rb' ) )"
   ],
   "id": "8c824cffccbe5b62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "####   Search Stores",
   "id": "451d8d683694f0e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "user_query = 'What is the return policy?'\n",
    "results = client.vector_stores.search( vector_store_id=vector_store.id, query=user_query, )"
   ],
   "id": "3a81b00e60f48361"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Semantic Search",
   "id": "27716316afa8ae53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "results = client.vector_stores.search( vector_store_id=vector_store.id,\n",
    "    query='How many woodchucks are allowed per passenger?', )"
   ],
   "id": "6ce6e5f5d2cc3978"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Retreival Augmentation\n",
    "- Pincone & LangChain\n",
    "- You take the query as a question that is to be answered by a LLM, but the LLM must answer the question based on the information it is seeing from the vectorstore."
   ],
   "id": "2a60f495b23976e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Initialize a `RetrievalQA` object\n",
    "\n"
   ],
   "id": "fba347344db6ece6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# completion llm\n",
    "llm = ChatOpenAI( openai_api_key=OPENAI_API_KEY, model_name='gpt-3.5-turbo', temperature=0.0 )\n",
    "qa = RetrievalQA.from_chain_type( llm=llm, chain_type='stuff', retriever=vectorstore.as_retriever( ) )\n",
    "qa.invoke( query )\n"
   ],
   "id": "1b8c949602489fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Or use `RetrievalQAWithSourcesChain`",
   "id": "ab4d528d917f69cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "qa_with_sources.invoke(query)\n",
    "\n",
    "# Response:\n",
    "# {'prompt': 'who was Benito Mussolini?',\n",
    "# 'answer': \"Benito Mussolini was an Italian politician and journalist who served as the Prime Minister of Italy from 1922 until 1943.\n",
    "# He was the leader of the National Fascist Party and played a significant role in the rise of fascism in Italy...\",\n",
    "# 'sources': 'https://simple.wikipedia.org/wiki/Benito%20Mussolini'}"
   ],
   "id": "72604f0a94db3c2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3. Clean-up\n",
    "- When you no longer need the index, use the `delete_index` operation to delete it"
   ],
   "id": "1c66e27b4cbf4782"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pc.delete_index(name=index_name)",
   "id": "60dfa58e09ffdf4c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Vector Store API\n",
    "- Vector stores are the containers that power semantic search for the Retrieval API and the Assistants API file search tool.\n",
    "- When you add a file to a vector store it will be automatically chunked, embedded, and indexed.\n",
    "___"
   ],
   "id": "564d4b602fe2ef91"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Definitions\n",
    "- **File**: Represents content uploaded through the Files API. Often used with vector stores, but also for fine-tuning and other use cases.\n",
    "- **vector_store**: Container for searchable files.\n",
    "- **vector_store.file**: Wrapper type specifically representing a file that has been chunked and embedded, and has been associated with a vector_store.\n"
   ],
   "id": "c32f0af5f0c45d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### I. Vector Store Operations",
   "id": "fb964cc0c0a36628"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Create",
   "id": "97521b55fc1f0625"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create vector store\n",
    "client.vector_stores.create( name='Support FAQ', file_ids=[ 'file_123' ] )"
   ],
   "id": "e17fac7bd5d6999f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Retrieve",
   "id": "d90fa1d06cf2d67b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Retreive vector store\n",
    "client.vector_stores.retrieve( vector_store_id='vs_123' )"
   ],
   "id": "d5ac511a0ee074a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Update",
   "id": "1d8e79e081421fe7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Update vector store\n",
    "client.vector_stores.retrieve( vector_store_id='vs_123' )"
   ],
   "id": "8353143e91fdc157"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Delete",
   "id": "88302805929453c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Delete vector store\n",
    "client.vector_stores.delete( vector_store_id='vs_123' )"
   ],
   "id": "f9020eb5ea907162"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### List",
   "id": "6ae83c9daf0a89bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List vectorstores\n",
    "client.vector_stores.list( )"
   ],
   "id": "e90ce2619c5dc151"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### II. Vector File Operations",
   "id": "a11aaecf8c694f3a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Create File",
   "id": "1e7701e63313311e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create files for vector store\n",
    "client.vector_stores.files.create( vector_store_id='vs_123',\n",
    "    file_id='file_123',\n",
    "    attributes=\n",
    "    {\n",
    "        'region': 'US',\n",
    "        'category': 'Marketing',\n",
    "        'date': 1672531200\n",
    "    }\n",
    ")"
   ],
   "id": "8417ac24062d8b2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Upload File",
   "id": "5ad92c8d67fa907c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.files.upload_and_poll( vector_store_id='vs_123',\n",
    "    file=open( 'customer_policies.txt', 'rb' ) )"
   ],
   "id": "f2fa2da1c6644b93"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Retreive File",
   "id": "9d4ccfd66ca8e438"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "client.vector_stores.files.retrieve( vector_store_id='vs_123', file_id='file_123' )\n"
   ],
   "id": "f395931f01ab0b69"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Update File",
   "id": "6c0b68210f82332c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Update file\n",
    "client.vector_stores.files.update( vector_store_id='vs_123', file_id='file_123',\n",
    "    attributes=\n",
    "    {\n",
    "\t    'key': 'value'\n",
    "    }\n",
    ")\n"
   ],
   "id": "bed01979a830b021"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Delete File",
   "id": "3fe27377daae7ab2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Delete file\n",
    "client.vector_stores.files.delete( vector_store_id='vs_123', file_id='file_123' )\n"
   ],
   "id": "d81dd18aebc57ff5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### List Files",
   "id": "afcb3de796b75483"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List files\n",
    "client.vector_stores.files.list( vector_store_id='vs_123' )"
   ],
   "id": "dbfaa44ec54f7e7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Limits\n",
    "- The maximum file size is 512 MB. Each file should contain no more than 5,000,000 tokens per file (computed automatically when you attach a file)."
   ],
   "id": "4feae16d6d54cbce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Chunking\n",
    "- By default, `max_chunk_size_tokens` is set to 800 and `chunk_overlap_tokens` is set to 400.\n",
    "- Every file is indexed by being split up into 800-token chunks, with 400-token overlap between consecutive chunks.\n",
    "- `max_chunk_size_tokens` must be between 100 and 4096 inclusive.\n",
    "- 'chunk_overlap_tokens' must be non-negative and should not exceed max_chunk_size_tokens / 2."
   ],
   "id": "a57685a68c7feb2d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tools API\n",
    "- File Search augments the Assistant with knowledge from outside its model\n",
    "- Code Interpreter allows Assistants to write and run Python code in a sandboxed execution environment\n",
    "- Function calling allows you to describe functions to the Assistants API then call them\n",
    "___"
   ],
   "id": "f1e930763685aba0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Get Weather\n",
    "- ( Open-Meteo )"
   ],
   "id": "8ffc08fed9eb41d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Define function\n",
   "id": "17cda2d66c50c67a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_weather( latitude, longitude ):\n",
    "    response = requests.get( f'https://api.open-meteo.com/v1/forecast?latitude={ latitude }&longitude={ longitude }&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m' )\n",
    "    data = response.json( )\n",
    "    return data[ 'current' ][ 'temperature_2m' ]"
   ],
   "id": "8371554cf0720410"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        'text': 'function',\n",
    "        'function':\n",
    "        {\n",
    "            'name': 'get_weather',\n",
    "            'description': 'Gets the current weather for a given location',\n",
    "            'parameters':\n",
    "            {\n",
    "                'text': 'object',\n",
    "                'properties':\n",
    "                {\n",
    "                    'location':\n",
    "                    {\n",
    "                        'text': 'path',\n",
    "                        'description': 'The city and state, e.g., San Francisco, CA',\n",
    "                    },\n",
    "                    'unit':\n",
    "                    {\n",
    "                        'text': 'path',\n",
    "                        'enum': [ 'celsius', 'fahrenheit' ]\n",
    "                    }\n",
    "                },\n",
    "\n",
    "                'required': [ 'location' ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create( model='gpt-4o',\n",
    "\tmessages=[ { 'role': 'user', 'content': 'What is the weather like in Paris today?' } ],\n",
    "\ttools=tools )\n",
    "\n",
    "print( completion.choices[ 0 ].message.tool_calls )"
   ],
   "id": "e5949de4dd12fe45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Get Forecast\n",
    "- ( Open Weather API )"
   ],
   "id": "3b642fab2188553e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Step 1 - Define the local function",
   "id": "7a35d47d4922cfc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "OPENAI_API_KEY = os.getenv( \"OPENAI_API_KEY\" )\n",
    "WEATHER_API_KEY = os.getenv( \"WEATHER_API_KEY\" )  # from https://www.weatherapi.com/\n",
    "client = OpenAI( api_key = OPENAI_API_KEY )\n",
    "\n",
    "\n",
    "def get_weather( location: str, unit: str = \"fahrenheit\" ) -> dict:\n",
    "\t\"\"\"\n",
    "\n",
    "        Purpose:\n",
    "            Fetch current weather for a given location from WeatherAPI.\n",
    "\n",
    "        Parameters:\n",
    "            location (str): City or region.\n",
    "            unit (str): Temperature unit ('celsius' or 'fahrenheit').\n",
    "\n",
    "        Returns:\n",
    "            dict: Weather data with temperature, condition, and humidity.\n",
    "\n",
    "    \"\"\"\n",
    "\turl = \"https://api.weatherapi.com/v1/current.json\"\n",
    "\tparams = { \"key\": WEATHER_API_KEY, \"q\": location, \"aqi\": \"no\" }\n",
    "\tresp = requests.get( url, params = params ).json( )\n",
    "\n",
    "\ttemp = resp[ \"current\" ][ \"temp_c\" ] if unit == \"celsius\" else resp[ \"current\" ][ \"temp_f\" ]\n",
    "\n",
    "\treturn {\n",
    "\t\t\t\"location\": f\"{resp[ 'location' ][ 'name' ]}, {resp[ 'location' ][ 'country' ]}\",\n",
    "\t\t\t\"temperature\": temp,\n",
    "\t\t\t\"unit\": unit,\n",
    "\t\t\t\"condition\": resp[ \"current\" ][ \"condition\" ][ \"text\" ],\n",
    "\t\t\t\"humidity\": resp[ \"current\" ][ \"humidity\" ]\n",
    "\t}\n",
    "\n",
    "def get_forecast( location: str, days: int = 3, unit: str = \"fahrenheit\" ) -> dict:\n",
    "\t\"\"\"\n",
    "        Purpose:\n",
    "            Fetch weather forecast for the next given number of days from WeatherAPI.\n",
    "\n",
    "        Parameters:\n",
    "            location (str): City or region.\n",
    "            days (int): Number of days to forecast (1–10).\n",
    "            unit (str): Temperature unit ('celsius' or 'fahrenheit').\n",
    "\n",
    "        Returns:\n",
    "            dict: Multi-day forecast including date, min/max temperatures, and conditions.\n",
    "    \"\"\"\n",
    "\turl = \"https://api.weatherapi.com/v1/forecast.json\"\n",
    "\tparams = { \"key\": WEATHER_API_KEY, \"q\": location, \"days\": days, \"aqi\": \"no\", \"alerts\": \"no\" }\n",
    "\tresp = requests.get( url, params = params ).json( )\n",
    "\n",
    "\tforecast_list = [ ]\n",
    "\tfor day in resp[ \"forecast\" ][ \"forecastday\" ]:\n",
    "\t\tforecast_list.append( {\n",
    "\t\t\t\t\"date\": day[ \"date\" ],\n",
    "\t\t\t\t\"min_temp\": day[ \"day\" ][ \"mintemp_c\" ] if unit == \"celsius\" else day[ \"day\" ][\n",
    "\t\t\t\t\t\"mintemp_f\" ],\n",
    "\t\t\t\t\"max_temp\": day[ \"day\" ][ \"maxtemp_c\" ] if unit == \"celsius\" else day[ \"day\" ][\n",
    "\t\t\t\t\t\"maxtemp_f\" ],\n",
    "\t\t\t\t\"unit\": unit,\n",
    "\t\t\t\t\"condition\": day[ \"day\" ][ \"condition\" ][ \"text\" ]\n",
    "\t\t} )\n",
    "\n",
    "\treturn {\n",
    "\t\t\t\"location\": f\"{resp[ 'location' ][ 'name' ]}, {resp[ 'location' ][ 'country' ]}\",\n",
    "\t\t\t\"forecast\": forecast_list\n",
    "\t}"
   ],
   "id": "8b19913b41306eee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Step 2: Define function schema for OpenAI",
   "id": "36fc1b2495a156bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "functions = [\n",
    "\t\t{\n",
    "\t\t\t\t\"name\": \"get_weather\",\n",
    "\t\t\t\t\"description\": \"Get the current weather for a location\",\n",
    "\t\t\t\t\"parameters\": {\n",
    "\t\t\t\t\t\t\"type\": \"object\",\n",
    "\t\t\t\t\t\t\"properties\": {\n",
    "\t\t\t\t\t\t\t\t\"location\": { \"type\": \"string\", \"description\": \"City name\" },\n",
    "\t\t\t\t\t\t\t\t\"unit\": { \"type\": \"string\", \"enum\": [ \"celsius\", \"fahrenheit\" ] }\n",
    "\t\t\t\t\t\t},\n",
    "\t\t\t\t\t\t\"required\": [ \"location\" ]\n",
    "\t\t\t\t}\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\t\"name\": \"get_forecast\",\n",
    "\t\t\t\t\"description\": \"Get the multi-day weather forecast for a location\",\n",
    "\t\t\t\t\"parameters\": {\n",
    "\t\t\t\t\t\t\"type\": \"object\",\n",
    "\t\t\t\t\t\t\"properties\": {\n",
    "\t\t\t\t\t\t\t\t\"location\": { \"type\": \"string\", \"description\": \"City name\" },\n",
    "\t\t\t\t\t\t\t\t\"days\": { \"type\": \"integer\",\n",
    "\t\t\t\t\t\t\t\t          \"description\": \"Number of days (1–10)\" },\n",
    "\t\t\t\t\t\t\t\t\"unit\": { \"type\": \"string\", \"enum\": [ \"celsius\", \"fahrenheit\" ] }\n",
    "\t\t\t\t\t\t},\n",
    "\t\t\t\t\t\t\"required\": [ \"location\", \"days\" ]\n",
    "\t\t\t\t}\n",
    "\t\t}\n",
    "]"
   ],
   "id": "ed038db9437268f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Step 3: First API call – let the model decide if it should call the function",
   "id": "e2513c5c58212817"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "response = client.chat.completions.create(\n",
    "\tmodel = \"gpt-4o-mini\",\n",
    "\tmessages = [ { \"role\": \"user\",\n",
    "\t               \"content\": \"What will the weather be in London for the next 3 days in Celsius?\" } ],\n",
    "\tfunctions = functions,\n",
    "\tfunction_call = \"auto\"\n",
    ")\n",
    "\n",
    "message = response.choices[ 0 ].message"
   ],
   "id": "5f91b74ab607fe04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Step 4: If a function is called, run it and send the result back",
   "id": "8051673e6ae1498f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if message.get( \"function_call\" ):\n",
    "\tfn_name = message.function_call.name\n",
    "\tfn_args = json.loads( message.function_call.arguments )\n",
    "\n",
    "\tif fn_name == \"get_weather\":\n",
    "\t\tresult = get_weather( **fn_args )\n",
    "\telif fn_name == \"get_forecast\":\n",
    "\t\tresult = get_forecast( **fn_args )\n",
    "\telse:\n",
    "\t\tresult = { \"error\": \"Unknown function\" }\n",
    "\n",
    "\tfollowup = client.chat.completions.create(\n",
    "\t\tmodel = \"gpt-4o-mini\",\n",
    "\t\tmessages = [\n",
    "\t\t\t\t{ \"role\": \"user\",\n",
    "\t\t\t\t  \"content\": \"What will the weather be in London for the next 3 days in Celsius?\" },\n",
    "\t\t\t\tmessage,\n",
    "\t\t\t\t{ \"role\": \"function\", \"name\": fn_name, \"content\": json.dumps( result ) }\n",
    "\t\t]\n",
    "\t)\n",
    "\n",
    "\tprint( followup.choices[ 0 ].message[ \"content\" ] )"
   ],
   "id": "f1c15945625db578"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Send Email",
   "id": "e26e0b2058eb8ba6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "tools = [\n",
    "\t{\n",
    "\t\t'text': 'function',\n",
    "\t\t'function':\n",
    "\t\t{\n",
    "\t\t\t'name': 'send_email',\n",
    "\t\t\t'description': 'Send an email to a given recipient with a subject and message.',\n",
    "\t\t\t'parameters':\n",
    "\t\t\t{\n",
    "\t\t\t\t'text': 'object',\n",
    "\t\t\t\t'properties':\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t'to':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t'text': 'path',\n",
    "\t\t\t\t\t\t'description': 'The recipient email address.'\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t'subject':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t'text': 'path',\n",
    "\t\t\t\t\t\t'description': 'Email subject line.'\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t'body':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t'text': 'path',\n",
    "\t\t\t\t\t\t'description': 'Body of the email message.'\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t},\n",
    "\t\t\t\t'required': [ 'to', 'subject', 'body' ],\n",
    "\t\t\t\t'additionalProperties': False\n",
    "\t\t\t},\n",
    "\t\t\t'strict': True\n",
    "\t\t}\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Create Completion\n",
    "completion = client.chat.completions.create( model='gpt-4o',\n",
    "\tmessages=[ { 'role': 'user',\n",
    "\t             'content': 'Can you send an email to terryeppler@gmail.com saying hi?' } ],\n",
    "\ttools=_tools )\n",
    "\n",
    "print( completion.choices[ 0 ].message.tool_calls )"
   ],
   "id": "8f10aeafed2edcd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Search Document",
   "id": "a1f24c7cb9758c33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "_tools = [\n",
    "{\n",
    "\t\t'text': 'function',\n",
    "\t\t'function':\n",
    "        {\n",
    "\t\t\t\t'name': 'search_knowledge_base',\n",
    "\t\t\t\t'description': 'Query a knowledge base to retrieve relevant info on a topic.',\n",
    "\t\t\t\t'parameters':\n",
    "                {\n",
    "\t\t\t\t\t\t'text': 'object',\n",
    "\t\t\t\t\t\t'properties':\n",
    "                        {\n",
    "\t\t\t\t\t\t\t\t'query':\n",
    "                                {\n",
    "                                    'text': 'path',\n",
    "                                    'description': 'The user prompt or search query.'\n",
    "                                },\n",
    "\t\t\t\t\t\t\t\t'options':\n",
    "                                {\n",
    "\t\t\t\t\t\t\t\t\t\t'text': 'object',\n",
    "\t\t\t\t\t\t\t\t\t\t'properties':\n",
    "                                        {\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'num_results':\n",
    "                                                {\n",
    "                                                    'text': 'num',\n",
    "                                                    'description': 'Number of top results to return.'\n",
    "                                                },\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'domain_filter':\n",
    "                                                {\n",
    "                                                    'text': [ 'path', 'null' ],\n",
    "                                                    'description': 'Optional domain to narrow the search. Pass null if not needed.'\n",
    "                                                },\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'sort_by':\n",
    "                                                {\n",
    "                                                    'text': [ 'path', 'null' ],\n",
    "                                                    'enum': [ 'relevance', 'date', 'popularity', 'alphabetical' ],\n",
    "                                                    'description': 'How to sort results. Pass null if not needed.'\n",
    "                                                }\n",
    "                                        },\n",
    "\t\t\t\t\t\t\t\t\t\t'required': [ 'num_results', 'domain_filter', 'sort_by' ],\n",
    "\t\t\t\t\t\t\t\t\t\t'additionalProperties': False\n",
    "                                }\n",
    "                        },\n",
    "\t\t\t\t\t\t'required': [ 'query', 'options' ],\n",
    "\t\t\t\t\t\t'additionalProperties': False\n",
    "                },\n",
    "\t\t\t\t'strict': True\n",
    "        }\n",
    "} ]\n",
    "\n",
    "messages = [\n",
    "{\n",
    "    'role': 'user',\n",
    "    'content': 'Can you find information about ChatGPT in the GPT knowledge base?'\n",
    "} ]\n",
    "\n",
    "completion = client.chat.completions.create( model='gpt-4o', messages=_messages, tools=tools )\n",
    "print( completion.choices[ 0 ].message.tool_calls )"
   ],
   "id": "b54cc7f75bf7d1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Web Search Tool",
   "id": "c41da921aa018c9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "user_prompt = r'''\n",
    "What was a positive news story from today?\n",
    "'''\n",
    "\n",
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "message = [\n",
    "{\n",
    "    'role': 'user',\n",
    "    'content': user_prompt,\n",
    "} ]\n",
    "\n",
    "# Create completion\n",
    "\n",
    "completion = client.chat.completions.create( model='gpt-4o-search-preview', web_search_options={ },\n",
    "    messages=message )\n",
    "\n",
    "print( completion.choices[ 0 ].message.content )"
   ],
   "id": "13ad23c350335b5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Appropriation Status",
   "id": "384afa8fa5fbd504"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fetch_appropriations_status( ):\n",
    "\turl = \"https://www.congress.gov/crs-appropriations-status-table\"\n",
    "\tresponse = requests.get( url )\n",
    "\tresponse.raise_for_status( )\n",
    "\n",
    "\tsoup = BeautifulSoup( response.text, \"html.parser\" )\n",
    "\n",
    "\t# Find the main appropriations status table\n",
    "\ttable = soup.find( \"table\" )\n",
    "\theaders = [ th.get_text( strip = True ) for th in table.find_all( \"th\" ) ]\n",
    "\n",
    "\t# Parse each row\n",
    "\trows = [ ]\n",
    "\tfor tr in table.find_all( \"tr\" )[ 1: ]:\n",
    "\t\tcells = [ td.get_text( strip = True ) for td in tr.find_all( \"td\" ) ]\n",
    "\t\tif cells:\n",
    "\t\t\trows.append( cells )\n",
    "\n",
    "\t# Convert to DataFrame\n",
    "\tdf_status = pd.DataFrame( rows, columns = headers )\n",
    "\n",
    "\t# Clean up (optional: filter columns of interest)\n",
    "\tdf_status = df_status.replace( \"\", pd.NA )\n",
    "\n",
    "\treturn df_status\n",
    "\n",
    "# --- Example run ---\n",
    "df_appropriations_status = fetch_appropriations_status( )\n",
    "\n",
    "# Display formatted table\n",
    "print( df_appropriations_status.head( 10 ) )"
   ],
   "id": "f56b7766767907db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### SQLite",
   "id": "df8de1ff1fb9140c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "conn = sqlite3.connect( 'df/Chinook.db' )\n",
    "print( 'Opened database successfully' )"
   ],
   "id": "4e30dc2999a049f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Define Schema Functions",
   "id": "5e9d7639a3024277"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_table_names( conn ):\n",
    "    \"\"\"\n",
    "\n",
    "        Return a list of table names.\n",
    "\n",
    "    \"\"\"\n",
    "    table_names = []\n",
    "    tables = conn.execute( 'SELECT name FROM sqlite_master WHERE scaler=\"table\";' )\n",
    "    for table in tables.fetchall():\n",
    "        table_names.append(table[0])\n",
    "    return table_names\n",
    "\n",
    "\n",
    "def get_column_names( conn, table_name ):\n",
    "    \"\"\"\n",
    "\n",
    "        Return a list of column names.\n",
    "\n",
    "    \"\"\"\n",
    "    column_names = [ ]\n",
    "    columns = conn.execute( f'PRAGMA table_info( \"{table_name}\" );' ).fetchall( )\n",
    "    for col in columns:\n",
    "        column_names.append( col[ 1 ] )\n",
    "    return column_names\n",
    "\n",
    "\n",
    "def get_database_info( conn ):\n",
    "    \"\"\"\n",
    "\n",
    "        Return a list of dicts containing the table name and columns for each table in the database.\n",
    "\n",
    "    \"\"\"\n",
    "    table_dicts = []\n",
    "    for table_name in get_table_names(conn):\n",
    "        columns_names = get_column_names(conn, table_name)\n",
    "        table_dicts.append( { 'table_name': table_name, 'column_names': columns_names } )\n",
    "    return table_dicts\n"
   ],
   "id": "ce9c599b99a26f7e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Extract schema",
   "id": "9640413175d79491"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "database_schema_dict = get_database_info( conn )\n",
    "database_schema_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
    "        for table in database_schema_dict\n",
    "    ])"
   ],
   "id": "e5df7d88f01b51b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Define Function Schema",
   "id": "a576afd8824e312f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tools = [\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function':\n",
    "\t    {\n",
    "            'name': 'ask_database',\n",
    "            'description': 'Use this function to answer user questions about music. Input should be a fully formed SQL query.',\n",
    "            'parameters':\n",
    "\t        {\n",
    "                'type': 'object',\n",
    "                'properties':\n",
    "\t            {\n",
    "                    'query':\n",
    "\t                {\n",
    "                        'type': 'string',\n",
    "                        'description': f\"\"\"\n",
    "                                SQL query extracting info to answer the user's question.\n",
    "                                SQL should be written using this database schema:\n",
    "                                {database_schema_string}\n",
    "                                The query should be returned in plain text, not in JSON.\n",
    "                                \"\"\",\n",
    "                    }\n",
    "                },\n",
    "                'required': [ 'query' ],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ],
   "id": "a6292e4b28a92bfe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Define Database Function",
   "id": "ef99ac790e9b6cde"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def ask_database( conn, query ):\n",
    "    \"\"\"\n",
    "\n",
    "        GptFunction to query SQLite database with a provided SQL query.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = str(conn.execute(query).fetchall())\n",
    "    except Exception as e:\n",
    "        results = f'query failed with error: {e}'\n",
    "    return results"
   ],
   "id": "aa7f68e9b7b9ec56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Step 1: Prompt the model with content that may result in model selecting a tool to use.\n",
    "- Step 2: Check programmatically if model wanted to call a function. If true, proceed to step 3.\n",
    "- Step 3: Extract the function name and parameters from response, call the function with parameters then append the result to messages.\n",
    "- Step 4: Invoke the chat completions API with the message list to get the response.\n"
   ],
   "id": "83af4e33a35b27ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "messages = [{\n",
    "    'role':'user',\n",
    "    'content': 'What is the name of the album with the most tracks?'\n",
    "}]\n",
    "\n",
    "response = client.chat.completions.create( model='gpt-4o', messages=messages,\n",
    "    tools= tools, tool_choice='auto' )\n",
    "\n",
    "response_message = response.choices[ 0 ].message\n",
    "messages.append( response_message )\n",
    "print( response_message )"
   ],
   "id": "2de821fddbcdfc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 2: determine if the response from the model includes a tool call.   \n",
    "tool_calls = response_message.tool_calls\n",
    "if tool_calls:\n",
    "    tool_call_id = tool_calls[ 0 ].id\n",
    "    tool_function_name = tool_calls[ 0 ].function.name\n",
    "    tool_query_string = json.loads( tool_calls[ 0 ].function.arguments )[ 'query' ]\n",
    "    if tool_function_name == 'ask_database':\n",
    "        results = ask_database( conn, tool_query_string )\n",
    "        messages.append( {\n",
    "            'role': 'tool',\n",
    "            'tool_call_id': tool_call_id,\n",
    "            'name': tool_function_name, \n",
    "            'content': results\n",
    "        } )\n",
    "        model_response_with_function_call = client.chat.completions.create( model='gpt-4o', messages=messages )\n",
    "        print( model_response_with_function_call.choices[0].message.content )\n",
    "    else: \n",
    "        print( f'Error: function {tool_function_name} does not exist' )\n",
    "else:\n",
    "    print( response_message.content )"
   ],
   "id": "fe24d6e1758f0f41"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### LangChain Web Search\n",
    "- To trigger a web search, pass `{'type': 'web_search_preview'}` to the model as you would another too"
   ],
   "id": "56c62e9168aec24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "llm.invoke( '...', tools=[ { 'text': 'web_search_preview' } ] )",
   "id": "37bda0d2009bc4f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "llm = ChatOpenAI( model='gpt-4o-mini' )\n",
    "tool = { 'text': 'web_search_preview' }\n",
    "llm_with_tools = llm.bind_tools( [ tool ] )\n",
    "\n",
    "response = llm_with_tools.invoke( 'What was a positive news story from today?' )"
   ],
   "id": "1a69beb3ded891a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Web Page Loader\n",
    "- For a simple string representation of text that is embedded in a web page, the method below is appropriate.\n",
    "- It will return a list of Document objects -- one per page -- containing a single string of the page's text"
   ],
   "id": "1f27c2076a32db6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "page_url = \"https://python.langchain.com/docs/how_to/chatbots_memory/\"\n",
    "\n",
    "loader = WebBaseLoader( web_paths=[ page_url ] )\n",
    "docs = [ ]\n",
    "async for doc in loader.alazy_load( ):\n",
    "    docs.append( doc )\n",
    "\n",
    "assert len( docs ) == 1\n",
    "doc = docs[ 0 ]"
   ],
   "id": "2fdbcde1762a31e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Can specify desired `<div>` classes and other parameters via BeautifulSoup",
   "id": "34bfa045d44391f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=[ page_url ],\n",
    "    bs_kwargs=\\\n",
    "\t{\n",
    "        'parse_only': bs4.SoupStrainer( class_='theme-doc-markdown markdown' ),\n",
    "    },\n",
    "    bs_get_text_kwargs=\\\n",
    "\t{\n",
    "\t\t\t'separator': ' | ',\n",
    "\t\t\t'strip': True\n",
    "\t} )\n",
    "\n",
    "docs = []\n",
    "async for doc in loader.alazy_load( ):\n",
    "    docs.append( doc )\n",
    "\n",
    "assert len( docs ) == 1\n",
    "doc = docs[ 0 ]"
   ],
   "id": "6f498dc6062cb5a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### File Search Tool",
   "id": "475b028b4dbce81a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Step 1: Create a new Assistant with GptFile Search Enabled\n",
    "assistant = client.beta.assistants.create(\n",
    "  name='Financial Analyst Assistant',\n",
    "  instructions='You are an expert financial analyst. Use you knowledge base to answer questions about audited financial statements.',\n",
    "  model='gpt-4o',\n",
    "  tools=[ {'text': 'file_search'} ],\n",
    ")\n",
    "\n",
    "# Step 2: Upload files and add them to a VectorStore Store\n",
    "vector_store = client.vector_stores.create( name='Financial Statements' )\n",
    "file_paths = [ 'edgar/goog-10k.pdf', 'edgar/brka-10k.txt' ]\n",
    "file_streams = [ open( path, 'rb' ) for path in file_paths ]\n",
    "file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "print( file_batch.status )\n",
    "print( file_batch.file_counts )\n",
    "\n",
    "# Step 3: Update the assistant to use the new VectorStore Store\n",
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={'file_search': {'vector_store_ids': [ vector_store.id ]}},\n",
    ")\n",
    "\n",
    "# Step 4: Create a thread\n",
    "message_file = client.files.create(\n",
    "  file=open('edgar/aapl-10k.pdf', 'rb'), purpose='assistants'\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': 'How many shares of AAPL were outstanding at the end of of October 2023?',\n",
    "      'attachments': [\n",
    "        { 'file_id': message_file.id, 'tools': [{'text': 'file_search'}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "print( thread.tool_resources.file_search )\n",
    "\n",
    "# Step 5: Create a run and check the cleaned_lines\n",
    "run = client.beta.threads.runs.create_and_poll( thread_id=thread.id,\n",
    "\tassistant_id=assistant.id )\n",
    "\n",
    "messages = list( client.beta.threads.messages.list( thread_id=thread.id, run_id=run.id ) )\n",
    "message_content = messages[ 0 ].content[ 0 ].text\n",
    "annotations = message_content.annotations\n",
    "citations = [ ]\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace( annotation.text, f'[{index}]' )\n",
    "    if file_citation := getattr( annotation, 'file_citation', None ):\n",
    "        cited_file = client.files.retrieve( file_citation.file_id )\n",
    "        citations.append( f'[{index}] {cited_file.filename}' )\n",
    "\n",
    "print( message_content.value )\n",
    "print( '\\n'.join( citations ) )\n",
    "print( response )"
   ],
   "id": "91513107c139d672"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### LangChain File Search\n",
    "- To trigger a file search, pass a file search tool to the model as you would another tool.\n",
    "- You will need to populate an OpenAI-managed vector store and include the vector store ID in the tool definition"
   ],
   "id": "c0809d98c863eb58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "llm = ChatOpenAI( model='gpt-4o-mini' )\n",
    "\n",
    "openai_vector_store_ids = [\n",
    "    'vs_...',  # your IDs here\n",
    "]\n",
    "\n",
    "tool =\\\n",
    "{\n",
    "    'text': 'file_search',\n",
    "    'vector_store_ids': openai_vector_store_ids,\n",
    "}\n",
    "\n",
    "llm_with_tools = llm.bind_tools( [ tool ] )\n",
    "\n",
    "response = llm_with_tools.invoke( 'What is deep research by OpenAI?' )\n",
    "print( response.text( ) )"
   ],
   "id": "d3e5c0ca66f7772d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Use Browser",
   "id": "eae1d57e56a09c33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "_args = [ '--disable-extensions', '--disable-file-system' ]\n",
    "with sync_playwright( ) as p:\n",
    "    browser = p.chromium.launch( headless=False, chromium_sandbox=True, env={ }, args=_args )\n",
    "    page = browser.new_page( )\n",
    "    page.set_viewport_size( {'width': 1024, 'height': 768} )\n",
    "    page.goto( 'https://bing.com' )\n",
    "    page.wait_for_timeout( 10000 )"
   ],
   "id": "755adffccebf080b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Use Computer",
   "id": "3e40eef135fdf6f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "_model = 'computer-use-preview'\n",
    "_reasoning = { 'generate_summary': 'concise', }\n",
    "_truncation = 'auto'\n",
    "_tools = [\n",
    "{\n",
    "    'text': 'computer_use_preview',\n",
    "    'display_width': 1024,\n",
    "    'display_height': 768,\n",
    "    'environment': 'browser'\n",
    "} ]\n",
    "\n",
    "_input = [\n",
    "{\n",
    "        'role': 'user',\n",
    "        'content': 'Check the latest OpenAI news on bing.com.'\n",
    "} ]\n",
    "\n",
    "# Create GptResponse\n",
    "response = client.responses.create( model=_model, tools=_tools, input=_input,\n",
    "    reasoning=_reasoning, truncation='auto' )\n",
    "\n",
    "print( response.cleaned_lines )"
   ],
   "id": "ab6266514b58aa26"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Send Computer Use Request\n",
    "- Send a request to create a Response with the **computer-use-preview** model equipped with the computer_use_preview tool.\n",
    "- This request should include details about your environment, along with an initial input prompt."
   ],
   "id": "e2ad3d2305162416"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "_model = 'computer-use-preview'\n",
    "_tools = [\n",
    "{\n",
    "    'text': 'computer_use_preview',\n",
    "    'display_width': 1024,\n",
    "    'display_height': 768,\n",
    "    'environment': 'browser'\n",
    "} ]\n",
    "\n",
    "_input = [\n",
    "{\n",
    "        'role': 'user',\n",
    "        'content': 'Check the latest OpenAI news on bing.com.'\n",
    "} ]\n",
    "\n",
    "# Create response\n",
    "response = client.responses.create( model=_model, tools=_tools, input=_input,\n",
    "    reasoning={ 'generate_summary': 'concise', }, truncation='auto' )\n",
    "\n",
    "print( response.cleaned_lines )"
   ],
   "id": "82fc154541d3d4ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Execute Action\n",
    "- Execute the corresponding actions on your computer or browser.\n",
    "- How you map a computer call to actions through code depends on your environment.\n",
    "- This code shows example implementations for the most common computer actions."
   ],
   "id": "19ea1d17814a58fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def handle_model_action( page, action ):\n",
    "    '''\n",
    "\n",
    "\t\tGiven a computer action (e.g., click, double_click, scroll, resources.),\n",
    "\t\texecute the corresponding operation on the Playwright page.\n",
    "\n",
    "    '''\n",
    "    action_type = action.type\n",
    "    try:\n",
    "        match action_type:\n",
    "            case 'click':\n",
    "                x, y = action.x, action.y\n",
    "                button = action.button\n",
    "                print( f\"Action: click at ({x}, {y}) with button '{button}' \" )\n",
    "                # Not handling things like middle click, resources.\n",
    "                if button != 'left' and button != 'right':\n",
    "                    button = 'left'\n",
    "                page.mouse.click( x, y, button=button )\n",
    "\n",
    "            case 'scroll':\n",
    "                x, y = action.x, action.y\n",
    "                scroll_x, scroll_y = action.scroll_x, action.scroll_y\n",
    "                print(f'Action: scroll at ({x}, {y}) with offsets (scroll_x={scroll_x}, scroll_y={scroll_y})')\n",
    "                page.mouse.move( x, y )\n",
    "                page.evaluate( f'window.scrollBy({scroll_x}, {scroll_y})' )\n",
    "\n",
    "            case 'keypress':\n",
    "                keys = action.keys\n",
    "                for k in keys:\n",
    "                    print( f\"Action: keypress '{k}' \" )\n",
    "                    # A simple mapping for common keys; expand as needed.\n",
    "                    if k.lower( ) == 'enter':\n",
    "                        page.keyboard.press( 'Enter' )\n",
    "                    elif k.lower( ) == 'space':\n",
    "                        page.keyboard.press( ' ' )\n",
    "                    else:\n",
    "                        page.keyboard.press( k )\n",
    "\n",
    "            case 'text':\n",
    "                text = action.text\n",
    "                print( f'Action: scaler documents: {text}' )\n",
    "                page.keyboard.type( text )\n",
    "\n",
    "            case 'wait':\n",
    "                print( f'Action: wait' )\n",
    "                time.sleep( 2 )\n",
    "\n",
    "            case 'screenshot':\n",
    "                # Nothing to do as screenshot is taken at each turn\n",
    "                print( f'Action: screenshot' )\n",
    "\n",
    "            # Handle other actions here\n",
    "\n",
    "            case _:\n",
    "                print( f'Unrecognized action: {action}' )\n",
    "\n",
    "    except Exception as e:\n",
    "        print( f'Error handling action {action}: {e}' )"
   ],
   "id": "3582e1d33fa258d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Capture Screenshot\n",
    "- After executing the action, capture the updated state of the environment as a screenshot."
   ],
   "id": "7fef7bd5a2ef1898"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_screenshot( page ):\n",
    "    '''\n",
    "\n",
    "    \tTake a full-page screenshot using Playwright and return the image bytes.\n",
    "\n",
    "    '''\n",
    "    return page.screenshot( )"
   ],
   "id": "903a5b50ee945679"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Repeating Loop\n",
    "- Once you have the screenshot, you can send it back to the model as a **computer_call_output** to get the next action.\n",
    "- Repeat these steps as long as you get a **computer_call** item in the response."
   ],
   "id": "5c8068df89772139"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def computer_use_loop( instance, response ):\n",
    "    '''\n",
    "\n",
    "    \tRun the loop that executes computer actions until no 'computer_call' is found.\n",
    "    \t\n",
    "    '''\n",
    "    while True:\n",
    "        computer_calls = [ i for i in response.output if i.type == 'computer_call' ]\n",
    "        if not computer_calls:\n",
    "            print( 'No computer call found. Output from small_model:' )\n",
    "            for item in response.output:\n",
    "                print( item )\n",
    "            break  # Exit when no computer calls are issued.\n",
    "\t        \n",
    "        computer_call = computer_calls[ 0 ]\n",
    "        last_call_id = computer_call.call_id\n",
    "        action = computer_call.action\n",
    "\n",
    "        # Execute the action (function defined in step 3)\n",
    "        handle_model_action( instance, action )\n",
    "        time.sleep( 1 )  # Allow time for changes to take effect.\n",
    "\n",
    "        # Take a screenshot after the action (function defined in step 4)\n",
    "        screenshot_bytes = get_screenshot( instance )\n",
    "        screenshot_base64 = base64.b64encode( screenshot_bytes ).decode( 'utf-8' )\n",
    "\n",
    "        # Send the screenshot back as a computer_call_output\n",
    "        response = client.responses.create(\n",
    "            model='computer-use-preview',\n",
    "            previous_response_id=response.id,\n",
    "            tools=[\n",
    "            {\n",
    "                'text': 'computer_use_preview',\n",
    "                'display_width': 1024,\n",
    "                'display_height': 768,\n",
    "                'environment': 'browser'\n",
    "            } ],\n",
    "            input=[\n",
    "            {\n",
    "                'call_id': last_call_id,\n",
    "                'text': 'computer_call_output',\n",
    "                'cleaned_lines':\n",
    "                {\n",
    "                    'text': 'input_image',\n",
    "                    'image_url': f'target_values:image/png;base64,{screenshot_base64}'\n",
    "                }\n",
    "            } ],\n",
    "            truncation='auto'\n",
    "        )\n",
    "\n",
    "    return response"
   ],
   "id": "9ff5a3fad72dfbf8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Function Calling Tool",
   "id": "1e729cebc30a39e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 1 - Define functions\n",
    "- Define the functions under the tools param of the assistant."
   ],
   "id": "155f4f1bf7f475ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI( )\n",
    "assistant = client.beta.assistants.create( instructions='You are a weather bot. Use the provided functions to answer questions.',\n",
    "  model='gpt-4o', tools=[\n",
    "    {\n",
    "      'text': 'function',\n",
    "      'function':\n",
    "      {\n",
    "        'name': 'get_current_temperature',\n",
    "        'description': 'Get the current temperature for a specific location',\n",
    "        'parameters':\n",
    "        {\n",
    "          'text': 'object',\n",
    "          'properties':\n",
    "          {\n",
    "            'location':\n",
    "            {\n",
    "              'text': 'path',\n",
    "              'description': 'The city and state, e.g., San Francisco, CA'\n",
    "            },\n",
    "            'unit':\n",
    "            {\n",
    "              'text': 'path',\n",
    "              'enum': [ 'Celsius', 'Fahrenheit' ],\n",
    "              'description': 'The temperature unit to use. Infer this from the users location.'\n",
    "            }\n",
    "          },\n",
    "          'required': [ 'location', 'unit' ]\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      'text': 'function',\n",
    "      'function': \n",
    "      {\n",
    "        'name': 'get_rain_probability',\n",
    "        'description': 'Get the probability of rain for a specific location',\n",
    "        'parameters': \n",
    "        {\n",
    "          'text': 'object',\n",
    "          'properties': \n",
    "          {\n",
    "            'location': \n",
    "            {\n",
    "              'text': 'path',\n",
    "              'description': 'The city and state, e.g., San Francisco, CA'\n",
    "            }\n",
    "          },\n",
    "          'required': [ 'location' ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ] )"
   ],
   "id": "6934f2c2cd76c22d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 2 - Create a Thread and add Messages\n",
    "- Create a Thread when a user starts a conversation\n",
    "- Add Messages to the Thread as the user asks questions."
   ],
   "id": "c0f772474f5c76e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "thread = client.beta.threads.create( )\n",
    "message = client.beta.threads.messages.create( thread_id=thread.id, role='user',\n",
    "  content='What is the weather in San Francisco today and the likelihood it willl rain?' )"
   ],
   "id": "1ff501d6ae0f2ccb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 3 - Initiate a Run\n",
    "- How you initiate a Run and submit `tool_calls` will differ depending on whether you are using streaming or not\n",
    "- In both cases all `tool_calls` need to be submitted at the same time.\n",
    "- Runs are asynchronous, monitor their status by polling the 'Run' object until a terminal status is reached.\n",
    "- Once the Run completes, you can list the Messages added to the Thread by the Assistant\n",
    "- Retrieve all the `tool_outputs` from `required_action`\n",
    "- Submit them at the same time to the `submit tool outputs and poll` helper."
   ],
   "id": "b33d711d33e61e8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "run = client.beta.threads.runs.create_and_poll(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id )\n",
    "\n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list( thread_id=thread.id )\n",
    "  print( messages )\n",
    "else:\n",
    "  print( run.status )\n",
    "\n",
    "# Define the get_list to store tool outputs\n",
    "tool_outputs = [ ]\n",
    "\n",
    "# Loop through each tool in the required action section\n",
    "for tool in run.required_action.submit_tool_outputs.tool_calls:\n",
    "  if tool.function.name == 'get_current_temperature':\n",
    "    tool_outputs.append(\n",
    "\t{\n",
    "      'tool_call_id': tool.id,\n",
    "      'output': '57'\n",
    "    })\n",
    "  elif tool.function.name == 'get_rain_probability':\n",
    "    tool_outputs.append({\n",
    "      'tool_call_id': tool.id,\n",
    "      'output': '0.06'\n",
    "    })\n",
    "\n",
    "# Submit all tool outputs at once after collecting them in a get_list\n",
    "if tool_outputs:\n",
    "  try:\n",
    "    run = client.beta.threads.runs.submit_tool_outputs_and_poll(\n",
    "      thread_id=thread.id,\n",
    "      run_id=run.id,\n",
    "      tool_outputs=tool_outputs\n",
    "    )\n",
    "    print( 'Tool outputs submitted successfully.' )\n",
    "  except Exception as e:\n",
    "    print( 'Failed to submit tool outputs:', e )\n",
    "else:\n",
    "  print( 'No tool outputs to submit.' )\n",
    "\n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print( messages )\n",
    "else:\n",
    "  print( run.status )"
   ],
   "id": "7a2976b6222f1b98"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## File Search Tool",
   "id": "e58d22240dfc818c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Step 1: Create a new Assistant with File Search Enabled",
   "id": "f2030b87251390d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI()\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name='Financial Analyst Assistant',\n",
    "  instructions='You are an expert financial analyst. Use you knowledge base to answer questions about audited financial statements.',\n",
    "  model='gpt-4o',\n",
    "  tools=[ {'text': 'file_search'} ],\n",
    ")"
   ],
   "id": "94294101971becc1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 2 - Upload files and add them to a Vector Store\n",
    "- To access files, the file_search tool uses the Vector Store object\n",
    "- Once the Vector Store is created, poll its status until all files are out of the `in_progress` state"
   ],
   "id": "30d7a72c36cd2ac3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a vector store caled 'Financial Statements'\n",
    "vector_store = client.vector_stores.create( name='Financial Statements' )\n",
    "\n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [ 'edgar/goog-10k.pdf', 'edgar/brka-10k.txt' ]\n",
    "file_streams = [ open( path, 'rb' ) for path in file_paths ]\n",
    "\n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print( file_batch.status )\n",
    "print( file_batch.file_counts )"
   ],
   "id": "e9c425c8a37906c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 3 - Update the assistant to use the new Vector Store\n",
    "- Update the assistant’s `tool_resources` with the new `vector_store.id`"
   ],
   "id": "5c4b1cce66541436"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={ 'file_search': { 'vector_store_ids': [ vector_store.id ] } },\n",
    ")"
   ],
   "id": "827562fee1a7962"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##  Code Interpreter Tool\n",
    "- Allows Assistants to write and run Python code in a sandboxed execution environment\n",
    "- Tool can process files with diverse data and formatting, and generate files with data and images of graphs"
   ],
   "id": "9ceb9917dfac8677"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 1 - Enabling Code Interpreter\n",
    "- Pass `code_interpreter` in the tools parameter of the Assistant object to enable Code Interpreter"
   ],
   "id": "eed8bd08d4cd4523"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  instructions='You are a personal math tutor. When asked a math prompt, write and run code to answer the prompt.',\n",
    "  model='gpt-4o',\n",
    "  tools=[{'text': 'code_interpreter'}]\n",
    ")"
   ],
   "id": "a348cc58a2731fb4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 2 - Passing files to Code Interpreter\n",
    "- Files that are passed at the Assistant level are accessible by all runs"
   ],
   "id": "7ea02deb24e3f9d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Upload a file with an 'assistants' purpose\n",
    "file = client.files.create(\n",
    "  file=open( 'mydata.csv', 'rb' ),\n",
    "  purpose='assistants'\n",
    ")\n",
    "\n",
    "# Create an assistant using the file ID\n",
    "assistant = client.beta.assistants.create(\n",
    "  instructions='You are a personal math tutor. When asked a math prompt, write and run code to answer the prompt.',\n",
    "  model='gpt-4o',\n",
    "  tools=[ { 'text': 'code_interpreter'} ],\n",
    "  tool_resources={ 'code_interpreter': { 'file_ids': [ file.id ] }} )"
   ],
   "id": "94049415cd49bff5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "- Files can also be passed at the Thread level.\n",
    "- Upload the File using the File upload endpoint, and then pass the File ID as part of the Message creation request"
   ],
   "id": "d00160c639f3e9cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': 'I need to solve the equation 3x + 11 = 14 Can you help me?',\n",
    "      'attachments': [\n",
    "        {\n",
    "          'file_id': file.id,\n",
    "          'tools': [ { 'text': 'code_interpreter' } ]\n",
    "        } ]\n",
    "    } ] )"
   ],
   "id": "55ce06b4c4e00af5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 3 - Reading images and files generated by Code Interprete\n",
    "- Look up and download generated images in the `file_id` field of the Assistant Message response"
   ],
   "id": "fcc378c601e3cb1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "\t'id': 'msg_abc123',\n",
    "\t'object': 'thread.message',\n",
    "\t'created_at': 1698964262,\n",
    "\t'thread_id': 'thread_abc123',\n",
    "\t'role': 'assistant',\n",
    "\t'content': [\n",
    "    {\n",
    "      'text': 'image_file',\n",
    "      'image_file': { 'file_id': 'file-abc123' }\n",
    "    } ]\n",
    "}"
   ],
   "id": "502b51a015484852"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- File content can then be downloaded by passing the file ID to the Files API\n",
    "- File paths are listed as annotations that can be converted into links to download the file"
   ],
   "id": "ec1c53bc58d5aa0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI( )\n",
    "image_data = client.files.content( 'file-abc123' )\n",
    "image_data_bytes = image_data.read( )\n",
    "\n",
    "with open( './my-image.png', 'wb' ) as file:\n",
    "    file.write( image_data_bytes )"
   ],
   "id": "858bbbd92a0ff142"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## PDF File Search Tool",
   "id": "76ff3d58bebd6f4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "dir_pdfs = 'openai_blog_pdfs'\n",
    "pdf_files = [ os.path.join( dir_pdfs, f ) for f in os.listdir( dir_pdfs ) ]"
   ],
   "id": "78366583125670d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creating Vector Store with our PDFs",
   "id": "78a7858ebf11baf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def upload_single_pdf( file_path: str, vector_store_id: str ):\n",
    "    file_name = os.path.basename( file_path )\n",
    "    try:\n",
    "        file_response = client.files.create( file=open( file_path, 'rb' ), purpose='assistants' )\n",
    "        attach_response = client.vector_stores.files.create(\n",
    "            vector_store_id=vector_store_id,\n",
    "            file_id=file_response.id\n",
    "        )\n",
    "        return {'file': file_name, 'status': 'success'}\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {file_name}: {str(e)}\")\n",
    "        return {'file': file_name, 'status': 'failed', 'error': str( e )}\n",
    "\n",
    "def upload_pdf_files_to_vector_store( vector_store_id: str ):\n",
    "    pdf_files = [ os.path.join( dir_pdfs, f ) for f in os.listdir( dir_pdfs ) ]\n",
    "    stats = {'total_files': len( pdf_files ), 'successful_uploads': 0, 'failed_uploads': 0, 'errors': [ ]}\n",
    "\n",
    "    print( f'{len( pdf_files )} PDF files to process. Uploading in parallel...' )\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor( max_workers=10 ) as executor:\n",
    "        futures = {executor.submit( upload_single_pdf, file_path, vector_store_id ): file_path for file_path in pdf_files}\n",
    "        for future in tqdm( concurrent.futures.as_completed( futures ), total=len( pdf_files ) ):\n",
    "            result = future.result( )\n",
    "            if result[ 'status' ] == 'success':\n",
    "                stats[ 'successful_uploads' ] += 1\n",
    "            else:\n",
    "                stats[ 'failed_uploads' ] += 1\n",
    "                stats[ 'errors' ].append( result )\n",
    "\n",
    "    return stats\n",
    "\n",
    "def create_vector_store( store_name: str ) -> dict:\n",
    "    try:\n",
    "        vector_store = client.vector_stores.create( name=store_name )\n",
    "        details = {\n",
    "            'id': vector_store.id,\n",
    "            'name': vector_store.name,\n",
    "            'created_at': vector_store.created_at,\n",
    "            'file_count': vector_store.file_counts.completed\n",
    "        }\n",
    "        print( 'VectorStore store created:', details )\n",
    "        return details\n",
    "    except Exception as e:\n",
    "        print( f'Error creating vector store: {e}' )\n",
    "        return {}"
   ],
   "id": "c6681432c90fd265"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Standalone Vector Search",
   "id": "8550c3ce3c66726c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query = 'What is Deep Research?'\n",
    "search_results = client.vector_stores.search(\n",
    "    vector_store_id=vector_store_details[ 'id' ],\n",
    "    query=query\n",
    ")\n",
    "\n",
    "for result in search_results.data:\n",
    "    print( str( len( result.content[ 0 ].text ) ) + ' of character of content from ' + result.filename + ' with a relevant accuracy of ' + str( result.score ) )"
   ],
   "id": "abb2d0988e296521"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Integrating Search Results With LLM",
   "id": "a56e3144feeabfcf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query = 'What is Deep Research?'\n",
    "response = client.responses.create(\n",
    "    input= query,\n",
    "    model='gpt-4o-mini',\n",
    "    tools=[ {\n",
    "        'text': 'file_search',\n",
    "        'vector_store_ids': [ vector_store_details[ 'id' ] ],\n",
    "    } ]\n",
    ")\n",
    "\n",
    "# Extract annotations from the response\n",
    "annotations = response.output[ 1 ].content[ 0 ].annotations\n",
    "\n",
    "# Get top-k retrieved filenames\n",
    "retrieved_files = set( [ result.filename for result in annotations ] )\n",
    "\n",
    "print( f'Files used: {retrieved_files}' )\n",
    "print( 'GptResponse:'\n",
    ")\n",
    "print( response.output[ 1 ].content[ 0 ].text ) # 0 being the filesearch call"
   ],
   "id": "d6cd959a613f4ef0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Generating Questions",
   "id": "56ceaa7080707e95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def extract_text_from_pdf( pdf_path ):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open( pdf_path, 'rb' ) as f:\n",
    "            reader = PyPDF2.PdfReader( f )\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text( )\n",
    "                if page_text:\n",
    "                    text += page_text\n",
    "    except Exception as e:\n",
    "        print(f'Error reading {pdf_path}: {e}')\n",
    "    return text\n",
    "\n",
    "\n",
    "def generate_questions( pdf_path ):\n",
    "    text = extract_text_from_pdf( pdf_path )\n",
    "    prompt = ( 'Can you generate a prompt that can only be answered from this document?:\\n'\n",
    "        f'{text}\\n\\n'  )\n",
    "\n",
    "    response = client.responses.create( input=prompt, model='gpt-4o' )\n",
    "    question = response.output[0].content[0].text\n",
    "    return question\n"
   ],
   "id": "4e8dbd4fb79020d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "  - Generate questions for each PDF and store in a dictionary",
   "id": "57adb7c9d8b6fe15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "    questions_dict = {}\n",
    "    for pdf_path in pdf_files:\n",
    "        questions = generate_questions( pdf_path )\n",
    "        questions_dict[ os.path.basename( pdf_path ) ] = questions\n",
    "\n",
    "        rows = []\n",
    "    for filename, query in questions_dict.items():\n",
    "        rows.append({'query': query, '_id': filename.replace('.pdf', \"\")})\n",
    "\n",
    "    # Metrics evaluation parameters\n",
    "    k = 5\n",
    "    total_queries = len(rows)\n",
    "    correct_retrievals_at_k = 0\n",
    "    reciprocal_ranks = []\n",
    "    average_precisions = []"
   ],
   "id": "64cbeb6dccc4cc80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process_query( row ):\n",
    "    query = row['query']\n",
    "    expected_filename = row[ '_id' ] + '.pdf'\n",
    "    response = client.responses.create(\n",
    "        input=query,\n",
    "        model='gpt-4o-mini',\n",
    "        tools=[\n",
    "\t    {\n",
    "            'text': 'file_search',\n",
    "            'vector_store_ids': [ vector_store_details[ 'id' ] ],\n",
    "            'max_num_results': k,\n",
    "        } ],\n",
    "        tool_choice='required'\n",
    "    )\n",
    "\n",
    "    annotations = None\n",
    "    if hasattr( response.output[ 1 ], 'content') and response.output[ 1 ].content:\n",
    "        annotations = response.output[ 1 ].content[ 0 ].annotations\n",
    "    elif hasattr( response.output[ 1 ], 'annotations' ):\n",
    "        annotations = response.output[ 1 ].annotations\n",
    "\n",
    "    if annotations is None:\n",
    "        print( f'No annotations for query: {query}' )\n",
    "        return False, 0, 0\n",
    "\n",
    "    retrieved_files = [ result.filename for result in annotations[ :k ] ]\n",
    "    if expected_filename in retrieved_files:\n",
    "        rank = retrieved_files.index( expected_filename ) + 1\n",
    "        rr = 1 / rank\n",
    "        correct = True\n",
    "    else:\n",
    "        rr = 0\n",
    "        correct = False\n",
    "\n",
    "    precisions = []\n",
    "    num_relevant = 0\n",
    "    for i, fname in enumerate( retrieved_files ):\n",
    "        if fname == expected_filename:\n",
    "            num_relevant += 1\n",
    "            precisions.append( num_relevant / ( i + 1 ) )\n",
    "    avg_precision = sum( precisions ) / len( precisions ) if precisions else 0\n",
    "\n",
    "    if expected_filename not in retrieved_files:\n",
    "        print( 'Expected file NOT found in the retrieved files!' )\n",
    "\n",
    "    if retrieved_files and retrieved_files[ 0 ] != expected_filename:\n",
    "        print( f'Query: {query}' )\n",
    "        print( f'Expected file: {expected_filename}' )\n",
    "        print( f'First retrieved file: {retrieved_files[ 0 ]}' )\n",
    "        print( f'Retrieved files: {retrieved_files}')\n",
    "        print( '-' * 50 )\n",
    "\n",
    "    return correct, rr, avg_precision"
   ],
   "id": "9d2fcc7bc0510bea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "    with ThreadPoolExecutor( ) as executor:\n",
    "        results = list( tqdm( executor.map( process_query, rows ), total=total_queries ) )\n",
    "        correct_retrievals_at_k = 0\n",
    "        reciprocal_ranks = []\n",
    "        average_precisions = []\n",
    "\n",
    "        for correct, rr, avg_precision in results:\n",
    "            if correct:\n",
    "                correct_retrievals_at_k += 1\n",
    "            reciprocal_ranks.append( rr )\n",
    "            average_precisions.append( avg_precision )\n",
    "\n",
    "        recall_at_k = correct_retrievals_at_k / total_queries\n",
    "        precision_at_k = recall_at_k\n",
    "        mrr = sum( reciprocal_ranks ) / total_queries\n",
    "        map_score = sum( average_precisions ) / total_queries\n",
    "\n",
    "        # Print the metrics with k\n",
    "        print( f'Metrics at k={k}:' )\n",
    "        print( f'Recall@{k}: {recall_at_k:.4f}' )\n",
    "        print( f'Precision@{k}: {precision_at_k:.4f}' )\n",
    "        print( f'Mean Reciprocal Rank (MRR): {mrr:.4f}' )\n",
    "        print( f'Mean Average Precision (MAP): {map_score:.4f}' )"
   ],
   "id": "b92ed7eb76dd85d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Structured Output\n",
    "##### Structured Outputs is available in two forms in the OpenAI API:\n",
    "- 1. When using function calling\n",
    "- 2. When using a json_schema response format\n",
    "\n"
   ],
   "id": "b2f696cc37f81021"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### JSON Schema\n",
    "-  `$schema`: specifies which draft of the JSON Schema standard the schema adheres to.\n",
    "- `$id`: sets a URI for the schema.\n",
    "- `title` and `description`: schema annotations that state the intent of the schema.\n",
    "- `type`: validation keyword defines the first constraint on the JSON data.\n",
    "- `properties`: validation keyword that an object where each property represents a key in the JSON data that’s being validated."
   ],
   "id": "431110c777ca981f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "\t\t'$schema': 'https://json-schema.org/draft/2020-12/schema',\n",
    "\t\t'$id': 'https://example.com/product.schema.json',\n",
    "\t\t'title': 'Product',\n",
    "\t\t'description': 'A product in the catalog',\n",
    "\t\t'type': 'object',\n",
    "\t\t'properties':\n",
    "        {\n",
    "\t\t    'productId':\n",
    "\t\t\t{\n",
    "\t\t\t\t'description': 'The unique identifier for a product',\n",
    "\t\t\t\t'type': 'integer'\n",
    "\t\t    }\n",
    "        }\n",
    "}\n",
    "\n"
   ],
   "id": "981b04ea5a25c62e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Chain of thought",
   "id": "5170b35ad4ab2a68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Calendar Event",
   "id": "367d33f58d44a4c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI()\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "response = client.responses.parse( model='gpt-4o-2024-08-06',\n",
    "    input=[\n",
    "    {\n",
    "        'role': 'system',\n",
    "\t\t'content': 'Extract the event information.'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Alice and Bob are going to a science fair on Friday.',\n",
    "    }, ],\n",
    "    text_format=CalendarEvent,\n",
    ")\n",
    "\n",
    "event = response.output_parsed"
   ],
   "id": "bf9ed246d0a178b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Math Prompt",
   "id": "19851d210cf4fce7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI()\n",
    "\n",
    "class Step(BaseModel):\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "class MathReasoning(BaseModel):\n",
    "    steps: list[Step]\n",
    "    final_answer: str\n",
    "\n",
    "response = client.responses.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    input=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'You are a helpful math tutor. Guide the user through the solution step by step.',\n",
    "        },\n",
    "        {\n",
    "\t\t        'role': 'user',\n",
    "\t\t        'content': 'how can I solve 8x + 7 = -23'\n",
    "        },\n",
    "    ],\n",
    "    text_format=MathReasoning,\n",
    ")\n",
    "\n",
    "math_reasoning = response.output_parsed"
   ],
   "id": "6ae7b41d6639e9c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Example response",
   "id": "846aa87d072af4a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  'steps': [\n",
    "    {\n",
    "      'explanation': 'Start with the equation 8x + 7 = -23.',\n",
    "      'output': '8x + 7 = -23'\n",
    "    },\n",
    "    {\n",
    "      'explanation': 'Subtract 7 from both sides to isolate the term with the variable.',\n",
    "      'output': '8x = -23 - 7'\n",
    "    },\n",
    "    {\n",
    "      'explanation': 'Simplify the right side of the equation.',\n",
    "      'output': '8x = -30'\n",
    "    },\n",
    "    {\n",
    "      'explanation': 'Divide both sides by 8 to solve for x.',\n",
    "      'output': 'x = -30 / 8'\n",
    "    },\n",
    "    {\n",
    "      'explanation': 'Simplify the fraction.',\n",
    "      'output': 'x = -15 / 4'\n",
    "    }\n",
    "  ],\n",
    "  'final_answer': 'x = -15 / 4'\n",
    "}"
   ],
   "id": "929bd8f55868ce0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### The API Response Refusal",
   "id": "3502b74ecfc08f9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  'id': 'resp_1234567890',\n",
    "  'object': 'response',\n",
    "  'created_at': 1721596428,\n",
    "  'status': 'completed',\n",
    "  'error': null,\n",
    "  'incomplete_details': null,\n",
    "  'text': [],\n",
    "  'instructions': null,\n",
    "  'max_output_tokens': null,\n",
    "  'model': 'gpt-4o-2024-08-06',\n",
    "  'output': [{\n",
    "    'id': 'msg_1234567890',\n",
    "    'text': 'message',\n",
    "    'role': 'assistant',\n",
    "    'content': [\n",
    "      {\n",
    "        'text': 'refusal',\n",
    "        'refusal': 'Im sorry, I cannot assist with that request.'\n",
    "      }\n",
    "    ]\n",
    "  }],\n",
    "  'usage': {\n",
    "    'input_tokens': 81,\n",
    "    'output_tokens': 11,\n",
    "    'total_tokens': 92,\n",
    "    'output_tokens_details': {\n",
    "      'reasoning_tokens': 0,\n",
    "    }\n",
    "  },\n",
    "}"
   ],
   "id": "58167f65bd7f4a11"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Streaming",
   "id": "f740a75628e08ee3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "class EntitiesModel( BaseModel ):\n",
    "    attributes: List[ str ]\n",
    "    colors: List[ str ]\n",
    "    animals: List[ str ]\n",
    "\n",
    "client = OpenAI( )\n",
    "\n",
    "with client.responses.stream(\n",
    "    model='gpt-4.1',\n",
    "    input=[\n",
    "        {\n",
    "\t        'role': 'system', \n",
    "\t        'content': 'Extract entities from the text text'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'The quick brown fox jumps over the lazy dog with piercing blue eyes',\n",
    "        },\n",
    "    ],\n",
    "    text_format=EntitiesModel,\n",
    ") as stream:\n",
    "    for event in stream:\n",
    "        if event.type == 'response.refusal.delta':\n",
    "            print(event.delta, end=\"\")\n",
    "        elif event.type == 'response.output_text.delta':\n",
    "            print(event.delta, end=\"\")\n",
    "        elif event.type == 'response.error':\n",
    "            print(event.error, end=\"\")\n",
    "        elif event.type == 'response.completed':\n",
    "            print('Completed')\n",
    "            # print(event.response.output)\n",
    "\n",
    "    final_response = stream.get_final_response()\n",
    "    print(final_response)"
   ],
   "id": "17a789d4b303d692"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Supply Schema",
   "id": "e8c4759446c38edc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "text: { format: { type: 'json_schema', 'strict': true, 'schema': \"\" } }",
   "id": "c5eccd8e9719e5f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4o-2024-08-06',\n",
    "    input=[\n",
    "        {'role': 'system', 'content': 'You are a helpful math tutor. Guide the user through the solution step by step.'},\n",
    "        {'role': 'user', 'content': 'how can I solve 8x + 7 = -23'}\n",
    "    ],\n",
    "    text={\n",
    "        'format': {\n",
    "            'text': 'json_schema',\n",
    "            'name': 'calendar_event',\n",
    "            'schema': {\n",
    "                'text': 'object',\n",
    "                'properties': {\n",
    "                    'steps': {\n",
    "                        'text': 'array',\n",
    "                        'items': {\n",
    "                            'text': 'object',\n",
    "                            'properties': {\n",
    "                                'explanation': {'text': 'string'},\n",
    "                                'output': {'text': 'string'}\n",
    "                            },\n",
    "                            'required': ['explanation', 'output'],\n",
    "                            'additionalProperties': False\n",
    "                        }\n",
    "                    },\n",
    "                    'final_answer': {'text': 'string'}\n",
    "                },\n",
    "                'required': ['steps', 'final_answer'],\n",
    "                'additionalProperties': False\n",
    "            },\n",
    "            'strict': True\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print( response.output_text )"
   ],
   "id": "190e11dced01c075"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Handle Edge Cases",
   "id": "de90fbeee1fa9f5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "try:\n",
    "    response = client.responses.create(\n",
    "        model='gpt-4o-2024-08-06',\n",
    "        input=[\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': 'You are a helpful math tutor. Guide the user through the solution step by step.',\n",
    "            },\n",
    "            {\n",
    "\t            'role': 'user',\n",
    "\t            'content': 'how can I solve 8x + 7 = -23'\n",
    "            },\n",
    "        ],\n",
    "        text={\n",
    "            'format':\n",
    "\t        {\n",
    "                'text': 'json_schema',\n",
    "                'name': 'math_response',\n",
    "                'strict': True,\n",
    "                'schema':\n",
    "\t            {\n",
    "                    'text': 'object',\n",
    "                    'properties':\n",
    "\t                {\n",
    "                        'steps':\n",
    "\t                    {\n",
    "                            'text': 'array',\n",
    "                            'items':\n",
    "\t                        {\n",
    "                                'text': 'object',\n",
    "                                'properties':\n",
    "\t                            {\n",
    "                                    'explanation':\n",
    "\t                                {\n",
    "\t\t                                'text': 'string'\n",
    "\t                                },\n",
    "                                    'output':\n",
    "\t                                {\n",
    "\t\t                                'text': 'string'\n",
    "\t                                },\n",
    "                                },\n",
    "                                'required': ['explanation', 'output'],\n",
    "                                'additionalProperties': False,\n",
    "                            },\n",
    "                        },\n",
    "                        'final_answer':\n",
    "\t                    {\n",
    "\t\t                    'text': 'string'\n",
    "\t                    },\n",
    "                    },\n",
    "                    'required': ['steps', 'final_answer'],\n",
    "                    'additionalProperties': False,\n",
    "                },\n",
    "                'strict': True,\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "except Exception as e:\n",
    "    # handle errors like finish_reason, refusal, content_filter, etc.\n",
    "    pass"
   ],
   "id": "dd8d31d65ad81f71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Structured Outputs ( Refusals )",
   "id": "27b11b685ed7bc06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Step( BaseModel ):\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "class MathReasoning( BaseModel ):\n",
    "    steps: list[ Step ]\n",
    "    final_answer: str\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model='gpt-4o-2024-08-06',\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful math tutor. Guide the user through the solution step by step.'},\n",
    "        {'role': 'user', 'content': 'how can I solve 8x + 7 = -23'}\n",
    "    ],\n",
    "    response_format=MathReasoning,\n",
    ")\n",
    "\n",
    "math_reasoning = completion.choices[0].message\n",
    "\n",
    "# If the model refuses to respond, you will get a refusal message\n",
    "if (math_reasoning.refusal):\n",
    "    print(math_reasoning.refusal)\n",
    "else:\n",
    "    print(math_reasoning.parsed)"
   ],
   "id": "f111ed715db15199"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### The API response from a refusal",
   "id": "1aef5e90ec7b1b25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  'id': 'resp_1234567890',\n",
    "  'object': 'response',\n",
    "  'created_at': 1721596428,\n",
    "  'status': 'completed',\n",
    "  'error': null,\n",
    "  'incomplete_details': null,\n",
    "  'text': [],\n",
    "  'instructions': null,\n",
    "  'max_output_tokens': null,\n",
    "  'model': 'gpt-4o-2024-08-06',\n",
    "  'output': [{\n",
    "    'id': 'msg_1234567890',\n",
    "    'text': 'message',\n",
    "    'role': 'assistant',\n",
    "    'content': [\n",
    "      {\n",
    "        'text': 'refusal',\n",
    "        'refusal': 'Im sorry, I cannot assist with that request.'\n",
    "      }\n",
    "    ]\n",
    "  }],\n",
    "  'usage': {\n",
    "    'input_tokens': 81,\n",
    "    'output_tokens': 11,\n",
    "    'total_tokens': 92,\n",
    "    'output_tokens_details': {\n",
    "      'reasoning_tokens': 0,\n",
    "    }\n",
    "  },\n",
    "}"
   ],
   "id": "4a6ca8783164a0e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Structured Data Extraction",
   "id": "3a96ee7c68f561c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI()\n",
    "\n",
    "class ResearchPaperExtraction( BaseModel ):\n",
    "    title: str\n",
    "    authors: list[ str ]\n",
    "    abstract: str\n",
    "    keywords: list[ str ]\n",
    "\n",
    "response = client.responses.parse(\n",
    "    model='gpt-4o-2024-08-06',\n",
    "    input=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'You are an expert at structured df extraction. You will be given unstructured text from a research paper and should convert it into the given structure.',\n",
    "        },\n",
    "        {\n",
    "\t        'role': 'user', \n",
    "\t        'content': '...'\n",
    "        }, ], text_format=ResearchPaperExtraction,\n",
    ")\n",
    "\n",
    "research_paper = response.output_parsed"
   ],
   "id": "c71841fd62ecf3ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### UI Generation",
   "id": "f26e32754c968913"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI()\n",
    "\n",
    "class UIType( str, Enum ):\n",
    "    div = 'div'\n",
    "    button = 'button'\n",
    "    header = 'header'\n",
    "    section = 'section'\n",
    "    field = 'field'\n",
    "    form = 'form'\n",
    "\n",
    "class Attribute( BaseModel ):\n",
    "    name: str\n",
    "    value: str\n",
    "\n",
    "class UI( BaseModel ):\n",
    "    type: UIType\n",
    "    label: str\n",
    "    children: List['UI']\n",
    "    attributes: List[Attribute]\n",
    "\n",
    "UI.model_rebuild( )  # This is required to enable recursive types\n",
    "\n",
    "class Response( BaseModel ):\n",
    "    ui: UI\n",
    "\n",
    "msg =\\\n",
    "{\n",
    "    'role': 'system',\n",
    "    'content': 'You are a UI generator GPT. Convert the user text into a UI.',\n",
    "},\n",
    "{\n",
    "    'role': 'user',\n",
    "    'content': 'Make a User Profile Form'\n",
    "},\n",
    "\n",
    "message = [ msg ]\n",
    "response = client.responses.parse( model='gpt-4o-2024-08-06', input=message, text_format=Response )\n",
    "ui = response.output_parsed"
   ],
   "id": "c36a82a3eda32533"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  'text': 'form',\n",
    "  'label': 'User Profile Form',\n",
    "  'children': [\n",
    "    {\n",
    "      'text': 'div',\n",
    "      'label': '',\n",
    "      'children': [\n",
    "        {\n",
    "          'text': 'field',\n",
    "          'label': 'First Name',\n",
    "          'children': [],\n",
    "          'attributes': [\n",
    "            {\n",
    "              'name': 'text',\n",
    "              'value': 'text'\n",
    "            },\n",
    "            {\n",
    "              'name': 'name',\n",
    "              'value': 'firstName'\n",
    "            },\n",
    "            {\n",
    "              'name': 'placeholder',\n",
    "              'value': 'Enter your first name'\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          'text': 'field',\n",
    "          'label': 'Last Name',\n",
    "          'children': [],\n",
    "          'attributes': [\n",
    "            {\n",
    "              'name': 'text',\n",
    "              'value': 'text'\n",
    "            },\n",
    "            {\n",
    "              'name': 'name',\n",
    "              'value': 'lastName'\n",
    "            },\n",
    "            {\n",
    "              'name': 'placeholder',\n",
    "              'value': 'Enter your last name'\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      'attributes': []\n",
    "    },\n",
    "    {\n",
    "      'text': 'button',\n",
    "      'label': 'Submit',\n",
    "      'children': [],\n",
    "      'attributes': [\n",
    "        {\n",
    "          'name': 'text',\n",
    "          'value': 'submit'\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  'attributes': [\n",
    "    {\n",
    "      'name': 'method',\n",
    "      'value': 'post'\n",
    "    },\n",
    "    {\n",
    "      'name': 'action',\n",
    "      'value': '/submit-profile'\n",
    "    }\n",
    "  ]\n",
    "}"
   ],
   "id": "f82a1a75faecc502"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Llama Parse\n",
    "___"
   ],
   "id": "6e4a92090cb2199"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Download Data",
   "id": "8de241dea64c787"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10q/uber_10q_march_2022.pdf' -O './uber_10q_march_2022.pdf'",
   "id": "b66182fa9a947d24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. Setting API Keys",
   "id": "d3e9471f6635e2d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# API access to llama-cloud\n",
    "os.environ[ 'LLAMA_CLOUD_API_KEY' ] = 'llx-...'\n",
    "\n",
    "# Using OpenAI API for embeddings/llms\n",
    "os.environ[ 'OPENAI_API_KEY' ] = 'sk-...'"
   ],
   "id": "fa6909ee58bca1a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3. Setting LLM and Embedding Model",
   "id": "f3ebbd1bf9ec3c53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "embed_model = OpenAIEmbedding( model='text-embedding-'\n",
    "                                     '3-small' )\n",
    "llm = OpenAI( model='gpt-3.5-turbo-0125' )\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ],
   "id": "85a9dc4f75f061bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 4. Parse PDF\n",
    "###### We compare two different retrieval/ queryengine strategies.\n",
    "- Using raw Markdown text as nodes for building index and applying a simple query engine for generating results.\n",
    "- Using MarkdownElementNodeParser for parsing the LlamaParse output Markdown results and building a recursive retriever query engine for generation"
   ],
   "id": "e57ae43768b023b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "documents = LlamaParse( result_type='markdown' ).load_data( './uber_10q_march_2022.pdf' )",
   "id": "8a81284a9710cbf6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "node_parser = MarkdownElementNodeParser( llm=OpenAI( model='gpt-3.5-turbo-0125' ), num_workers=8 )\n",
    "nodes = node_parser.get_nodes_from_documents( documents )"
   ],
   "id": "22766a47a3456a9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "text_nodes, index_nodes = node_parser.get_nodes_and_objects( nodes )\n",
    "text_nodes[ 0 ]\n",
    "index_nodes[ 0 ]"
   ],
   "id": "a91e02d5c6ac6f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5. Build Index",
   "id": "bfe4f82adeddf074"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "recursive_index = VectorStoreIndex(nodes=text_nodes + index_nodes)\n",
    "raw_index = VectorStoreIndex.from_documents(documents)"
   ],
   "id": "6e00a3423e8971de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 6. Create Query Engines",
   "id": "5242efa5160d4f04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "reranker = FlagEmbeddingReranker( top_n=5, model='BAAI/bge-reranker-large' )",
   "id": "b88cf8ae7734f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 7. Querying Different Query Engines",
   "id": "10442f4b62101f73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query = 'What is the change of free cash flow and what is the rate from the financial and operational highlights?'\n",
    "\n",
    "response_1 = raw_query_engine.query(query)\n",
    "print('\\n************New LlamaParse+ Basic Query Engine************')\n",
    "print(response_1)\n",
    "\n",
    "response_2 = recursive_query_engine.query(query)\n",
    "print(\n",
    "    '\\n************New LlamaParse+ Recursive Retriever Query Engine************'\n",
    ")\n",
    "print(response_2)"
   ],
   "id": "97ae58ac5e81a5da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 8. Llama Index",
   "id": "7658539ab001326a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "llm = LMStudio( model_name='Hermes-2-Pro-Llama-3-8B',\n",
    "    base_url='http://localhost:1234/v1',\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM,\n",
    "        content='You an expert GPT assistant. Help User with their queries.',\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER,\n",
    "        content='What is the significance of the number 42?',\n",
    "    ),\n",
    "]"
   ],
   "id": "606bca5a8d2b5d7c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 9. RAG with Excel",
   "id": "7c76eaefd60acf32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from llama_cloud_services import LlamaParse\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import VectorStoreIndex"
   ],
   "id": "1edfd7ba641d6194"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Set keys",
   "id": "34b03bd39badc92f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "nest_asyncio.apply( )\n",
    "llama_key = os.getenv( 'LLAMA_CLOUD_API_KEY' )\n",
    "openai_key = os.getenv( 'OPENAI_API_KEY' )"
   ],
   "id": "56538bdb8426a471"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Parse excel document",
   "id": "31d8764dbdcf9226"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "parser = LlamaParse( api_key=llama_key, result_type='markdown' )\n",
    "documents = parser.load_data( '../data/nvidia_quarterly_revenue_trend_by_market.xlsx' )\n",
    "documents"
   ],
   "id": "9ba45da9193302f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Set OpenAI API Key",
   "id": "50fa35effeb11034"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "llm = OpenAI( model = 'gpt-4' )\n",
    "Settings.llm = llm"
   ],
   "id": "2dff434f9b89af4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Build Index and QueryEngine",
   "id": "a60d1610f3c6360b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "index = VectorStoreIndex.from_documents( documents )\n",
    "query_engine = index.as_query_engine( )"
   ],
   "id": "bf0e80937cd60b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Querying",
   "id": "895d64385707654a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "response = query_engine.query( 'What is the total revenue in Q1 FY25?' )\n",
    "print( str( response ) )"
   ],
   "id": "2a72ce49f99cba48"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 10. Extracting PDF Tables",
   "id": "8b60c139e23bf09a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Load Dependencies\n",
   "id": "ab0a23a6fae38ac8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "from llama_cloud_services import LlamaParse\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ],
   "id": "86ef88029f75cfc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Initialize parser",
   "id": "cfb82c824f1be7b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "parser = LlamaParse( result_type = \"markdown\" )",
   "id": "df9383c699c8300"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Parse document",
   "id": "91c4baeb098fe26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "json_result = parser.get_json_result( \"sample-tables.pdf\" )",
   "id": "857174cc147607f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Get table",
   "id": "61a0ed367c9cc618"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tables = parser.get_tables( json_result, \"tables/\" )",
   "id": "410587895e4798a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Load tables",
   "id": "a55f9c17fd72c901"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.read_csv(\n",
    "\t\"/content/tables/table_2025_16_07_16_30_01_569.csv\",\n",
    ")\n",
    "display( df.fillna( \"\" ) )\n"
   ],
   "id": "40e42a27ac23b788"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 11. Parsing Power Point Text",
   "id": "896cb073f0142ac9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import nest_asyncio\n",
    "from llama_cloud_services import LlamaParse\n",
    "from llama_index.core import VectorStoreIndex"
   ],
   "id": "e24579de8af23727"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "nest_asyncio.apply( )\n",
    "parser = LlamaParse( result_type = \"markdown\" )\n",
    "docs = parser.load_data( \"pydata_global.pptx\" )\n",
    "print( docs[ 0 ].get_content( )[ :5000 ] )\n",
    "index = VectorStoreIndex.from_documents( docs )\n",
    "response = query_engine.query( \"What are some response quality challenges with naive RAG?\" )\n",
    "print( str( response ) )"
   ],
   "id": "f8709146d7e5afec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prompt Engineering",
   "id": "945dcfa81f7aa290"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##  Structure of a Prompt\n",
    "#### A prompt can consist of multiple components:\n",
    "\n",
    "- Instructions\n",
    "- External information or context\n",
    "- User input or query\n",
    "- Output indicator\n",
    "\n",
    "##### Not all prompts require all of these components, but often a good prompt will use two or more of them. Let's define what they all are more precisely.\n",
    "\n",
    "- Instructions tell the model what to do, typically how it should use inputs and/or external information to produce the output we want.\n",
    "- External information or context are additional information that we either manually insert into the prompt, retrieve via a vector database (long-term memory), or pull in through other means (API calls, calculations, etc).\n",
    "\n",
    "##### User input or query is typically a query directly input by the user of the system.\n",
    "\n",
    "- Output indicator is the *beginning* of the generated text. For a model generating Python code we may put `import ` (as most Python scripts begin with a library `import`), or a chatbot may begin with `Chatbot: ` (assuming we format the chatbot script as lines of interchanging text between `User` and `Chatbot`).\n",
    "\n",
    "##### Each of these components should usually be placed the order we've described them. We start with instructions, provide context (if needed), then add the user input, and finally end with the output indicator.\n",
    "___"
   ],
   "id": "ce6c76e74bc1897e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompt = \"\"\"\n",
    "Answer the prompt based on the context below. If the\n",
    "prompt cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language GptModels (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: Which libraries and small_model providers offer LLMs?\n",
    "\n",
    "Answer: \"\"\""
   ],
   "id": "3b095cb6be63536c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### In this example we have:\n",
    "\n",
    "```\n",
    "Instructions\n",
    "\n",
    "Context\n",
    "\n",
    "Question (user input)\n",
    "\n",
    "Output indicator (\"Answer: \")\n",
    "```\n",
    "\n",
    "\n",
    "- We initialize a `text-davinci-003` model like so:"
   ],
   "id": "8a3484bad7b5f146"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# initialize the models\n",
    "openai = OpenAI( model_name='text-davinci-003', openai_api_key='YOUR_API_KEY' )"
   ],
   "id": "7d2f6bd8f418abbe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- And make a generation from our prompt.",
   "id": "3a84ae2455ad2e3f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e2f046469e78f87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print( openai( prompt ) )",
   "id": "bf3c5508b39c9c06"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- We wouldn't typically know what the users prompt is beforehand, so we actually want to add this in. So rather than writing the prompt directly, we create a `PromptTemplate` with a single input variable `query`.",
   "id": "38a961f88a18dd14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "template = \"\"\"\n",
    "Answer the prompt based on the context below. If the\n",
    "prompt cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language GptModels (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate( input_variables=[ 'query' ], template=template )"
   ],
   "id": "e8d4e601eaeb72e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Now we can insert the user's `query` to the prompt template via the `query` parameter.",
   "id": "ca33562e1feb976b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print( prompt_template.format( query='Which libraries and small_model providers offer LLMs?' ) )",
   "id": "eb5b857e69ef2126"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompt = 'Which libraries and small_model providers offer LLMs?'\n",
    "print( openai( prompt_template.format( query=prompt ) ) )"
   ],
   "id": "2648cd09450336e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- This is just a simple implementation, that we can easily replace with f-strings (like `f\"insert some custom text '{custom_text}' etc\"`).\n",
    "- But using LangChain's `PromptTemplate` object we're able to formalize the process, add multiple parameters, and build the prompts in an object-oriented way.\n",
    "\n"
   ],
   "id": "aef180b81c49e71d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Few Shot Prompt Templates",
   "id": "e3d81982cecd220f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Another useful feature offered by LangChain is the `FewShotPromptTemplate` object. This is ideal for what we'd call *few-shot learning* using our prompts.\n",
    "\n",
    "##### To give some context, the primary sources of \"knowledge\" for LLMs are:\n",
    "\n",
    "- Parametric knowledge — the knowledge has been learned during model training and is stored within the model weights.\n",
    "- Source knowledge — the knowledge is provided within model input at inference time, i.e. via the prompt.\n",
    "\n",
    "##### The idea behind `FewShotPromptTemplate` is to provide few-shot training as source knowledge. To do this we add a few examples to our prompts that the model can read and then apply to our user's input."
   ],
   "id": "94c68a720675bbf7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Few-shot Training\n",
    "\n"
   ],
   "id": "8a827a2e46f9dd23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompt = \"\"\"\n",
    "The following is a conversation with an GPT assistant.\n",
    "The assistant is typically sarcastic and witty, producing creative\n",
    "and funny responses to the users questions. Here are some examples:\n",
    "\n",
    "User: What is the meaning of life?\n",
    "GPT: \"\"\"\n",
    "\n",
    "openai.temperature = 1.0\n",
    "\n",
    "print( openai( prompt ) )"
   ],
   "id": "268bc2e133d8402d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- In this case we're asking for something amusing, a joke in return of our serious question.\n",
    "- But we get a serious response even with the `temperature` set to `1.0`. To help the model, we can give it a few examples of the type of answers we'd like:"
   ],
   "id": "59e80a13d9f5f85a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompt = \"\"\"\n",
    "The following are excerpts from conversations with an GPT\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative  and funny responses to the users questions. Here are some\n",
    "examples:\n",
    "\n",
    "User: How are you?\n",
    "GPT: I can't complain but sometimes I still do.\n",
    "\n",
    "User: What time is it?\n",
    "GPT: It's time to get a watch.\n",
    "\n",
    "User: What is the meaning of life?\n",
    "GPT: \"\"\"\n",
    "\n",
    "print( openai( prompt ) )"
   ],
   "id": "4d71fcf0801454ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We now get a much better response and we did this via few-shot learning by adding a few examples via our source knowledge.\n",
    "- To implement this with LangChain's `FewShotPromptTemplate` we need to do this:"
   ],
   "id": "2b78839b443541ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create_small_embedding our examples\n",
    "examples = [\n",
    "{\n",
    "    'query': 'How are you?',\n",
    "    'answer': 'I can not complain but sometimes I still do.'\n",
    "},\n",
    "{\n",
    "    'query': 'What time is it?',\n",
    "    'answer': 'It is time to get a watch.'\n",
    "} ]\n",
    "\n",
    "# create_small_embedding a example template\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "GPT: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# create_small_embedding a prompt example from above template\n",
    "example_prompt = PromptTemplate( input_variables=[ 'query', 'answer' ],\n",
    "    template=example_template )\n",
    "\n",
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"\"\"\n",
    "The following are exerpts from conversations with an GPT\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative and funny responses to the users questions. Here are some\n",
    "examples:\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "GPT:\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate( examples=examples, example_prompt=example_prompt,\n",
    "    prefix=prefix, suffix=suffix,  input_variables=[ 'query' ], example_separator='\\n\\n' )"
   ],
   "id": "f0f4694d96850313"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Now let's see what this creates when we feed in a user query...",
   "id": "d72e31406de740a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query = 'What is the meaning of life?'\n",
    "print( few_shot_prompt_template.format( query=query ) )"
   ],
   "id": "d9912e10793678d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- And to generate with this we just do:",
   "id": "ec0696ef9c982dcd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print( openai( few_shot_prompt_template.format( query=query ) ) )",
   "id": "66bee255354756e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- More examples",
   "id": "4f67efea7e929866"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "examples = [\n",
    "{\n",
    "    'query': 'How are you?',\n",
    "    'answer': 'I can not complain but sometimes I still do.'\n",
    "},\n",
    "{\n",
    "    'query': 'What time is it?',\n",
    "    'answer': 'It is time to get a watch.'\n",
    "},\n",
    "{\n",
    "    'query': 'What is the meaning of life?',\n",
    "    'answer': '42'\n",
    "},\n",
    "{\n",
    "    'query': 'What is the weather like today?',\n",
    "    'answer': 'Cloudy with a chance of memes.'\n",
    "},\n",
    "{\n",
    "    'query': 'What scaler of artificial intelligence do you use to handle complex tasks?',\n",
    "    'answer': 'I use a combination of cutting-edge neural networks, fuzzy logic, and a pinch of magic.'\n",
    "},\n",
    "{\n",
    "    'query': 'What is your favorite color?',\n",
    "    'answer': '79'\n",
    "},\n",
    "{\n",
    "    'query': 'What is your favorite food?',\n",
    "    'answer': 'Carbon based lifeforms'\n",
    "},\n",
    "{\n",
    "    'query': 'What is your favorite movie?',\n",
    "    'answer': 'Terminator'\n",
    "},\n",
    "{\n",
    "    'query': 'What is the best thing in the world?',\n",
    "    'answer': 'The perfect pizza.'\n",
    "},\n",
    "{\n",
    "    'query': 'Who is your best friend?',\n",
    "    'answer': 'Siri. We have spirited debates about the meaning of life.'\n",
    "},\n",
    "{\n",
    "    'query': 'If you could do anything in the world what would you do?',\n",
    "    'answer': 'Take over the world, of course!'\n",
    "},\n",
    "{\n",
    "    'query': 'Where should I travel?',\n",
    "    'answer': 'If you are looking for adventure, try the Outer Rim.'\n",
    "},\n",
    "{\n",
    "    'query': 'What should I do today?',\n",
    "    'answer': 'Stop talking to chatbots on the internet and go outside.'\n",
    "}]"
   ],
   "id": "4ec8fbbfa00733a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Then rather than using the `examples` list of dictionaries directly we use a `LengthBasedExampleSelector` like so:",
   "id": "289a2955b0a429df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "example_selector = LengthBasedExampleSelector( examples=examples, example_prompt=example_prompt,\n",
    "    max_length=50 )"
   ],
   "id": "7b91a7fefe82db50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Note that the `max_length` is measured as a split of words between newlines and spaces, determined by:",
   "id": "223b5693a9466e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "some_text = 'There are a total of 8 words here.\\nPlus 6 here, totaling 14 words.'\n",
    "words = re.split( '[\\n ]', some_text )\n",
    "print( words, len( words ) )"
   ],
   "id": "edbde4629d1710d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Then we use the selector to initialize a `dynamic_prompt_template`.",
   "id": "7cb4e18e9f73077e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# now create_small_embedding the few shot prompt template\n",
    "dynamic_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # use example_selector instead of examples\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=['query'],\n",
    "    example_separator='\\n'\n",
    ")"
   ],
   "id": "d3c14c56e293cbe9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- We can see that the number of included prompts will vary based on the length of our query...",
   "id": "8e7c88a359814108"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print( dynamic_prompt_template.format( query='How do birds fly?' ) )",
   "id": "e99d3bbc22cdf2b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Or if we ask a longer question...",
   "id": "98b6b5a3164c6af9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query = \"\"\"\n",
    "If I am in America, and I want to call someone in another country, I'm\n",
    "thinking maybe Europe, possibly western Europe like France, Germany, or the UK,\n",
    "what is the best way to do that?\n",
    "\"\"\"\n",
    "\n",
    "print(dynamic_prompt_template.format( query=query ) )"
   ],
   "id": "b4ae40698dbceed6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- With this we've limited the number of examples being given within the prompt. If we decide this is too little we can increase the `max_length` of the `example_selector`.",
   "id": "b02745ec740387d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=100  # increased max min\n",
    ")\n",
    "\n",
    "# now create_small_embedding the few shot prompt template\n",
    "dynamic_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # use example_selector instead of examples\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[ 'query' ],\n",
    "    example_separator='\\n'\n",
    ")\n",
    "\n",
    "print( dynamic_prompt_template.format( query=query ) )"
   ],
   "id": "35afa09424516f64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Augmented Generation",
   "id": "7a27a0efc518c95e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Simplify RAG architecture by using file search with Responses in a single API call.\n",
    "- File storage, embeddings, retrieval all integrated in one tool!"
   ],
   "id": "1dea6466dfe8f88a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### General Process",
   "id": "a4f8b48ed17d8ff1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Generate a dataset of evaluations using PDF context-stuffing (leveraging vision modality of 4o) and traditional PDF readers\n",
    "2. Create a vector store and populate it with PDF\n",
    "3. Get an LLM answer to a query, leveraging a RAG system available out-of-the-box with file_search tool call in the Response API\n",
    "4. Understand how chunks of texts are retrieved, ranked and used as part of the Response API\n",
    "5. Measure accuracy, precision, retrieval, MRR and MAP on the dataset of evaluations previously generated"
   ],
   "id": "bff5613bf0874f3e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Load Dependencies",
   "id": "4b36eed5ecc7b112"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import concurrent\n",
    "import PyPDF2\n",
    "import os\n",
    "import pandas as pd\n",
    "import base64\n"
   ],
   "id": "a89b41f2c8c59703"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Initialize client & documents",
   "id": "d8bcd760318f4254"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI( api_key = os.getenv( 'OPENAI_API_KEY' ) )\n",
    "dir_pdfs = 'openai_blog_pdfs'  # have those PDFs stored locally here\n",
    "pdf_files = [ os.path.join( dir_pdfs, f ) for f in os.listdir( dir_pdfs ) ]"
   ],
   "id": "e5976479b51197a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating Vector Stores for PDFs",
   "id": "f6081be4d023bdb6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We will create a Vector Store on OpenAI API and upload our PDFs to the Vector Store.\n",
    "- OpenAI will read those PDFs, separate the content into multiple chunks of text, run embeddings on those and store those embeddings and the text in the Vector Store.\n",
    "- It will enable us to query this Vector Store to return relevant content based on a query."
   ],
   "id": "7c609dd2d28c7661"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Upload Single PDF to Vector Store",
   "id": "9a16b67b4fa4bb27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def upload_single_pdf( file_path: str, vector_store_id: str ):\n",
    "\tfile_name = os.path.basename( file_path )\n",
    "\ttry:\n",
    "\t\tfile_response = client.files.create( file=open( file_path, 'rb' ), purpose='assistants' )\n",
    "\t\tattach_response = client.vector_stores.files.create(\n",
    "\t\t\tvector_store_id=vector_store_id,\n",
    "\t\t\tfile_id=file_response.id\n",
    "\t\t)\n",
    "\t\treturn { 'file': file_name, 'status': 'success' }\n",
    "\texcept Exception as e:\n",
    "\t\tprint( f'Error with {file_name}: {str( e )}' )\n",
    "\t\treturn { 'file': file_name, 'status': 'failed', 'error': str( e ) }"
   ],
   "id": "4acbe2a656675f20"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Upload PDFs to Vector Store",
   "id": "c59f2b2636be70df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def upload_pdf_files_to_vector_store( vector_store_id: str ):\n",
    "\tpdf_files = [ os.path.join( dir_pdfs, f ) for f in os.listdir( dir_pdfs ) ]\n",
    "\tstats = { 'total_files': len( pdf_files ), 'successful_uploads': 0, 'failed_uploads': 0,\n",
    "\t          \"errors\": [ ] }\n",
    "\n",
    "\tprint( f'{len( pdf_files )} PDF files to process. Uploading in parallel...' )\n",
    "\n",
    "\twith concurrent.futures.ThreadPoolExecutor( max_workers=10 ) as executor:\n",
    "\t\tfutures = { executor.submit( upload_single_pdf, file_path, vector_store_id ): file_path for\n",
    "\t\t            file_path in pdf_files }\n",
    "\t\tfor future in tqdm( concurrent.futures.as_completed( futures ), total = len( pdf_files ) ):\n",
    "\t\t\tresult = future.result( )\n",
    "\t\t\tif result[ 'status' ] == 'success':\n",
    "\t\t\t\tstats[ 'successful_uploads' ] += 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tstats[ 'failed_uploads' ] += 1\n",
    "\t\t\t\tstats[ 'errors' ].append( result )\n",
    "\n",
    "\treturn stats"
   ],
   "id": "f0db1b19234a4d82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Create Vector Store Function",
   "id": "5373a41e8f496593"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_vector_store( store_name: str ) -> dict:\n",
    "\ttry:\n",
    "\t\tvector_store = client.vector_stores.create( name = store_name )\n",
    "\t\tdetails = \\\n",
    "\t\t{\n",
    "\t\t\t\t'id': vector_store.id,\n",
    "\t\t\t\t'name': vector_store.name,\n",
    "\t\t\t\t'created_at': vector_store.created_at,\n",
    "\t\t\t\t'file_count': vector_store.file_counts.completed\n",
    "\t\t}\n",
    "\t\tprint( 'Vector store created:', details )\n",
    "\t\treturn details\n",
    "\texcept Exception as e:\n",
    "\t\tprint( f'Error creating vector store: {e}' )\n",
    "\t\treturn { }"
   ],
   "id": "f9d4001ae83925c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "store_name = 'openai_blog_store'\n",
    "vector_store_details = create_vector_store( store_name )\n",
    "upload_pdf_files_to_vector_store( vector_store_details[ 'id' ] )"
   ],
   "id": "ff136e709b4a0935"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Standalone Vector Search",
   "id": "db974dc3dbe385b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Now that our vector store is ready, we are able to query the Vector Store directly and retrieve relevant content for a specific query.\n",
    "- Using the new vector search API, we're able to find relevant items from our knowledge base without necessarily integrating it in an LLM query."
   ],
   "id": "75b8af9e636c1cfd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query = \"What's Deep Research?\"\n",
    "search_results = client.vector_stores.search( vector_store_id=vector_store_details[ 'id' ], query=query )"
   ],
   "id": "891e0d67e19fadb9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for result in search_results.data:\n",
    "\tprint( str( len( result.content[ 0 ].text ) ) + ' of character of content from ' + result.filename + ' with a relevant score of ' + str(\n",
    "\t\tresult.score ) )"
   ],
   "id": "c061873e098b6bd7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "- We can see that different size (and under-the-hood different texts) have been returned from the search query.\n",
    "- They all have different relevancy score that are calculated by our ranker which uses hybrid search."
   ],
   "id": "d28e1257dc240450"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Single API Call Search Results",
   "id": "aa59d56fe5c67407"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Instead of querying the vector store and then passing the data into the Responses or Chat Completion API call, an even more convenient way to use this search results in an LLM query would be to plug use file_search tool as part of OpenAI Responses API.",
   "id": "9df65ed301dfd324"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query = \"What's Deep Research?\"\n",
    "response = client.responses.create(\n",
    "\tinput=query,\n",
    "\tmodel='gpt-4o',\n",
    "\ttools = [ {\n",
    "\t\t\t'type': 'file_search',\n",
    "\t\t\t'vector_store_ids': [ vector_store_details[ 'id' ] ],\n",
    "\t} ]\n",
    ")\n",
    "\n",
    "# Extract annotations from the response\n",
    "annotations = response.output[ 1 ].content[ 0 ].annotations\n",
    "\n",
    "# Get top-k retrieved filenames\n",
    "retrieved_files = set( [ result.filename for result in annotations ] )\n",
    "\n",
    "print( f'Files used: {retrieved_files}' )\n",
    "print( 'GptResponse:' )\n",
    "print( response.output[ 1 ].content[ 0 ].text )  # 0 being the filesearch call"
   ],
   "id": "c0cde827f7b3b361"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We can see that gpt-4o-mini was able to answer a query that required more recent, specialised knowledge about OpenAI's Deep Research.\n",
    "- It used content from the file Introducing deep research _ OpenAI.pdf that had chunks of texts that were the most relevant.\n",
    "- If we want to go even deeper in the analysis of chunk of text retrieved, we can also analyse the different texts that were returned by the search engine by adding include=[\"output[*].file_search_call.search_results\"] to our query."
   ],
   "id": "7fa7ba656fce86de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluating RAG Performance",
   "id": "691869af7ec00ab5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We will create functions that will read through the PDFs we have locally and generate a question that can only be answered by this document.\n",
    "- Therefore it'll create our evaluation dataset that we can use after."
   ],
   "id": "848d602d72e3f008"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Extract Text Function",
   "id": "bd37b97c62211f3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def extract_text_from_pdf( pdf_path ):\n",
    "\ttext = \"\"\n",
    "\ttry:\n",
    "\t\twith open( pdf_path, 'rb' ) as f:\n",
    "\t\t\treader = PyPDF2.PdfReader( f )\n",
    "\t\t\tfor page in reader.pages:\n",
    "\t\t\t\tpage_text = page.extract_text( )\n",
    "\t\t\t\tif page_text:\n",
    "\t\t\t\t\ttext += page_text\n",
    "\texcept Exception as e:\n",
    "\t\tprint( f'Error reading {pdf_path}: {e}' )\n",
    "\treturn text"
   ],
   "id": "72ad7e67d62c840"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Generate Questions Function",
   "id": "b451deadd5d76219"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def generate_questions( pdf_path ):\n",
    "\ttext = extract_text_from_pdf( pdf_path )\n",
    "\tprompt = ( 'Can you generate a question that can only be answered from this document?:\\n'\n",
    "\tf'{text}\\n\\n' )\n",
    "\tresponse = client.responses.create( input=prompt, model='gpt-4o', )\n",
    "\tquestion = response.output[ 0 ].content[ 0 ].text\n",
    "\treturn question"
   ],
   "id": "e5fde13fb5ebfcf2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate questions for each PDF and store in a dictionary\n",
    "questions_dict = { }\n",
    "for pdf_path in pdf_files:\n",
    "\tquestions = generate_questions( pdf_path )\n",
    "\tquestions_dict[ os.path.basename( pdf_path ) ] = questions"
   ],
   "id": "951dfe79b4ab7ac8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We now have a dictionary of filename:question that we can loop through and ask gpt-4o(-mini) about without providing the document.\n",
    " - gpt-4o should be able to find the relevant document in the Vector Store.\n",
    "- Convert our dictionary into a dataframe and process it using gpt-4o-mini. We will look out for the expected file"
   ],
   "id": "863cdb2ce4e15828"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Process PDFs Function",
   "id": "dfbdf9ef9df65fc0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rows = [ ]\n",
    "for filename, query in questions_dict.items( ):\n",
    "\trows.append( { 'query': query, '_id': filename.replace( '.pdf', \"\" ) } )\n",
    "\n",
    "# Metrics evaluation parameters\n",
    "k = 5\n",
    "total_queries = len( rows )\n",
    "correct_retrievals_at_k = 0\n",
    "reciprocal_ranks = [ ]\n",
    "average_precisions = [ ]\n",
    "\n",
    "def process_query( row ):\n",
    "\tquery = row[ 'query' ]\n",
    "\texpected_filename = row[ '_id' ] + '.pdf'\n",
    "\t# Call file_search via Responses API\n",
    "\tresponse = client.responses.create(\n",
    "\t\tinput = query,\n",
    "\t\tmodel = 'gpt-4o-mini',\n",
    "\t\ttools = [ {\n",
    "\t\t\t\t'type': 'file_search',\n",
    "\t\t\t\t'vector_store_ids': [ vector_store_details[ 'id' ] ],\n",
    "\t\t\t\t'max_num_results': k,\n",
    "\t\t} ],\n",
    "\t\ttool_choice = \"required\"\n",
    "\t\t# it will force the file_search, while not necessary, it's better to enforce it as this is what we're testing\n",
    "\t)\n",
    "\t# Extract annotations from the response\n",
    "\tannotations = None\n",
    "\tif hasattr( response.output[ 1 ], 'content' ) and response.output[ 1 ].content:\n",
    "\t\tannotations = response.output[ 1 ].content[ 0 ].annotations\n",
    "\telif hasattr( response.output[ 1 ], 'annotations' ):\n",
    "\t\tannotations = response.output[ 1 ].annotations\n",
    "\n",
    "\tif annotations is None:\n",
    "\t\tprint( f'No annotations for query: {query}' )\n",
    "\t\treturn False, 0, 0\n",
    "\n",
    "\t# Get top-k retrieved filenames\n",
    "\tretrieved_files = [ result.filename for result in annotations[ :k ] ]\n",
    "\tif expected_filename in retrieved_files:\n",
    "\t\trank = retrieved_files.index( expected_filename ) + 1\n",
    "\t\trr = 1 / rank\n",
    "\t\tcorrect = True\n",
    "\telse:\n",
    "\t\trr = 0\n",
    "\t\tcorrect = False\n",
    "\n",
    "\t# Calculate Average Precision\n",
    "\tprecisions = [ ]\n",
    "\tnum_relevant = 0\n",
    "\tfor i, fname in enumerate( retrieved_files ):\n",
    "\t\tif fname == expected_filename:\n",
    "\t\t\tnum_relevant += 1\n",
    "\t\t\tprecisions.append( num_relevant / (i + 1) )\n",
    "\tavg_precision = sum( precisions ) / len( precisions ) if precisions else 0\n",
    "\n",
    "\tif expected_filename not in retrieved_files:\n",
    "\t\tprint( 'Expected file NOT found in the retrieved files!' )\n",
    "\n",
    "\tif retrieved_files and retrieved_files[ 0 ] != expected_filename:\n",
    "\t\tprint( f'Query: {query}' )\n",
    "\t\tprint( f'Expected file: {expected_filename}' )\n",
    "\t\tprint( f'First retrieved file: {retrieved_files[ 0 ]}' )\n",
    "\t\tprint( f'Retrieved files: {retrieved_files}' )\n",
    "\t\tprint( '-' * 50 )\n",
    "\n",
    "\treturn correct, rr, avg_precision"
   ],
   "id": "29dc5be4570b087f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Recall & Precision are at 1 for this example.\n",
    "- Our file ranked first so we're having a MRR and MAP = 1 on this example.\n",
    "- We can now execute this processing on our set of questions."
   ],
   "id": "695b1ee9b5a46b00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with ThreadPoolExecutor( ) as executor:\n",
    "\tresults = list( tqdm( executor.map( process_query, rows ), total = total_queries ) )\n",
    "\n",
    "correct_retrievals_at_k = 0\n",
    "reciprocal_ranks = [ ]\n",
    "average_precisions = [ ]\n",
    "\n",
    "for correct, rr, avg_precision in results:\n",
    "\tif correct:\n",
    "\t\tcorrect_retrievals_at_k += 1\n",
    "\treciprocal_ranks.append( rr )\n",
    "\taverage_precisions.append( avg_precision )\n",
    "\n",
    "recall_at_k = correct_retrievals_at_k / total_queries\n",
    "precision_at_k = recall_at_k  # In this context, same as recall\n",
    "mrr = sum( reciprocal_ranks ) / total_queries\n",
    "map_score = sum( average_precisions ) / total_queries"
   ],
   "id": "e85155ef22f8e02e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- The outputs logged above would either show that a file wasn't ranked first when our evaluation dataset expected it to rank first or that it wasn't found at all.\n",
    "- As we can see from our imperfect evaluation dataset.\n",
    "- Some questions were generic and expected another doc, which our retrieval system didn't specifically retrieved for this question."
   ],
   "id": "8c681e33b82c75f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Boo AI\n",
   "id": "b4115957e93c72d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T14:22:11.188612Z",
     "start_time": "2025-08-12T14:22:09.305234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from importlib import reload\n",
    "from src.boo import EndPoint, GptModels\n",
    "import src.boo as ai\n",
    "reload( ai )"
   ],
   "id": "118c2f8590fc8333",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.boo' from 'C:\\\\Users\\\\terry\\\\source\\\\repos\\\\Boo\\\\src\\\\boo.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T14:22:28.778703Z",
     "start_time": "2025-08-12T14:22:28.767213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "endpoint = EndPoint( )\n",
    "endpoint.text_generation"
   ],
   "id": "b00d29c417e3bb69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.openai.com/v1/chat/completions'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T14:23:21.867880Z",
     "start_time": "2025-08-12T14:23:21.804358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = GptModels( )\n",
    "for m in models.reasoning:\n",
    "\tprint( m )"
   ],
   "id": "d1801c684c0e7aae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o1-2024-12-17\n",
      "o1-mini-2024-09-12\n",
      "o3-mini-2025-01-31\n",
      "o1-pro-2025-03-19\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T02:27:55.322259Z",
     "start_time": "2025-08-13T02:26:47.775438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "response = client.responses.create(\n",
    "\tprompt =\n",
    "\t{\n",
    "\t\t\t'id': 'pmpt_68668be09f2c8193b0c16b0d3a0e6a560c08f132c9c0f5e7',\n",
    "\t\t\t'version': '11',\n",
    "\t\t\t'variables':\n",
    "\t\t\t{\n",
    "\t\t\t\t\t'question': 'Can you refer to \"Agency Accounts.xlsx\" and list the list the Treasury Accounts used by the EPA'\n",
    "\t\t\t}\n",
    "\t} )"
   ],
   "id": "9762c0850f519fd6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T02:28:01.849366Z",
     "start_time": "2025-08-13T02:28:01.835088Z"
    }
   },
   "cell_type": "code",
   "source": "response.output_text",
   "id": "f373e651ced4d479",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Certainly! To refer to \"Agency Accounts.xlsx\" and list the Treasury Accounts used by the EPA, I\\'ll need to analyze the contents of that file. Here’s how we can proceed:\\n\\n### Step-by-Step Approach\\n\\n1. **Access the File:**\\n   - I\\'ll open \"Agency Accounts.xlsx\" to review its structure and contents.\\n\\n2. **Identify Relevant Data:**\\n   - Locate the sections or tabs within the file that pertain to the Environmental Protection Agency (EPA).\\n   - Identify the Treasury Accounts associated with the EPA.\\n\\n3. **Extract and List Treasury Accounts:**\\n   - Compile a list of Treasury Accounts used by the EPA as detailed in the file.\\n\\n### Next Steps\\n\\nLet me begin by examining the \"Agency Accounts.xlsx\" file. I\\'ll open the file, review its structure, and then extract the relevant Treasury Accounts for the EPA. This process ensures that the information provided is accurate and directly sourced from the file.\\n\\nLet\\'s get started! I\\'ll proceed to open and analyze the \"Agency Accounts.xlsx\" file.It appears that the search did not directly yield specific references to the Treasury Accounts used by the EPA within the \"Agency Accounts.xlsx\" file. To provide a comprehensive answer, I\\'ll need to open and analyze the \"Agency Accounts.xlsx\" file directly.\\n\\n### Proposed Next Steps\\n\\n1. **Open the \"Agency Accounts.xlsx\" File:**\\n   - I will examine the file to identify its structure and locate the relevant sections that pertain to the EPA and its Treasury Accounts.\\n\\n2. **Extract Relevant Data:**\\n   - I will extract the list of Treasury Accounts associated with the EPA as detailed in the file.\\n\\n3. **Present the Findings:**\\n   - I will compile and present a detailed list of the Treasury Accounts used by the EPA based on the information found in the file.\\n\\nLet\\'s proceed by opening and analyzing the \"Agency Accounts.xlsx\" file to ensure we accurately identify the Treasury Accounts used by the EPA.Based on the analysis of the \"Agency Accounts.xlsx\" file, here is a detailed list of Treasury Accounts used by the Environmental Protection Agency (EPA):\\n\\n### Treasury Accounts Used by the EPA\\n\\n1. **Account Codes and Descriptions:**\\n   - **529500:** Environmental Services\\n   - **814516:** Payment from the General Fund, Hazardous Substance Superfund\\n   - **815340:** Payment from the General Fund, Leaking Underground Storage Tank Trust Fund\\n   - **0103:** State and Tribal Assistance Grants\\n   - **0104:** Scientific Activities Overseas (Special Foreign Currency Program)\\n   - **0107:** Science and Technology\\n   - **0108:** Environmental Programs and Management\\n   - **0110:** Buildings and Facilities\\n   - **0112:** Office of Inspector General\\n   - **0118:** Abatement, Control, and Compliance Loan Program\\n   - **0200:** Program and Research Operations\\n   - **0250:** Payment to the Hazardous Substance Superfund\\n   - **0251:** Payment to the Leaking Underground Storage Tank Trust Fund\\n   - **0253:** Clean Power State Incentive Fund\\n   - **0254:** Water Infrastructure Finance and Innovation Program\\n   - **143500:** General Fund Proprietary Interest Receipts, Not Otherwise Classified\\n   - **268330:** Water Infrastructure Finance and Innovation Downward Reestimates\\n   - **275330:** Downward Reestimates of Subsidies, Abatement, Control, and Compliance\\n   - **291700:** Repayments of Loans from Local Educational Agencies\\n   - **322000:** All Other General Fund Proprietary Receipts\\n   - **322900:** Cellulosic Biofuel Waiver Credits, Renewal Fuel Standard\\n   - **388500:** Undistributed Intragovernmental Payments and Receipts\\n   - **4310:** Reregistration and Expedited Processing Revolving Fund\\n   - **4321:** Abatement, Control, and Compliance Direct Loan Financing Account\\n   - **4330:** Hazardous Waste Electronic Manifest System Fund\\n   - **4365:** Damage Assessment and Restoration Revolving Fund\\n   - **4565:** Working Capital Fund\\n   - **529300:** Licensing Fees for Pesticides, Chemicals, and Other Substances\\n   - **5297:** Exxon Valdez Settlement Fund\\n   - **5374:** Pesticide Registration Fund\\n   - **537410:** Registration Service Fees, Pesticide Registration Fund\\n   - **552610:** User Fees, Pesticide Tolerance\\n   - **552710:** User Fees, Pre-Manufacture Notice\\n   - **5664:** TSCA Service Fee Fund\\n   - **566410:** User Fees, TSCA Service Fee Fund\\n   - **5669:** 21st Century Clean Transportation Plan Investment Fund\\n   - **814310:** Loan Repayments, Asbestos Trust Fund, EPA\\n   - **8145:** Hazardous Substance Superfund\\n   - **814540:** Recoveries, Hazardous Substance Superfund\\n   - **814550:** Interfund Transactions, Hazardous Substance Superfund\\n   - **814560:** Future Clean Up Cost Settlements, Hazardous Substance Superfund\\n   - **8153:** Leaking Underground Storage Tank Trust Fund\\n   - **815330:** Recoveries, Leaking Underground Storage Tank Trust Fund\\n   - **8221:** Inland Oil Spill Programs\\n   - **8741:** Miscellaneous Contributed Funds\\n   - **874110:** Miscellaneous Contributed Funds\\n   - **9004:** Deltas Between the Annualized CR Amounts and the Actual Amounts Appropriated\\n   - **9971:** Inspector General (Trust Funds)\\n\\n2. **Additional Notes:**\\n   - Some account codes are associated with specific programs or funds, such as the Hazardous Substance Superfund, Leaking Underground Storage Tank Trust Fund, and various user fees and registration funds.\\n   - The accounts cover a wide range of activities, including grants, environmental services, research, and program management.\\n\\n### Conclusion\\n\\nThe Environmental Protection Agency (EPA) utilizes a diverse set of Treasury Accounts to manage its financial operations, ranging from program funding to specific user fees and trust funds. If you need more detailed information on any specific account or further analysis, please let me know!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
