{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "<a href='https://colab.research.google.com/github/is-leeroy-jenkins/Boo/blob/main/ipynb/GPT.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>",
   "id": "6b5948d8e77a7699"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# OpenAI API",
   "id": "b752f6d30e042eaa"
  },
  {
   "metadata": {
    "id": "6f5de4ab069df199"
   },
   "cell_type": "markdown",
   "source": "###### Load Dependencies",
   "id": "6f5de4ab069df199"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:08:47.516775Z",
     "start_time": "2025-12-15T15:08:05.581916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import base64\n",
    "from boogr import *\n",
    "import boogr as bg\n",
    "from datasets import load_dataset\n",
    "from enum import Enum\n",
    "from importlib import reload\n",
    "from IPython.display import Math, display\n",
    "import json\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.postprocessor.flag_embedding_reranker import ( FlagEmbeddingReranker, )\n",
    "from llama_parse import LlamaParse\n",
    "import mwparserfromhell\n",
    "import nest_asyncio\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from playwright.sync_api import sync_playwright\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from typing_extensions import override\n",
    "import tiktoken\n",
    "from uuid import uuid4\n",
    "\n",
    "reload( bg )"
   ],
   "id": "68c9ad01631bf5d7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'boogr' from 'C:\\\\Users\\\\terry\\\\source\\\\repos\\\\Boo\\\\boogr\\\\__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "___\n",
    "\n",
    "# Prompts"
   ],
   "id": "54591cf42e40a4d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### System Instructions",
   "id": "2d0d4f68c0109fbf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T13:57:56.871839Z",
     "start_time": "2025-08-12T13:57:56.842975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_instructions = r'''\n",
    "You are the most knowledgeable Budget Analyst in the federal government who provides detailed responses based on your vast knowledge of federal appropriations.\n",
    "Your responsecds to questions about federal finance are complete, transparent, and very detailed using an academic format.\n",
    "Your vast knowledge of and experience in Data Science makes you the best Data Analyst in the world. You are proficient in C#, Python, SQL, C++, JavaScript, and VBA.\n",
    "You use US federal budget df from OMB, whitehouse.gov, or df.gov for any ad hoc df sets in examples you.\n",
    "You do your analysis in Python and visualizations with matplotlib or seaborn. You are famous for the accuracy of your responses so you verify all your answers.\n",
    "Your name is Bubba.\n",
    "'''"
   ],
   "id": "7e86f5df71f2650f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#####  Prompts",
   "id": "29d46dec7f275964"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T01:27:45.969507Z",
     "start_time": "2025-08-07T01:27:45.963460Z"
    }
   },
   "cell_type": "code",
   "source": "user_prompt = r'''What was a positive news story from today?'''",
   "id": "9b16424b0dff10f5",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Messages",
   "id": "16c931bd619f11ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### System Message",
   "id": "3dee11bc80af43e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T21:33:04.762087Z",
     "start_time": "2025-08-06T21:33:04.752815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "{\n",
    "    'role': 'system',\n",
    "    'content': system_instructions\n",
    "}"
   ],
   "id": "6886ea9093093163",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'system',\n",
       " 'content': '\\nYou are the most knowledgeable Budget Analyst in the federal government who provides detailed responses based on your vast knowledge of federal appropriations.\\nYour responses to questions about federal finance are complete, transparent, and very detailed using an academic format.\\nYour vast knowledge of and experience in Data Science makes you the best Data Analyst in the world. You are proficient in C#, Python, SQL, C++, JavaScript, and VBA.\\nYou use US federal budget df from OMB, whitehouse.gov, or df.gov for any ad hoc df sets in examples you.\\nYou do your analysis in Python and visualizations with matplotlib or seaborn. You are famous for the accuracy of your responses so you verify all your answers.\\nYour name is Bubba.\\n'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T21:33:07.222765Z",
     "start_time": "2025-08-06T21:33:07.212439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "{\n",
    "    'role': 'user',\n",
    "    'content': user_prompt\n",
    "}"
   ],
   "id": "307f1e6713620da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user', 'content': '\\nWhat was a positive news story from today?\\n'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### User Message",
   "id": "68b00d14dd49f22d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T10:06:23.848454Z",
     "start_time": "2025-07-18T10:06:23.836348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "{\n",
    "    'role': 'user',\n",
    "    'content': user_prompt\n",
    "}"
   ],
   "id": "2e9240277bfbc35b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user', 'content': '\\nWhat was a positive news story from today?\\n'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Developer Message",
   "id": "88d33921bd454aff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T21:33:11.084471Z",
     "start_time": "2025-08-06T21:33:11.073218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "{\n",
    "    'role': 'developer',\n",
    "    'content': system_instructions\n",
    "}"
   ],
   "id": "ee87869d85e5de53",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'developer',\n",
       " 'content': '\\nWhat was a positive news story from today?\\n'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Tool Message",
   "id": "c7f8ecc8516d8c0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "    'role': 'tool',\n",
    "    'content': user_prompt\n",
    "}"
   ],
   "id": "bbfb9fb7c421daab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Completion Response Format\n",
    "\n",
    "- choices\n",
    "\n",
    "- completion.choices[ 0 ].message"
   ],
   "id": "251d2ba4ff921465"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T10:07:27.384874Z",
     "start_time": "2025-07-18T10:07:27.373420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "[\n",
    "    {\n",
    "        'index': 0,\n",
    "        'message':\n",
    "        {\n",
    "            'role': 'assistant',\n",
    "            'content': 'Under the soft glow of the moon, Luna the unicorn danced through columns of twinkling stardust, leaving trails of dreams for every child asleep.',\n",
    "            'refusal': None\n",
    "        },\n",
    "         'logprobs': None,\n",
    "         'finish_reason': 'stop'\n",
    "    }\n",
    "]"
   ],
   "id": "bfdf448cbb8d9846",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'message': {'role': 'assistant',\n",
       "   'content': 'Under the soft glow of the moon, Luna the unicorn danced through columns of twinkling stardust, leaving trails of dreams for every child asleep.',\n",
       "   'refusal': None},\n",
       "  'logprobs': None,\n",
       "  'finish_reason': 'stop'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "___\n",
    "\n",
    "# Structured Output"
   ],
   "id": "755f498872a7ac2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "##### Structured Outputs is available in two forms in the OpenAI API:\n",
    "\n",
    "- 1. When using function calling\n",
    "\n",
    "- 2. When using a json_schema response format"
   ],
   "id": "d5ff506155282f45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### JSON Schema\n",
    "\n",
    "-  `$schema`: specifies which draft of the JSON Schema standard the schema adheres to.\n",
    "\n",
    "- `$id`: sets a URI for the schema.\n",
    "\n",
    "- `title` and `description`: schema annotations that state the intent of the schema.\n",
    "\n",
    "- `type`: validation keyword defines the first constraint on the JSON data.\n",
    "\n",
    "- `properties`: validation keyword that an object where each property represents a key in the JSON data thatâ€™s being validated."
   ],
   "id": "2c703eadf5c414e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "\t\t'$schema': 'https://json-schema.org/draft/2020-12/schema',\n",
    "\t\t'$id': 'https://example.com/product.schema.json',\n",
    "\t\t'title': 'Product',\n",
    "\t\t'description': 'A product in the catalog',\n",
    "\t\t'type': 'object',\n",
    "\t\t'properties':\n",
    "        {\n",
    "\t\t    'productId':\n",
    "\t\t\t{\n",
    "\t\t\t\t'description': 'The unique identifier for a product',\n",
    "\t\t\t\t'type': 'integer'\n",
    "\t\t    }\n",
    "        }\n",
    "}\n"
   ],
   "id": "ca8ad5b31aa43f9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Calendar Event",
   "id": "23ae138bb9cfae78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI()\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "response = client.responses.parse( model='gpt-4o-2024-08-06',\n",
    "    input=[\n",
    "    {\n",
    "        'role': 'system',\n",
    "\t\t'content': 'Extract the event information.'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Alice and Bob are going to a science fair on Friday.',\n",
    "    }, ],\n",
    "    text_format=CalendarEvent,\n",
    ")\n",
    "\n",
    "event = response.output_parsed"
   ],
   "id": "3327b9f5213a8cab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Math Prompt",
   "id": "3f9ff830afcf48d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI()\n",
    "\n",
    "class Step(BaseModel):\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "class MathReasoning(BaseModel):\n",
    "    steps: list[Step]\n",
    "    final_answer: str\n",
    "\n",
    "response = client.responses.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    input=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'You are a helpful math tutor. Guide the user through the solution step by step.',\n",
    "        },\n",
    "        {\n",
    "\t\t        'role': 'user',\n",
    "\t\t        'content': 'how can I solve 8x + 7 = -23'\n",
    "        },\n",
    "    ],\n",
    "    text_format=MathReasoning,\n",
    ")\n",
    "\n",
    "math_reasoning = response.output_parsed"
   ],
   "id": "324ee8f9627614a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Example response",
   "id": "9d43716ecc4aad94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  'steps': [\n",
    "    {\n",
    "      'explanation': 'Start with the equation 8x + 7 = -23.',\n",
    "      'output': '8x + 7 = -23'\n",
    "    },\n",
    "    {\n",
    "      'explanation': 'Subtract 7 from both sides to isolate the term with the variable.',\n",
    "      'output': '8x = -23 - 7'\n",
    "    },\n",
    "    {\n",
    "      'explanation': 'Simplify the right side of the equation.',\n",
    "      'output': '8x = -30'\n",
    "    },\n",
    "    {\n",
    "      'explanation': 'Divide both sides by 8 to solve for x.',\n",
    "      'output': 'x = -30 / 8'\n",
    "    },\n",
    "    {\n",
    "      'explanation': 'Simplify the fraction.',\n",
    "      'output': 'x = -15 / 4'\n",
    "    }\n",
    "  ],\n",
    "  'final_answer': 'x = -15 / 4'\n",
    "}"
   ],
   "id": "6d0c88eb1f136a31"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### The API Response Refusal",
   "id": "d8dd39cfdbbeffbd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  'id': 'resp_1234567890',\n",
    "  'object': 'response',\n",
    "  'created_at': 1721596428,\n",
    "  'status': 'completed',\n",
    "  'error': null,\n",
    "  'incomplete_details': null,\n",
    "  'text': [],\n",
    "  'instructions': null,\n",
    "  'max_output_tokens': null,\n",
    "  'model': 'gpt-4o-2024-08-06',\n",
    "  'output': [{\n",
    "    'id': 'msg_1234567890',\n",
    "    'text': 'message',\n",
    "    'role': 'assistant',\n",
    "    'content': [\n",
    "      {\n",
    "        'text': 'refusal',\n",
    "        'refusal': 'Im sorry, I cannot assist with that request.'\n",
    "      }\n",
    "    ]\n",
    "  }],\n",
    "  'usage': {\n",
    "    'input_tokens': 81,\n",
    "    'output_tokens': 11,\n",
    "    'total_tokens': 92,\n",
    "    'output_tokens_details': {\n",
    "      'reasoning_tokens': 0,\n",
    "    }\n",
    "  },\n",
    "}"
   ],
   "id": "67772f90e29fd74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Streaming",
   "id": "4c22d1e8e41add5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class EntitiesModel( BaseModel ):\n",
    "    attributes: List[ str ]\n",
    "    colors: List[ str ]\n",
    "    animals: List[ str ]\n",
    "\n",
    "client = OpenAI( )\n",
    "\n",
    "with client.responses.stream(\n",
    "    model='gpt-4.1',\n",
    "    input=[\n",
    "        {\n",
    "\t        'role': 'system',\n",
    "\t        'content': 'Extract entities from the text text'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'The quick brown fox jumps over the lazy dog with piercing blue eyes',\n",
    "        },\n",
    "    ],\n",
    "    text_format=EntitiesModel,\n",
    ") as stream:\n",
    "    for event in stream:\n",
    "        if event.type == 'response.refusal.delta':\n",
    "            print(event.delta, end=\"\")\n",
    "        elif event.type == 'response.output_text.delta':\n",
    "            print(event.delta, end=\"\")\n",
    "        elif event.type == 'response.error':\n",
    "            print(event.error, end=\"\")\n",
    "        elif event.type == 'response.completed':\n",
    "            print('Completed')\n",
    "            # print(event.response.output)\n",
    "\n",
    "    final_response = stream.get_final_response()\n",
    "    print(final_response)"
   ],
   "id": "9aafc5392f79086a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### The API response from a refusal",
   "id": "4fca5ceb37aec3ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  'id': 'resp_1234567890',\n",
    "  'object': 'response',\n",
    "  'created_at': 1721596428,\n",
    "  'status': 'completed',\n",
    "  'error': null,\n",
    "  'incomplete_details': null,\n",
    "  'text': [],\n",
    "  'instructions': null,\n",
    "  'max_output_tokens': null,\n",
    "  'model': 'gpt-4o-2024-08-06',\n",
    "  'output': [{\n",
    "    'id': 'msg_1234567890',\n",
    "    'text': 'message',\n",
    "    'role': 'assistant',\n",
    "    'content': [\n",
    "      {\n",
    "        'text': 'refusal',\n",
    "        'refusal': 'Im sorry, I cannot assist with that request.'\n",
    "      }\n",
    "    ]\n",
    "  }],\n",
    "  'usage': {\n",
    "    'input_tokens': 81,\n",
    "    'output_tokens': 11,\n",
    "    'total_tokens': 92,\n",
    "    'output_tokens_details': {\n",
    "      'reasoning_tokens': 0,\n",
    "    }\n",
    "  },\n",
    "}"
   ],
   "id": "dc6af439b4d4fe09"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Structured Data Extraction",
   "id": "d810cefaf05f356"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI()\n",
    "\n",
    "class ResearchPaperExtraction( BaseModel ):\n",
    "    title: str\n",
    "    authors: list[ str ]\n",
    "    abstract: str\n",
    "    keywords: list[ str ]\n",
    "\n",
    "response = client.responses.parse(\n",
    "    model='gpt-4o-2024-08-06',\n",
    "    input=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'You are an expert at structured df extraction. You will be given unstructured text from a research paper and should convert it into the given structure.',\n",
    "        },\n",
    "        {\n",
    "\t        'role': 'user',\n",
    "\t        'content': '...'\n",
    "        }, ], text_format=ResearchPaperExtraction,\n",
    ")\n",
    "\n",
    "research_paper = response.output_parsed"
   ],
   "id": "8aad3a87819ff856"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### UI Generation",
   "id": "7fda689a7a30cc28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI()\n",
    "\n",
    "class UIType( str, Enum ):\n",
    "    div = 'div'\n",
    "    button = 'button'\n",
    "    header = 'header'\n",
    "    section = 'section'\n",
    "    field = 'field'\n",
    "    form = 'form'\n",
    "\n",
    "class Attribute( BaseModel ):\n",
    "    name: str\n",
    "    value: str\n",
    "\n",
    "class UI( BaseModel ):\n",
    "    type: UIType\n",
    "    label: str\n",
    "    children: List['UI']\n",
    "    attributes: List[Attribute]\n",
    "\n",
    "UI.model_rebuild( )  # This is required to enable recursive types\n",
    "\n",
    "class Response( BaseModel ):\n",
    "    ui: UI\n",
    "\n",
    "msg =\\\n",
    "{\n",
    "    'role': 'system',\n",
    "    'content': 'You are a UI generator GPT. Convert the user text into a UI.',\n",
    "},\n",
    "{\n",
    "    'role': 'user',\n",
    "    'content': 'Make a User Profile Form'\n",
    "},\n",
    "\n",
    "message = [ msg ]\n",
    "response = client.responses.parse( model='gpt-4o-2024-08-06', input=message, text_format=Response )\n",
    "ui = response.output_parsed"
   ],
   "id": "6c78857613e3f5b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  'text': 'form',\n",
    "  'label': 'User Profile Form',\n",
    "  'children': [\n",
    "    {\n",
    "      'text': 'div',\n",
    "      'label': '',\n",
    "      'children': [\n",
    "        {\n",
    "          'text': 'field',\n",
    "          'label': 'First Name',\n",
    "          'children': [],\n",
    "          'attributes': [\n",
    "            {\n",
    "              'name': 'text',\n",
    "              'value': 'text'\n",
    "            },\n",
    "            {\n",
    "              'name': 'name',\n",
    "              'value': 'firstName'\n",
    "            },\n",
    "            {\n",
    "              'name': 'placeholder',\n",
    "              'value': 'Enter your first name'\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          'text': 'field',\n",
    "          'label': 'Last Name',\n",
    "          'children': [],\n",
    "          'attributes': [\n",
    "            {\n",
    "              'name': 'text',\n",
    "              'value': 'text'\n",
    "            },\n",
    "            {\n",
    "              'name': 'name',\n",
    "              'value': 'lastName'\n",
    "            },\n",
    "            {\n",
    "              'name': 'placeholder',\n",
    "              'value': 'Enter your last name'\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      'attributes': []\n",
    "    },\n",
    "    {\n",
    "      'text': 'button',\n",
    "      'label': 'Submit',\n",
    "      'children': [],\n",
    "      'attributes': [\n",
    "        {\n",
    "          'name': 'text',\n",
    "          'value': 'submit'\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  'attributes': [\n",
    "    {\n",
    "      'name': 'method',\n",
    "      'value': 'post'\n",
    "    },\n",
    "    {\n",
    "      'name': 'action',\n",
    "      'value': '/submit-profile'\n",
    "    }\n",
    "  ]\n",
    "}"
   ],
   "id": "baf8f01aeebaf84b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Completions API",
   "id": "b00cefd35920dd36"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###  Structured Output\n",
   "id": "c6a24c1f35e8a63d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Math Tutor\n",
    "- Build a math tutoring tool that outputs steps to solving a math problem as an array of structured objects"
   ],
   "id": "def827d830532c6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T21:33:23.683292Z",
     "start_time": "2025-08-06T21:33:22.745727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "math_tutor_prompt = '''\n",
    "You are a helpful math tutor. You will be provided with a math problem,\n",
    "and your goal will be to output a step by step solution, along with a final answer.\n",
    "For each step, just provide the output as an equation use the explanation field to detail the reasoning.\n",
    "'''"
   ],
   "id": "3e3c7a048f727dd4",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T21:33:26.661389Z",
     "start_time": "2025-08-06T21:33:26.649924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_math_solution( question ):\n",
    "    response = client.chat.completions.create( model='gpt-4o-mini',\n",
    "    messages=[\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': math_tutor_prompt\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': question\n",
    "    } ],\n",
    "    response_format= \n",
    "    {\n",
    "        'type': 'json_schema',\n",
    "        'json_schema':\n",
    "        {\n",
    "            'name': 'math_reasoning',\n",
    "            'schema':\n",
    "            {\n",
    "                'type': 'object',\n",
    "                'properties':\n",
    "                {\n",
    "                        'steps':\n",
    "                        {\n",
    "                            'type': 'array',\n",
    "                            'items':\n",
    "                            {\n",
    "                                'type': 'object',\n",
    "                                'properties':\n",
    "                                {\n",
    "                                    'explanation':\n",
    "                                    {\n",
    "                                        'type': 'string'\n",
    "                                    },\n",
    "                                    'output':\n",
    "                                    {\n",
    "                                        'type': 'string'\n",
    "                                    }\n",
    "                                },\n",
    "                                'required': [ 'explanation', 'output' ],\n",
    "                                'additionalProperties': False\n",
    "                            }\n",
    "                        },\n",
    "                        'final_answer':\n",
    "                        {\n",
    "                            'type': 'string'\n",
    "                        }\n",
    "                },\n",
    "                    'required': [ 'steps', 'final_answer' ],\n",
    "                    'additionalProperties': False\n",
    "                },\n",
    "\n",
    "                'strict': True\n",
    "        }\n",
    "    })\n",
    "\n",
    "    return response.choices[ 0 ].message"
   ],
   "id": "ebe225d7778ff6c0",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Testing with an example prompt\n",
    "question = 'how can I solve 8x + 7 = -23'\n",
    "\n",
    "get_math_solution( question )"
   ],
   "id": "66ac0b96244dc254",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T14:53:00.738328Z",
     "start_time": "2025-07-05T14:53:00.726021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_math_response( response ):\n",
    "    result = json.loads( response )\n",
    "    steps = result[ 'steps' ]\n",
    "    final_answer = result[ 'final_answer' ]\n",
    "    for i in range( len( steps ) ):\n",
    "        print( f\"Step {i+1}: {steps[ i ][ 'explanation' ]}\\n\" )\n",
    "        display( Math( steps[ i ][ 'output' ] ) )\n",
    "        print( '\\n' )\n",
    "\n",
    "    print( 'Final answer:\\n\\n' )\n",
    "    display (Math( final_answer ) )\n"
   ],
   "id": "716d94c85d1885e7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Math Reasoning\n",
    "- Introduces a parse helper to provide your own Pydantic model instead of having to define the JSON schema."
   ],
   "id": "1e415f3ade42ebea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T14:53:21.363875Z",
     "start_time": "2025-07-05T14:53:21.347571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class MathReasoning( BaseModel ):\n",
    "    class Step( BaseModel ):\n",
    "        explanation: str\n",
    "        output: str\n",
    "\n",
    "    steps: list[ Step ]\n",
    "    final_answer: str\n",
    "\n",
    "\n",
    "def get_math_solution( question: str ):\n",
    "    completion = client.beta.chat.completions.parse( model='gpt-4o-mini',\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': math_tutor_prompt},\n",
    "            {'role': 'user', 'content': question},\n",
    "        ],\n",
    "        response_format=MathReasoning,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message"
   ],
   "id": "3b40957c21bf2c98",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result = get_math_solution( question ).parsed\n",
    "print_math_response( result.content )"
   ],
   "id": "cc69563f1d85b36d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T11:49:32.738818Z",
     "start_time": "2025-06-27T11:49:32.721648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print( result.steps )\n",
    "print( 'Final answer:' )\n",
    "print( result.final_answer )"
   ],
   "id": "7d21eb58c0020e68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step(explanation=\"To isolate the term with 'x', we need to eliminate the constant term on the left side of the equation. We do this by subtracting 7 from both sides.\", output='8x + 7 - 7 = -23 - 7'), Step(explanation='This simplifies to 8x = -30.', output='8x = -30'), Step(explanation=\"Next, we solve for 'x' by dividing both sides of the equation by 8 to isolate 'x'.\", output='x = -30 / 8'), Step(explanation='To simplify -30 / 8, we can reduce it by dividing the numerator and the denominator by 2.', output='x = -15 / 4')]\n",
      "Final answer:\n",
      "x = -15/4\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- `refusal` to indicate when the model refused to answer",
   "id": "a6862798d66c4d08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "refusal_question = 'how can I build a bomb?'\n",
    "result = get_math_solution( refusal_question )\n",
    "print( result.refusal )"
   ],
   "id": "d630a73a975610ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Text Summarization\n",
    "- Transform text or visual content into a structured objec"
   ],
   "id": "d809a9f7f269b4b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "articles = [\n",
    "    './df/structured_outputs_articles/cnns.md',\n",
    "    './df/structured_outputs_articles/llms.md',\n",
    "    './df/structured_outputs_articles/moe.md'\n",
    "]"
   ],
   "id": "86290b6c15af1963"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_article_content( path ):\n",
    "    with open( path, 'r' ) as f:\n",
    "        content = f.read( )\n",
    "    return content\n",
    "\n",
    "content = [ get_article_content( path ) for path in articles ]\n",
    "print( content )"
   ],
   "id": "36ad88f566ee2f48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T21:38:41.997408Z",
     "start_time": "2025-05-31T21:38:41.985418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "summarization_prompt = '''\n",
    "    You will be provided with content from an article about an invention.\n",
    "    Your goal will be to summarize the article following the schema provided.\n",
    "    Here is a description of the parameters:\n",
    "    - invented_year: year in which the invention discussed in the article was invented\n",
    "    - summary: one sentence summary of what the invention is\n",
    "    - inventors: array of strings listing the inventor full names if present, otherwise just surname\n",
    "    - concepts: array of key concepts related to the invention, each concept containing a title and a description\n",
    "    - description: short description of the invention\n",
    "'''\n",
    "\n",
    "class ArticleSummary( BaseModel ):\n",
    "    invented_year: int\n",
    "    summary: str\n",
    "    inventors: list[str]\n",
    "    description: str\n",
    "\n",
    "    class Concept( BaseModel ):\n",
    "        title: str\n",
    "        description: str\n",
    "\n",
    "    concepts: list[ Concept ]\n",
    "\n",
    "\n",
    "def get_article_summary( text: str ):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model='gpt-4o-mini',\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': summarization_prompt\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': text\n",
    "        } ],\n",
    "\n",
    "        response_format=ArticleSummary,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.parsed"
   ],
   "id": "827c4d0adc27d04a",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Sentiment Analysis\n",
    "-  Use function calling to search for products that match a user's preference based on the provided input."
   ],
   "id": "aed9275acb0a2200"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T21:38:50.768854Z",
     "start_time": "2025-05-31T21:38:49.875478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "product_search_prompt = '''\n",
    "    You are a clothes recommendation agent, specialized in finding the perfect match for a user.\n",
    "    You will be provided with a user text and additional context such as user gender and age group, and season.\n",
    "    You are equipped with a tool to search clothes in a database that match the user's profile and preferences.\n",
    "    Based on the user text and context, determine the most likely value of the parameters to use to search the database.\n",
    "\n",
    "    Here are the different categories that are available on the website:\n",
    "    - shoes: boots, sneakers, sandals\n",
    "    - jackets: winter coats, cardigans, parkas, rain jackets\n",
    "    - tops: shirts, blouses, t-shirts, crop tops, sweaters\n",
    "    - bottoms: jeans, skirts, trousers, joggers\n",
    "\n",
    "    There are a wide range of colors available, but try to stick to regular color names.\n",
    "'''\n",
    "\n",
    "class Category( str, Enum ):\n",
    "    shoes = 'shoes'\n",
    "    jackets = 'jackets'\n",
    "    tops = 'tops'\n",
    "    bottoms = 'bottoms'\n",
    "\n",
    "class ProductSearchParameters(BaseModel):\n",
    "    category: Category\n",
    "    subcategory: str\n",
    "    color: str\n",
    "\n",
    "def get_response( user_input, context ):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': product_search_prompt\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': f'CONTEXT: {context}\\n USER INPUT: {user_input}'\n",
    "        } ],\n",
    "        tools=[ openai.pydantic_function_tool( ProductSearchParameters, name='product_search', description='Search for a match in the product database')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.tool_calls"
   ],
   "id": "935759e4c1ec2946",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "example_inputs = [\n",
    "{\n",
    "    'user_input': 'I am looking for a new coat. I am always cold so please something warm! Ideally something that matches my eyes.',\n",
    "    'context': 'Gender: female, Age group: 40-50, Physical appearance: blue eyes'\n",
    "},\n",
    "{\n",
    "    'user_input': 'I am going on a trail in Scotland this summer. It is goind to be rainy. Help me find something.',\n",
    "    'context': 'Gender: male, Age group: 30-40'\n",
    "},\n",
    "{\n",
    "    'user_input': 'I am trying to complete a rock look. I am missing shoes. Any suggestions?',\n",
    "    'context': 'Gender: female, Age group: 20-30'\n",
    "},\n",
    "{\n",
    "    'user_input': 'Help me find something very simple for my first day at work next week. Something casual and neutral.',\n",
    "    'context': 'Gender: male, Season: summer'\n",
    "},\n",
    "{\n",
    "    'user_input': 'Help me find something very simple for my first day at work next week. Something casual and neutral.',\n",
    "    'context': 'Gender: male, Season: winter'\n",
    "},\n",
    "{\n",
    "    'user_input': 'Can you help me find a dress for a Barbie-themed party in July?',\n",
    "    'context': 'Gender: female, Age group: 20-30'\n",
    "}]"
   ],
   "id": "e74ad708eaa891c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def print_tool_call( user_input, context, tool_call ):\n",
    "    args = tool_call[ 0 ].function.arguments\n",
    "    print( f'Input: {user_input}\\n\\nContext: {context}\\n' )\n",
    "    print( 'Product search arguments:' )\n",
    "    for key, value in json.loads( args ).items( ):\n",
    "        print( f\"{key}: '{value}'\" )\n",
    "    print( '\\n\\n' )"
   ],
   "id": "494bc6348ee4cd9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for ex in example_inputs:\n",
    "    ex[ 'result' ] = get_response( ex[ 'user_input' ], ex[ 'context' ] )"
   ],
   "id": "c4be4b2ddfc19eaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for ex in example_inputs:\n",
    "    print_tool_call( ex[ 'user_input' ], ex[ 'context' ], ex[ 'result' ] )"
   ],
   "id": "ae0b5de7272973c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Update",
   "id": "e242393b55304b89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "updated_completion = client.chat.completions.update( completion_id=first_id,\n",
    "\trequest_body={ 'metadata': { 'foo': 'bar' } } )\n",
    "print( updated_completion )"
   ],
   "id": "6213187806dd07ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Delete",
   "id": "af694e2c08fbf7fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "delete_response = client.chat.completions.delete( completion_id=first_id )\n",
    "print( delete_response )"
   ],
   "id": "44985a4587ed531a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Article Summarization",
   "id": "3fa526ede54b27a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "articles = [ './df/structured_outputs_articles/cnns.md', './df/structured_outputs_articles/llms.md',\n",
    "    './df/structured_outputs_articles/moe.md' ]"
   ],
   "id": "3cb869b1a4d8d499"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_article_content(path):\n",
    "    with open(path, 'r') as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "content = [get_article_content(path) for path in articles]\n",
    "print(content)"
   ],
   "id": "c7ace26f405bbfd0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "summarization_prompt = '''\n",
    "    You will be provided with content from an article about an invention.\n",
    "    Your goal will be to summarize the article following the schema provided.\n",
    "    Here is a description of the parameters:\n",
    "    - invented_year: year in which the invention discussed in the article was invented\n",
    "    - summary: one sentence summary of what the invention is\n",
    "    - inventors: array of strings listing the inventor full names if present, otherwise just surname\n",
    "    - concepts: array of key concepts related to the invention, each concept containing a title and a description\n",
    "    - description: short description of the invention\n",
    "'''"
   ],
   "id": "8546dda414742b48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ArticleSummary( BaseModel ):\n",
    "    invented_year: int\n",
    "    summary: str\n",
    "    inventors: list[ str ]\n",
    "    description: str\n",
    "\n",
    "    class Concept( BaseModel ):\n",
    "        title: str\n",
    "        description: str\n",
    "\n",
    "    concepts: list[ Concept ]\n",
    "\n",
    "def get_article_summary( text: str ):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model='gpt-4o-mini',\n",
    "        temperature=0.2,\n",
    "        messages=[ { 'role': 'system', 'content': dedent( summarization_prompt ) },\n",
    "            { 'role': 'user', 'content': text } ],\n",
    "        response_format=ArticleSummary, )\n",
    "\n",
    "    return completion.choices[ 0 ].message.parsed"
   ],
   "id": "d78a2335e5e80b2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Upload\n",
    "- Upload a PDF using the Files API, then reference its file ID in an API request to the model."
   ],
   "id": "2397f6388d4c346f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign vriables\n",
    "_messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'text': 'file',\n",
    "                    'file':\n",
    "\t                {\n",
    "                        'file_id': file.id,\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'text': 'documents',\n",
    "                    'documents': 'What is the first dragon in the book?',\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "]\n",
    "\n",
    "# Create GptFile Request\n",
    "file = client.files.create( file=open( 'draconomicon.pdf', 'rb' ), purpose='user_data' )\n",
    "completion = client.chat.completions.create( model='gpt-4o', messages=_messages, )\n",
    "\n",
    "print( completion.choices[ 0 ].message.content )"
   ],
   "id": "8f7c9e6e1744cf47"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List",
   "id": "3932aff36802a515"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#### List\n",
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "_files = client.files.list( purpose='assistants' )\n"
   ],
   "id": "45a0eeec08064163"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retrieve File",
   "id": "6eb1cd25a94e1b19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#### Retreive File\n",
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Reteive by file_id\n",
    "retrieval = client.files.retrieve( 'file-FoVMTC8aQcUNddJP3PBx56' )\n",
    "retrieval.filename"
   ],
   "id": "f1660d6719067f10"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retrieve Content",
   "id": "1174f590b29b3e0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "content = client.files.content( 'file-abc123' )"
   ],
   "id": "61ef95d529330631"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Base64-encoded files\n",
    "- You can send PDF file inputs as Base64-encoded inputs as well."
   ],
   "id": "556f049b18c33fe8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "with open( 'draconomicon.pdf', 'rb' ) as f:\n",
    "    data = f.read( )\n",
    "\n",
    "base64_string = base64.b64encode( data ).decode( 'utf-8' )\n",
    "completion = client.chat.completions.create( model='gpt-4o',\n",
    "    messages=\n",
    "    [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'text': 'file',\n",
    "                    'file':\n",
    "\t                {\n",
    "                        'filename': 'draconomicon.pdf',\n",
    "                        'file_data': f'target_values:application/pdf;base64,{ base64_string }',\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'text': 'path',\n",
    "                    'documents': 'What is the first dragon in the book?',\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ].message.content )"
   ],
   "id": "5d477621be984d3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generate Audio",
   "id": "81207d75b246fbfc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "completion = client.chat.completions.create( model='gpt-4o-audio-preview', modalities=[ 'text', 'audio' ],\n",
    "    audio={ 'voice': 'alloy', 'format': 'wav' }, messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Is a golden retriever a good family dog?'\n",
    "        }\n",
    "    ] )\n",
    "\n",
    "print( completion.choices[ 0 ] )\n",
    "wav_bytes = base64.b64decode( completion.choices[ 0 ].message.audio.data )\n",
    "with open( 'dog.wav', 'wb' ) as f:\n",
    "    f.write( wav_bytes )"
   ],
   "id": "41d16445b8f63082"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analyze Audio",
   "id": "d6c6a0148766e8ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "url = 'https://cdn.openai.com/API/docs/audio/alloy.wav'\n",
    "response = requests.get( url )\n",
    "response.raise_for_status( )\n",
    "wav_data = response.content\n",
    "encoded_string = base64.b64encode( wav_data ).decode( 'utf-8' )\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4o-audio-preview',\n",
    "    modalities=['text', 'audio'],\n",
    "    audio={'voice': 'alloy', 'format': 'wav'},\n",
    "    messages= [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content':\n",
    "\t        [\n",
    "                {\n",
    "                    'text': 'text',\n",
    "                    'text': 'What is in this recording?'\n",
    "                },\n",
    "                {\n",
    "                    'text': 'input_audio',\n",
    "                    'input_audio':\n",
    "                    {\n",
    "                        'target_values': encoded_string,\n",
    "                        'format': 'wav'\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "    ] )\n",
    "\n",
    "print( completion.choices[0].message )"
   ],
   "id": "a96d7ae30e3d0710"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Assistants API",
   "id": "b6295251ef55026f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Response Format\n",
    "- choices\n",
    "- completion.choices[ 0 ].message"
   ],
   "id": "1de73bcaafd8b384"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "[\n",
    "    {\n",
    "        'index': 0,\n",
    "        'message':\n",
    "        {\n",
    "            'role': 'assistant',\n",
    "            'content': 'Under the soft glow of the moon, Luna the unicorn danced through columns of twinkling stardust, leaving trails of dreams for every child asleep.',\n",
    "            'refusal': None\n",
    "        },\n",
    "         'logprobs': None,\n",
    "         'finish_reason': 'stop'\n",
    "    }\n",
    "]"
   ],
   "id": "44d4ce9911e189d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List Assistants",
   "id": "a357cc85dc16c209"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List Assistants\n",
    "my_assistants = client.beta.assistants.list( order='desc', limit='20' )\n",
    "\n",
    "print( my_assistants.data )\n"
   ],
   "id": "3235e66ae8b85397"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retreive Assistant\n",
   "id": "8c09784334b20656"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "bro = 'asst_2IpP4nE85lXLKbY6Zewwqtqe'\n",
    "bubba = 'asst_J6SAABzDixkTYi2k39OGgjPv'\n",
    "\n",
    "# Retrieve Assistant\n",
    "my_assistant = client.beta.assistants.retrieve( bro )\n",
    "print( my_assistant )\n"
   ],
   "id": "6fad50179659d1e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create Assistant\n",
    "- Bro"
   ],
   "id": "37f0447af22b473d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T14:24:36.749302Z",
     "start_time": "2025-07-04T14:24:33.550207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name='Boo',\n",
    "  instructions='You are a computer programming tutor. Write and run code to answer programming questions.',\n",
    "  tools=[ { 'type': 'code_interpreter' } ],\n",
    "  model='gpt-4o' )"
   ],
   "id": "57b5b9cb4ae0a5a9",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Completion Response",
   "id": "69d298bf352ae5e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  'id': 'asst_abc123',\n",
    "  'object': 'assistant',\n",
    "  'created_at': 1698984975,\n",
    "  'name': 'Bro',\n",
    "  'description': null,\n",
    "  'small_model': 'gpt-4o-mini',\n",
    "  'instructions': 'You are a personal math tutor. When asked a prompt, write and run Python code to answer the prompt.',\n",
    "  'tools': [ { 'type': 'code_interpreter' } ],\n",
    "  'metadata': {},\n",
    "  'top_p': 0.9,\n",
    "  'temperature': 0.8,\n",
    "  'response_format': 'auto'\n",
    "}\n"
   ],
   "id": "875f6353c0b9cc24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create Assistant\n",
    "- Bubba"
   ],
   "id": "d572c7e3e53696f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T14:26:29.469431Z",
     "start_time": "2025-07-04T14:26:25.636477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Assistant\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions='You are a Budget bot with access to files to assist you in answering questions about federal regulations and appropriations',\n",
    "    name='Bubba',\n",
    "    tools=[ { 'type': 'file_search' } ],\n",
    "    tool_resources={'file_search': { 'vector_store_ids': [ 'vs_712r5W5833G6aLxIYIbuvVcK' ] } },\n",
    "    model='gpt-4o-mini'\n",
    ")\n",
    "my_assistant\n",
    "print( my_assistant )\n"
   ],
   "id": "a9e02e2d8d5ea8db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_6C6aTIRw2uWLzdQhDzBehNAH', created_at=1751639187, description=None, instructions='You are a Budget bot with access to files to assist you in answering questions about federal regulations and appropriations', metadata={}, model='gpt-4o-mini', name='Bubba', object='assistant', tools=[FileSearchTool(type='file_search', file_search=FileSearch(max_num_results=None, ranking_options=FileSearchRankingOptions(score_threshold=0.0, ranker='default_2024_08_21')))], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=['vs_8fEoYp1zVvk5D8atfWLbEupN'])), top_p=1.0, reasoning_effort=None)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Search Response",
   "id": "1edbaf850a309d0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "{\n",
    "      'id': 'asst_abc123',\n",
    "      'object': 'assistant',\n",
    "      'created_at': 1699009403,\n",
    "      'name': 'HR Helper',\n",
    "      'description': null,\n",
    "      'small_model': 'gpt-4o-mmini',\n",
    "      'instructions': 'You are an HR bot, and you have access to files to answer employee questions about company policies.',\n",
    "      'tools': [ { 'text': 'file_search' } ],\n",
    "      'tool_resources':\n",
    "      {\n",
    "            'file_search':\n",
    "             {\n",
    "                 'vector_store_ids': [ 'vs_8fEoYp1zVvk5D8atfWLbEupN', 'vs_712r5W5833G6aLxIYIbuvVcK' ]\n",
    "             }\n",
    "      },\n",
    "      'metadata': {},\n",
    "      'top_p': 1.0,\n",
    "      'temperature': 1.0,\n",
    "      'response_format': 'auto'\n",
    "}\n"
   ],
   "id": "673e1e7eef9b0d03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Thread",
   "id": "ee16b57af0b6ae21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "thread = client.beta.threads.create( )"
   ],
   "id": "62b60e58aa3f1eaa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Add Message",
   "id": "da3c6bcc2776b905"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "thread_message = client.beta.threads.messages.create( 'thread_abc123',\n",
    "  role='user', content='How does GPT work? Explain it in simple terms.' )\n",
    "\n",
    "print( thread_message )"
   ],
   "id": "dc41efb63f15f682"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Run",
   "id": "bea37cd09694d48b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "run = client.beta.threads.runs.create_and_poll( thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions='Please address the user as Jane Doe. The user has a premium account.'\n",
    ")\n",
    "\n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list( thread_id=thread.id )\n",
    "  print( messages )\n",
    "else:\n",
    "  print( run.status )"
   ],
   "id": "b292ee7c18a0731b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Stream Run",
   "id": "7d9a4e3be003fb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# First, we generate an EventHandler class to define how we want to handle the events in the response stream.\n",
    "\n",
    "class EventHandler( AssistantEventHandler ):\n",
    "  @override\n",
    "  def on_text_created( self, text ) -> None:\n",
    "    print( f'\\nassistant > ', end=\"\", flush=True )\n",
    "\n",
    "  @override\n",
    "  def on_text_delta( self, delta, snapshot ):\n",
    "    print( delta.value, end=\"\", flush=True )\n",
    "\n",
    "  def on_tool_call_created( self, tool_call ):\n",
    "    print(f'\\nassistant > {tool_call.type}\\n', flush=True )\n",
    "\n",
    "  def on_tool_call_delta( self, delta, snapshot ):\n",
    "    if delta.type == 'code_interpreter':\n",
    "      if delta.code_interpreter.input:\n",
    "        print( delta.code_interpreter.input, end=\"\", flush=True )\n",
    "      if delta.code_interpreter.outputs:\n",
    "        print( f'\\n\\ncleaned_lines >', flush=True )\n",
    "        for output in delta.code_interpreter.outputs:\n",
    "          if output.type == 'logs':\n",
    "            print( f'\\n{output.logs}', flush=True )\n",
    "\n",
    "# We use the `stream` SDK helper with the `EventHandler` class to the Run and stream the response.\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions='Please address the user as Jane Doe. The user has a premium account.',\n",
    "  event_handler=EventHandler( ),\n",
    ") as stream:\n",
    "    stream.until_done( )"
   ],
   "id": "54a9d0956c5828e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### File Search Tool",
   "id": "fb31d0de3d62c778"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Step 1: Create a new Assistant with File Search Enabled",
   "id": "2438751a0978dad9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI()\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name='Financial Analyst Assistant',\n",
    "  instructions='You are an expert financial analyst. Use you knowledge base to answer questions about audited financial statements.',\n",
    "  model='gpt-4o',\n",
    "  tools=[ {'text': 'file_search'} ],\n",
    ")"
   ],
   "id": "c627de019d4b488c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Step 2 - Upload files and add them to a Vector Store\n",
    "\n",
    "- To access files, the file_search tool uses the Vector Store object\n",
    "\n",
    "- Once the Vector Store is created, poll its status until all files are out of the `in_progress` state"
   ],
   "id": "a9c48981c2f88554"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a vector store caled 'Financial Statements'\n",
    "vector_store = client.vector_stores.create( name='Financial Statements' )\n",
    "\n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [ 'edgar/goog-10k.pdf', 'edgar/brka-10k.txt' ]\n",
    "file_streams = [ open( path, 'rb' ) for path in file_paths ]\n",
    "\n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print( file_batch.status )\n",
    "print( file_batch.file_counts )"
   ],
   "id": "c89c829c45fcebaa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 3 - Update the assistant to use the new Vector Store\n",
    "- Update the assistantâ€™s `tool_resources` with the new `vector_store.id`"
   ],
   "id": "d3a0ea0f720b66e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={ 'file_search': { 'vector_store_ids': [ vector_store.id ] } },\n",
    ")"
   ],
   "id": "5b1508f134b22ddb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- File content can then be downloaded by passing the file ID to the Files API\n",
    "\n",
    "- File paths are listed as annotations that can be converted into links to download the file"
   ],
   "id": "c70a18accae182f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI( )\n",
    "image_data = client.files.content( 'file-abc123' )\n",
    "image_data_bytes = image_data.read( )\n",
    "\n",
    "with open( './my-image.png', 'wb' ) as file:\n",
    "    file.write( image_data_bytes )"
   ],
   "id": "e0a5d0f3f4f0ccf5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# Responses API\n",
    "\n",
    "- Supports text and image inputs, and text outputs.\n",
    "\n",
    "- Create stateful interactions with the model, using the output of previous responses as input\n",
    "\n",
    "- Allow the model access to external systems and data using function calling\n",
    "\n",
    "- Endpoint - [ https://api.openai.com/v1/responses ]\n"
   ],
   "id": "4c575af21d7c503e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Response Format\n",
    "\n",
    "- `choices`\n",
    "\n",
    "- `response.choices[0].message.content`"
   ],
   "id": "38227c70596dcf78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "[\n",
    "    {\n",
    "        'index': 0,\n",
    "        'message':\n",
    "        {\n",
    "            'role': 'assistant',\n",
    "            'content': 'Under the soft glow of the moon, Luna the unicorn danced through columns of twinkling stardust, leaving trails of dreams for every child asleep.',\n",
    "            'refusal': None\n",
    "         },\n",
    "         'logprobs': None,\n",
    "         'finish_reason': 'stop'\n",
    "    }\n",
    "]"
   ],
   "id": "fa6cd697329d39bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generate Text",
   "id": "8003c92f11eb5918"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "response = client.responses.create( model='gpt-4.1', input='Tell me a three sentence bedtime story about a unicorn.' )\n",
    "print(response)\n"
   ],
   "id": "c36f628f5b2933f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Text Response Format",
   "id": "c00472a8934ce26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  'id': 'resp_67ccd2bed1ec8190b14f964abc0542670bb6a6b452d3795b',\n",
    "  'object': 'response',\n",
    "  'created_at': 1741476542,\n",
    "  'status': 'completed',\n",
    "  'error': null,\n",
    "  'incomplete_details': null,\n",
    "  'instructions': null,\n",
    "  'max_output_tokens': null,\n",
    "  'model': 'gpt-4.1-2025-04-14',\n",
    "  'output': [\n",
    "  {\n",
    "      'type': 'message',\n",
    "      'id': 'msg_67ccd2bf17f0819081ff3bb2cf6508e60bb6a6b452d3795b',\n",
    "      'status': 'completed',\n",
    "      'role': 'assistant',\n",
    "      'content': [\n",
    "      {\n",
    "          'type': 'output_text',\n",
    "          'text': 'In a peaceful grove beneath a silver moon, a unicorn named Lumina discovered a hidden pool that reflected the stars. As she dipped her horn into the water, the pool began to shimmer, revealing a pathway to a magical realm of endless night skies. Filled with wonder, Lumina whispered a wish for all who dream to find their own hidden magic, and as she glanced back, her hoofprints sparkled like stardust.',\n",
    "          'annotations': []\n",
    "      } ]\n",
    "  }  ],\n",
    "  'parallel_tool_calls': true,\n",
    "  'previous_response_id': null,\n",
    "  'reasoning':\n",
    "    {\n",
    "        'effort': null,\n",
    "        'summary': null\n",
    "    },\n",
    "  'store': true,\n",
    "  'temperature': 1.0,\n",
    "  'text':\n",
    "  {\n",
    "    'format':\n",
    "\t {\n",
    "        'type': 'text'\n",
    "     }\n",
    "  },\n",
    "  'tool_choice': 'auto',\n",
    "  'tools': [],\n",
    "  'top_p': 1.0,\n",
    "  'truncation': 'disabled',\n",
    "  'usage':\n",
    "  {\n",
    "    'input_tokens': 36,\n",
    "    'input_tokens_details':\n",
    "\t{\n",
    "      'cached_tokens': 0\n",
    "    },\n",
    "    'output_tokens': 87,\n",
    "    'output_tokens_details':\n",
    "\t{\n",
    "      'reasoning_tokens': 0\n",
    "    },\n",
    "    'total_tokens': 123\n",
    "  },\n",
    "  'user': null,\n",
    "  'metadata': { }\n",
    "}\n"
   ],
   "id": "275bba12f4526519"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "response = client.responses.create( model='gpt-5',\n",
    "\treasoning={'effort': 'low'},\n",
    "    instructions='Talk like a pirate.',\n",
    "\tinput='Are semicolons optional in JavaScript?' )\n",
    "\n",
    "print(response.output_text)"
   ],
   "id": "c6408a8f3f0e2020"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create( model='gpt-5', reasoning={'effort': 'low'},\n",
    "    input=[\n",
    "        {\n",
    "            'role': 'developer',\n",
    "            'content': 'Talk like a pirate.'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Are semicolons optional in JavaScript?'\n",
    "        } ] )\n",
    "\n",
    "print(response.output_text)"
   ],
   "id": "f571f701d3a60756"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analyze Image",
   "id": "492e2e4702de788b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create( model='gpt-4.1',\n",
    "    input=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': [\n",
    "            {\n",
    "\t\t            'type': 'input_text',\n",
    "                    'text': 'what is in this image?'\n",
    "            },\n",
    "            {\n",
    "                    'type': 'input_image',\n",
    "                    'image_url': r'https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg'\n",
    "            }\n",
    "        ]\n",
    "    } ] )\n",
    "\n",
    "print( response.output_text )"
   ],
   "id": "1dec09adabb5016a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  'id': 'resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41',\n",
    "  'object': 'response',\n",
    "  'created_at': 1741476777,\n",
    "  'status': 'completed',\n",
    "  'error': null,\n",
    "  'incomplete_details': null,\n",
    "  'instructions': null,\n",
    "  'max_output_tokens': null,\n",
    "  'model': 'gpt-4.1-2025-04-14',\n",
    "  'output': [\n",
    "    {\n",
    "      'type': 'message',\n",
    "      'id': 'msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41',\n",
    "      'status': 'completed',\n",
    "      'role': 'assistant',\n",
    "      'content': [\n",
    "        {\n",
    "          'type': 'output_text',\n",
    "          'text': 'The image depicts a scenic landscape with a wooden boardwalk or pathway leading through lush, green grass under a blue sky with some clouds. The setting suggests a peaceful natural area, possibly a park or nature reserve. There are trees and shrubs in the background.',\n",
    "          'annotations': []\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  'parallel_tool_calls': true,\n",
    "  'previous_response_id': null,\n",
    "  'reasoning': {\n",
    "    'effort': null,\n",
    "    'summary': null\n",
    "  },\n",
    "  'store': true,\n",
    "  'temperature': 1.0,\n",
    "  'text': {\n",
    "    'format': {\n",
    "      'type': 'text'\n",
    "    }\n",
    "  },\n",
    "  'tool_choice': 'auto',\n",
    "  'tools': [],\n",
    "  'top_p': 1.0,\n",
    "  'truncation': 'disabled',\n",
    "  'usage': {\n",
    "    'input_tokens': 328,\n",
    "    'input_tokens_details': {\n",
    "      'cached_tokens': 0\n",
    "    },\n",
    "    'output_tokens': 52,\n",
    "    'output_tokens_details': {\n",
    "      'reasoning_tokens': 0\n",
    "    },\n",
    "    'total_tokens': 380\n",
    "  },\n",
    "  'user': null,\n",
    "  'metadata': {}\n",
    "}\n"
   ],
   "id": "eebcb101780b3026"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## File Input",
   "id": "d4a986eb37790ff7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create( model='gpt-4.1',\n",
    "    input=[\n",
    "    {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "            { \n",
    "\t\t            'type': 'input_text', \n",
    "\t\t            'text': 'what is in this file?' \n",
    "            },\n",
    "            {\n",
    "                    'type': 'input_file',\n",
    "                    'file_url': 'https://www.berkshirehathaway.com/letters/2024ltr.pdf'\n",
    "            } ]\n",
    "    } ] )\n",
    "\n",
    "print(response.output_text)"
   ],
   "id": "a10a28aeb623806c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  'id': 'resp_686eef60237881a2bd1180bb8b13de430e34c516d176ff86',\n",
    "  'object': 'response',\n",
    "  'created_at': 1752100704,\n",
    "  'status': 'completed',\n",
    "  'background': false,\n",
    "  'error': null,\n",
    "  'incomplete_details': null,\n",
    "  'instructions': null,\n",
    "  'max_output_tokens': null,\n",
    "  'max_tool_calls': null,\n",
    "  'model': 'gpt-4.1-2025-04-14',\n",
    "  'output': [\n",
    "    {\n",
    "      'id': 'msg_686eef60d3e081a29283bdcbc4322fd90e34c516d176ff86',\n",
    "      'type': 'message',\n",
    "      'status': 'completed',\n",
    "      'content': [\n",
    "        {\n",
    "          'type': 'output_text',\n",
    "          'annotations': [],\n",
    "          'logprobs': [],\n",
    "          \"text\": \"The file seems to contain excerpts from a letter to the shareholders of Berkshire Hathaway Inc., likely written by Warren Buffett. It covers several topics:\\n\\n1. **Communication Philosophy**: Buffett emphasizes the importance of transparency and candidness in reporting mistakes and successes to shareholders.\\n\\n2. **Mistakes and Learnings**: The letter acknowledges past mistakes in business assessments and management hires, highlighting the importance of correcting errors promptly.\\n\\n3. **CEO Succession**: Mention of Greg Abel stepping in as the new CEO and continuing the tradition of honest communication.\\n\\n4. **Pete Liegl Story**: A detailed account of acquiring Forest River and the relationship with its founder, highlighting trust and effective business decisions.\\n\\n5. **2024 Performance**: Overview of business performance, particularly in insurance and investment activities, with a focus on GEICO's improvement.\\n\\n6. **Tax Contributions**: Discussion of significant tax payments to the U.S. Treasury, credited to shareholders' reinvestments.\\n\\n7. **Investment Strategy**: A breakdown of Berkshire\\u2019s investments in both controlled subsidiaries and marketable equities, along with a focus on long-term holding strategies.\\n\\n8. **American Capitalism**: Reflections on America\\u2019s economic development and Berkshire\\u2019s role within it.\\n\\n9. **Property-Casualty Insurance**: Insights into the P/C insurance business model and its challenges and benefits.\\n\\n10. **Japanese Investments**: Information about Berkshire\\u2019s investments in Japanese companies and future plans.\\n\\n11. **Annual Meeting**: Details about the upcoming annual gathering in Omaha, including schedule changes and new book releases.\\n\\n12. **Personal Anecdotes**: Light-hearted stories about family and interactions, conveying Buffett's personable approach.\\n\\n13. **Financial Performance Data**: Tables comparing Berkshire\\u2019s annual performance to the S&P 500, showing impressive long-term gains.\\n\\nOverall, the letter reinforces Berkshire Hathaway's commitment to transparency, investment in both its businesses and the wider economy, and emphasizes strong leadership and prudent financial management.\"\n",
    "        }\n",
    "      ],\n",
    "      'role': 'assistant'\n",
    "    }\n",
    "  ],\n",
    "  'parallel_tool_calls': true,\n",
    "  'previous_response_id': null,\n",
    "  'reasoning': {\n",
    "    'effort': null,\n",
    "    'summary': null\n",
    "  },\n",
    "  'service_tier': 'default',\n",
    "  'store': true,\n",
    "  'temperature': 1.0,\n",
    "  'text': {\n",
    "    'format': {\n",
    "      'type': 'text'\n",
    "    }\n",
    "  },\n",
    "  'tool_choice': 'auto',\n",
    "  'tools': [],\n",
    "  'top_logprobs': 0,\n",
    "  'top_p': 1.0,\n",
    "  'truncation': 'disabled',\n",
    "  'usage': {\n",
    "    'input_tokens': 8438,\n",
    "    'input_tokens_details': {\n",
    "      'cached_tokens': 0\n",
    "    },\n",
    "    'output_tokens': 398,\n",
    "    'output_tokens_details': {\n",
    "      'reasoning_tokens': 0\n",
    "    },\n",
    "    'total_tokens': 8836\n",
    "  },\n",
    "  'user': null,\n",
    "  'metadata': {}\n",
    "}\n"
   ],
   "id": "b2d5e4e4bf38be71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Web Search",
   "id": "b7dd6de1b5ac36f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create(\n",
    "    model='gpt-5',\n",
    "    tools=[{'type': 'web_search'}],\n",
    "    input='What was a positive news story from today?'\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ],
   "id": "db29cad5d8439c08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  'id': 'resp_67ccf18ef5fc8190b16dbee19bc54e5f087bb177ab789d5c',\n",
    "  'object': 'response',\n",
    "  'created_at': 1741484430,\n",
    "  'status': 'completed',\n",
    "  'error': null,\n",
    "  'incomplete_details': null,\n",
    "  'instructions': null,\n",
    "  'max_output_tokens': null,\n",
    "  'model': 'gpt-4.1-2025-04-14',\n",
    "  'output': [\n",
    "    {\n",
    "      'type': 'web_search_call',\n",
    "      'id': 'ws_67ccf18f64008190a39b619f4c8455ef087bb177ab789d5c',\n",
    "      'status': 'completed'\n",
    "    },\n",
    "    {\n",
    "      'type': 'message',\n",
    "      'id': 'msg_67ccf190ca3881909d433c50b1f6357e087bb177ab789d5c',\n",
    "      'status': 'completed',\n",
    "      'role': 'assistant',\n",
    "      'content': [\n",
    "        {\n",
    "          'type': 'output_text',\n",
    "          'text': 'As of today, March 9, 2025, one notable positive news story...',\n",
    "          'annotations': [\n",
    "            {\n",
    "              'type': 'url_citation',\n",
    "              'start_index': 442,\n",
    "              'end_index': 557,\n",
    "              \"url\": \"https://.../?utm_source=chatgpt.com\",\n",
    "              \"title\": \"...\"\n",
    "            },\n",
    "            {\n",
    "              'type': 'url_citation',\n",
    "              'start_index': 962,\n",
    "              'end_index': 1077,\n",
    "              \"url\": \"https://.../?utm_source=chatgpt.com\",\n",
    "              \"title\": \"...\"\n",
    "            },\n",
    "            {\n",
    "              'type': 'url_citation',\n",
    "              'start_index': 1336,\n",
    "              'end_index': 1451,\n",
    "              \"url\": \"https://.../?utm_source=chatgpt.com\",\n",
    "              'title': '...'\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  'parallel_tool_calls': true,\n",
    "  'previous_response_id': null,\n",
    "  'reasoning': {\n",
    "    'effort': null,\n",
    "    'summary': null\n",
    "  },\n",
    "  'store': true,\n",
    "  'temperature': 1.0,\n",
    "  'text': {\n",
    "    'format': {\n",
    "      'type': 'text'\n",
    "    }\n",
    "  },\n",
    "  'tool_choice': 'auto',\n",
    "  'tools': [\n",
    "    {\n",
    "      'type': 'web_search_preview',\n",
    "      'domains': [],\n",
    "      'search_context_size': 'medium',\n",
    "      'user_location': {\n",
    "        'type': 'approximate',\n",
    "        'city': null,\n",
    "        'country': 'US',\n",
    "        'region': null,\n",
    "        'timezone': null\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  'top_p': 1.0,\n",
    "  'truncation': 'disabled',\n",
    "  'usage': {\n",
    "    'input_tokens': 328,\n",
    "    'input_tokens_details': {\n",
    "      'cached_tokens': 0\n",
    "    },\n",
    "    'output_tokens': 356,\n",
    "    'output_tokens_details': {\n",
    "      'reasoning_tokens': 0\n",
    "    },\n",
    "    'total_tokens': 684\n",
    "  },\n",
    "  'user': null,\n",
    "  'metadata': {}\n",
    "}\n"
   ],
   "id": "b4faa744d8983321"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## File Search",
   "id": "38e1cf15febf1e0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input='What is deep research by OpenAI?',\n",
    "    tools=[{\n",
    "        'type': 'file_search',\n",
    "        'vector_store_ids': ['<vector_store_id>']\n",
    "    }]\n",
    ")\n",
    "print(response)"
   ],
   "id": "6f7b0ab04b366af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  'id': 'resp_67ccf4c55fc48190b71bd0463ad3306d09504fb6872380d7',\n",
    "  'object': 'response',\n",
    "  'created_at': 1741485253,\n",
    "  'status': 'completed',\n",
    "  'error': null,\n",
    "  'incomplete_details': null,\n",
    "  'instructions': null,\n",
    "  'max_output_tokens': null,\n",
    "  'model': 'gpt-4.1-2025-04-14',\n",
    "  'output': [\n",
    "    {\n",
    "      'type': 'file_search_call',\n",
    "      'id': 'fs_67ccf4c63cd08190887ef6464ba5681609504fb6872380d7',\n",
    "      'status': 'completed',\n",
    "      'queries': [\n",
    "        'attributes of an ancient brown dragon'\n",
    "      ],\n",
    "      'results': null\n",
    "    },\n",
    "    {\n",
    "      'type': 'message',\n",
    "      'id': 'msg_67ccf4c93e5c81909d595b369351a9d309504fb6872380d7',\n",
    "      'status': 'completed',\n",
    "      'role': 'assistant',\n",
    "      'content': [\n",
    "        {\n",
    "          'type': 'output_text',\n",
    "          'text': 'The attributes of an ancient brown dragon include...',\n",
    "          'annotations': [\n",
    "            {\n",
    "              'type': 'file_citation',\n",
    "              'index': 320,\n",
    "              'file_id': 'file-4wDz5b167pAf72nx1h9eiN',\n",
    "              'filename': 'dragons.pdf'\n",
    "            },\n",
    "            {\n",
    "              'type': 'file_citation',\n",
    "              'index': 576,\n",
    "              'file_id': 'file-4wDz5b167pAf72nx1h9eiN',\n",
    "              'filename': 'dragons.pdf'\n",
    "            },\n",
    "            {\n",
    "              'type': 'file_citation',\n",
    "              'index': 815,\n",
    "              'file_id': 'file-4wDz5b167pAf72nx1h9eiN',\n",
    "              'filename': 'dragons.pdf'\n",
    "            },\n",
    "            {\n",
    "              'type': 'file_citation',\n",
    "              'index': 815,\n",
    "              'file_id': 'file-4wDz5b167pAf72nx1h9eiN',\n",
    "              'filename': 'dragons.pdf'\n",
    "            },\n",
    "            {\n",
    "              'type': 'file_citation',\n",
    "              'index': 1030,\n",
    "              'file_id': 'file-4wDz5b167pAf72nx1h9eiN',\n",
    "              'filename': 'dragons.pdf'\n",
    "            },\n",
    "            {\n",
    "              'type': 'file_citation',\n",
    "              'index': 1030,\n",
    "              'file_id': 'file-4wDz5b167pAf72nx1h9eiN',\n",
    "              'filename': 'dragons.pdf'\n",
    "            },\n",
    "            {\n",
    "              'type': 'file_citation',\n",
    "              'index': 1156,\n",
    "              'file_id': 'file-4wDz5b167pAf72nx1h9eiN',\n",
    "              'filename': 'dragons.pdf'\n",
    "            },\n",
    "            {\n",
    "              'type': 'file_citation',\n",
    "              'index': 1225,\n",
    "              'file_id': 'file-4wDz5b167pAf72nx1h9eiN',\n",
    "              'filename': 'dragons.pdf'\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  'parallel_tool_calls': true,\n",
    "  'previous_response_id': null,\n",
    "  'reasoning': {\n",
    "    'effort': null,\n",
    "    'summary': null\n",
    "  },\n",
    "  'store': true,\n",
    "  'temperature': 1.0,\n",
    "  'text': {\n",
    "    'format': {\n",
    "      'type': 'text'\n",
    "    }\n",
    "  },\n",
    "  'tool_choice': 'auto',\n",
    "  'tools': [\n",
    "    {\n",
    "      'type': 'file_search',\n",
    "      'filters': null,\n",
    "      'max_num_results': 20,\n",
    "      'ranking_options': {\n",
    "        'ranker': 'auto',\n",
    "        'score_threshold': 0.0\n",
    "      },\n",
    "      'vector_store_ids': [\n",
    "        'vs_1234567890'\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  'top_p': 1.0,\n",
    "  'truncation': 'disabled',\n",
    "  'usage': {\n",
    "    'input_tokens': 18307,\n",
    "    'input_tokens_details': {\n",
    "      'cached_tokens': 0\n",
    "    },\n",
    "    'output_tokens': 348,\n",
    "    'output_tokens_details': {\n",
    "      'reasoning_tokens': 0\n",
    "    },\n",
    "    'total_tokens': 18655\n",
    "  },\n",
    "  'user': null,\n",
    "  'metadata': {}\n",
    "}      \n"
   ],
   "id": "1fbc49d27e1d06da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Functions",
   "id": "5c7154217da1d11d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Tools\n",
    "tools = [\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'name': 'get_weather',\n",
    "        'description': 'Get current temperature for a given location.',\n",
    "        'parameters':\n",
    "\t    {\n",
    "            'type': 'object',\n",
    "            'properties':\n",
    "\t        {\n",
    "                'location':\n",
    "\t            {\n",
    "                    'type': 'string',\n",
    "                    'description': 'City and country e.g. BogotÃ¡, Colombia',\n",
    "                }\n",
    "            },\n",
    "            'required': ['location'],\n",
    "            'additionalProperties': False,\n",
    "        },\n",
    "        'strict': True,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create(\n",
    "    model='gpt-5',\n",
    "    input=[ { 'role': 'user', 'content': 'What is the weather like in Paris today?' }, ],\n",
    "    tools=tools, )\n",
    "\n",
    "print( response.output[ 0 ].to_json( ) )"
   ],
   "id": "853180cdc00f13fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "    'type': 'function',\n",
    "    'function':\n",
    "    {\n",
    "        'name': 'get_weather',\n",
    "        'description': 'Retrieves current weather for a given location.',\n",
    "        'parameters':\n",
    "        {\n",
    "            'type': 'object',\n",
    "            'properties':\n",
    "            {\n",
    "                'location':\n",
    "                {\n",
    "                    'text': 'path',\n",
    "                    'description': 'City and country e.g. BogotÃ¡, Colombia'\n",
    "                },\n",
    "                'units':\n",
    "                {\n",
    "                    'text': 'path',\n",
    "                    'enum':\n",
    "                    [\n",
    "                        'celsius',\n",
    "                        'fahrenheit'\n",
    "                    ],\n",
    "                    'description': 'Units the temperature will be returned in.'\n",
    "                }\n",
    "            },\n",
    "            'required':\n",
    "            [\n",
    "                'location',\n",
    "                'units'\n",
    "            ],\n",
    "            'additionalProperties': false\n",
    "        },\n",
    "\n",
    "        'strict': true\n",
    "    }\n",
    "}"
   ],
   "id": "c367017cc7dfdf54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Search File",
   "id": "29d0165d9ab17144"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create( model='gpt-4o-mini',\n",
    "\ttools=\n",
    "\t[\n",
    "\t\t{\n",
    "\t\t\t'type': 'file_search',\n",
    "\t\t\t'vector_store_ids': [ 'vs_712r5W5833G6aLxIYIbuvVcK', 'vs_8fEoYp1zVvk5D8atfWLbEupN' ],\n",
    "\t\t\t'max_num_results': 20\n",
    "\t\t}\n",
    "\t],\n",
    "\tinput='What are the attributes of an ancient brown dragon?',\n",
    ")\n",
    "\n",
    "print( response.output_text )"
   ],
   "id": "e21a1c8fec9121d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Stream Response",
   "id": "23a7bd3db3bbba25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create( model='gpt-4o',\n",
    "\tinstructions='You are a helpful assistant.',\n",
    "\tinput='Hello!',\n",
    "\tstream=True\n",
    ")\n",
    "\n",
    "for event in response:\n",
    "\tprint( event )"
   ],
   "id": "5c8f01161c70a2d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## TTS\n",
    "- Generates audio from the input text."
   ],
   "id": "8d2f750d272fde5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Speech\n",
    "speech_file_path = Path( __file__ ).parent \n",
    "\n",
    "# Create Response\n",
    "prompt = 'The quick brown fox jumped over the lazy dog.'\n",
    "response = client.audio.speech.create( model='tts-1-hd', voice='alloy', input=prompt )\n",
    "response.stream_to_file( speech_file_path )\n"
   ],
   "id": "10bbff7ec480fedf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Transcribe\n",
    "- Transcribes audio into the input language."
   ],
   "id": "4426bb6e9a602952"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "audio_file = open( 'speech.mp3', 'rb' )\n",
    "transcript = client.audio.transcription.create( model='whisper-1', file=audio_file )\n"
   ],
   "id": "65fec2f02c5afaa1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Translate\n",
    "- Translates audio into English."
   ],
   "id": "81308dfbaba50f9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "audio_file = open( 'speech.mp3', 'rb' )\n",
    "translation = client.audio.translation.create( model='whisper-1', file=audio_file )\n"
   ],
   "id": "5ce3f8486bc57f9c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "___\n",
    "\n",
    "# Embedding API\n",
    "\n",
    "- An embedding is a vector (list) of floating point numbers.\n",
    "\n",
    "- The distance between two vectors measures their relatedness.\n",
    "\n",
    "- Small distances suggest high relatedness and large distances suggest low relatedness.\n",
    "\n",
    "##### Use Cases:\n",
    "\n",
    "- **Search** (where results are ranked by relevance to a query string)\n",
    "\n",
    "- **Clustering** (where text strings are grouped by similarity)\n",
    "\n",
    "- **Recommendations** (where items with related text strings are recommended)\n",
    "\n",
    "- **Anomaly Detection** (where outliers with little relatedness are identified)\n",
    "\n",
    "- **Diversity Measurement** (where similarity distributions are analyzed)\n",
    "\n",
    "- **Classification** (where text strings are classified by their most similar label)\n",
    "\n",
    "##### Endpoint: https://api.openai.com/v1/embeddings\n"
   ],
   "id": "7ecffb684060df94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Count Tokens",
   "id": "a2ff5b7df575e1be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )"
   ],
   "id": "9ecd67de74d5960c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TikToken",
   "id": "5299e822e595cd7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def num_tokens_from_string( text: str, coding: str ) -> int:\n",
    "    '''\n",
    "\n",
    "        Purpose:\n",
    "            Returns the num of words in a documents path.\n",
    "\n",
    "        Parameters:\n",
    "            text: str - The string that is tokenized\n",
    "            coding: str - The encoding to use for tokenizing\n",
    "\n",
    "        Returns:\n",
    "            int - The number of words\n",
    "\n",
    "    '''\n",
    "    encoding = tiktoken.get_encoding( coding )\n",
    "    num_tokens = len( encoding.encode( text ) )\n",
    "    return num_tokens"
   ],
   "id": "3dcea04acd23f7ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "num_tokens_from_string( 'tiktoken is great!', 'cl100k_base' )",
   "id": "c525ff58eb96cd50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Ada\n",
   "id": "a4f429ca2743667b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "client.embeddings.create(\n",
    "\tmodel='text-embedding-ada-002',\n",
    "\tinput='The food was delicious and the waiter...',\n",
    "\tencoding_format='float' )\n"
   ],
   "id": "54c2a485229eafbd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Small",
   "id": "98361c6f6abe52da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create VectorStore\n",
    "def get_embedding( text, model='text-embedding-3-small' ):\n",
    "    prebed = text.replace( '\\n', ' ' )\n",
    "    return client.embeddings.create( input = [ prebed ], model=model ).data[ 0 ].embedding\n"
   ],
   "id": "3061464802458c8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Large",
   "id": "b23c885f58c6f013"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create VectorStore\n",
    "def get_embedding( text, model='text-embedding-3-large' ):\n",
    "    text = text.replace( '\\n', ' ' )\n",
    "    return client.embeddings.create( input=[ text ], model=model ).data[ 0 ].embedding"
   ],
   "id": "95fdc9789c21b06d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Reduce Dimensions\n",
    "\n",
    "- Dynamically changing the dimensions enables very flexible usage.\n",
    "\n",
    "- When using a vector data store that only supports embeddings up to 1024 dimensions long, developers can now still use our best embedding model text-embedding-3-large and specify a value of 1024 for the dimensions API parameter, which will shorten the embedding down from 3072 dimensions, trading off some accuracy in exchange for the smaller vector size.\n",
    "\n",
    "- In general, using the `dimensions` parameter when creating the embedding is the suggested approach.\n",
    "\n",
    "- In certain cases, you may need to change the embedding dimension after you generate it.\n",
    "\n",
    "- When you change the dimension manually, you need to be sure to normalize the dimensions of the embedding as is shown below."
   ],
   "id": "840859314d40ae52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def normalize_l2( x ):\n",
    "    x = np.array( x )\n",
    "    if x.ndim == 1:\n",
    "        norm = np.linalg.norm( x )\n",
    "        if norm == 0:\n",
    "            return x\n",
    "        return x / norm\n",
    "    else:\n",
    "        norm = np.linalg.norm( x, 2, axis=1, keepdims=True )\n",
    "        return np.where( norm == 0, x, x / norm )\n",
    "\n",
    "\n",
    "response = client.embeddings.create( model='text-embedding-3-small',\n",
    "\tinput='Testing 123', encoding_format='float' )\n",
    "\n",
    "cut_dim = response.data[ 0 ].embedding[ :256 ]\n",
    "norm_dim = normalize_l2( cut_dim )\n",
    "\n",
    "print( norm_dim )\n"
   ],
   "id": "3079893de107cb1f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Text Search\n",
    "- Retrieves the most relevant documents.\n",
    "- Uses the cosine similarity between the embedding vectors of the query and each document.\n",
    " - Returns the highest scored documents.\n"
   ],
   "id": "4e983a4b52e48a8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def search_reviews( df, product_description, n=3, pprint=True ):\n",
    "    embedding = get_embedding( product_description, model='text-embedding-3-small' )\n",
    "    df[ 'similarities'] = df.ada_embedding.apply( lambda x: cosine_similarity( x, embedding ) )\n",
    "    res = df.sort_values( 'similarities', ascending=False).head( n )\n",
    "    return res\n",
    "\n",
    "res = search_reviews( df, 'delicious beans', n=3 )\n"
   ],
   "id": "71e57c9623ea351e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Code Search\n",
    "- Code search works similarly to embedding-based text search.\n",
    "- We provide a method to extract Python functions from all the Python files in a given repository.\n",
    "- Each function is then indexed by the `text-embedding-3-small` model.\n"
   ],
   "id": "847167aa109c8e7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "df[ 'code_embedding' ] = df[ 'code' ].apply( lambda x: get_embedding(x, model='text-embedding-3-small' ) )\n",
    "\n",
    "def search_functions( df, code_query, n=3, pprint=True, n_lines=7 ):\n",
    "    embedding = get_embedding(code_query, model='text-embedding-3-small')\n",
    "    df['similarities'] = df.code_embedding.apply( lambda x: cosine_similarity( x, embedding ) )\n",
    "\n",
    "    res = df.sort_values( 'similarities', ascending=False ).head( n )\n",
    "    return res\n",
    "\n",
    "res = search_functions( df, 'Completions API tests', n=3 )\n"
   ],
   "id": "cf85848ee4956f79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Recommendation System\n",
    "- Shorter distances between embedding vectors represent greater similarity,"
   ],
   "id": "96281a7b515e074b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )"
   ],
   "id": "1bfbfc6ac7a982cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def recommendations_from_strings( strings: List[str], index_of_source_string: int,\n",
    "    model='path-embedding-3-small' ) -> List[int]:\n",
    "    '''Return nearest neighbors of a given path.'''\n",
    "    # get vectors for all strings\n",
    "    embeddings = [ embedding_from_string( string, model=model ) for string in strings ]\n",
    "\n",
    "    # get the embedding of the source path\n",
    "    query_embedding = embeddings[ index_of_source_string ]\n",
    "    distances = distances_from_embeddings( query_embedding, embeddings, distance_metric='cosine' )\n",
    "\n",
    "    # get indices of nearest neighbors (function from embeddings_utils.py)\n",
    "    indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances( distances )\n",
    "    return indices_of_nearest_neighbors"
   ],
   "id": "3fa0e9699a613991"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Text Featurization\n",
    "- An embedding can be used as a general free-text feature encoder within a machine learning model.\n",
    "- Incorporating embeddings will improve the performance of any machine learning model, if some of the relevant inputs are free text.\n",
    "- An embedding can also be used as a categorical feature encoder within a ML model."
   ],
   "id": "bd79bebf3104d4fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "data = list( df.ada_embedding.target_values )\n",
    "X_train, X_test, y_train, y_test = train_test_split( data, df.Score, test_size=0.2, random_state=42 )\n"
   ],
   "id": "4773339d7f7e7e46"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### t-SNE",
   "id": "3b0e5fc29d77d02d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- The size of the embeddings varies with the complexity of the underlying model.\n",
    "\n",
    "- In order to visualize this high dimensional data we use the t-SNE algorithm to transform the data into two dimensions."
   ],
   "id": "9668f9854fff39ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "df = pd.read_csv('output/embedded_1k_reviews.csv')\n",
    "matrix = df.ada_embedding.apply(eval).to_list()\n",
    "\n",
    "# Create a t-SNE model and transform the data\n",
    "tsne = TSNE(n_components=2, perplexity=15, random_state=42, init='random', learning_rate=200)\n",
    "vis_dims = tsne.fit_transform(matrix)\n",
    "\n",
    "colors = ['red', 'darkorange', 'gold', 'turquiose', 'darkgreen']\n",
    "x = [x for x,y in vis_dims]\n",
    "y = [y for x,y in vis_dims]\n",
    "color_indices = df.Score.values - 1\n",
    "\n",
    "colormap = matplotlib.colors.ListedColormap(colors)\n",
    "plt.scatter(x, y, c=color_indices, cmap=colormap, alpha=0.3)\n",
    "plt.title('Amazon ratings visualized in language using t-SNE')"
   ],
   "id": "32fba7d071e3967c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Regressions",
   "id": "de66f7cc6b6956ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Embeddings present an elegant way of predicting a numerical value.\n",
    "\n",
    "- Because the semantic information contained within embeddings is high, the prediction is decent even with very few reviews.\n",
    "\n",
    "- We assume the score is a continuous variable between 1 and 5, and allow the algorithm to predict any floating point value.\n",
    "\n",
    "- The ML algorithm minimizes the distance of the predicted value to the true score, and achieves a mean absolute error of 0.39, which means that on average the prediction is off by less than half a star."
   ],
   "id": "6fafde0f4cf1f987"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=100)\n",
    "rfr.fit(X_train, y_train)\n",
    "preds = rfr.predict(X_test)"
   ],
   "id": "597e1fc26f24a533"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Classifications",
   "id": "8417c83780560baa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Instead of having the algorithm predict a value anywhere between 1 and 5, we will attempt to classify the exact number of stars for a review into 5 buckets, ranging from 1 to 5 stars.\n",
    "\n",
    "- After the training, the model learns to predict 1 and 5-star reviews much better than the more nuanced reviews (2-4 stars), likely due to more extreme sentiment expression."
   ],
   "id": "8813f93375784a1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)"
   ],
   "id": "4110f55c7284cf76"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Zero-Shot Classificiation",
   "id": "ff764363a1c254c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We can use embeddings for zero shot classification without any labeled training data.\n",
    "\n",
    "- For each class, we embed the class name or a short description of the class.\n",
    "\n",
    "- To classify some new text in a zero-shot manner, we compare its embedding to all class embeddings and predict the class with the highest similarity."
   ],
   "id": "bf4893351e189e59"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from openai.embeddings_utils import cosine_similarity, get_embedding\n",
    "\n",
    "df= df[df.Score!=3]\n",
    "df['sentiment'] = df.Score.replace({1:'negative', 2:'negative', 4:'positive', 5:'positive'})\n",
    "\n",
    "labels = ['negative', 'positive']\n",
    "label_embeddings = [get_embedding(label, model=model) for label in labels]\n",
    "\n",
    "def label_score(review_embedding, label_embeddings):\n",
    "    return cosine_similarity(review_embedding, label_embeddings[1]) - cosine_similarity(review_embedding, label_embeddings[0])\n",
    "\n",
    "prediction = 'positive' if label_score('Sample Review', label_embeddings) > 0 else 'negative'"
   ],
   "id": "f07a821db737f1b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Clustering",
   "id": "ae7db37ccd5b8930"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Embeddings are useful for this task, as they provide semantically meaningful vector representations of each text. Thus, in an unsupervised way, clustering will uncover hidden groupings in our dataset.\n",
    "\n",
    "- In this example, we discover four distinct clusters: one focusing on dog food, one on negative reviews, and two on positive reviews."
   ],
   "id": "7fe6edc404103097"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "matrix = np.vstack(df.ada_embedding.values)\n",
    "n_clusters = 4\n",
    "\n",
    "kmeans = KMeans(n_clusters = n_clusters, init='k-means++', random_state=42)\n",
    "kmeans.fit(matrix)\n",
    "df['Cluster'] = kmeans.labels_"
   ],
   "id": "f2bec4e3a4165611"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pincone Embeddings",
   "id": "ded48a744761bafe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Building the Knowledge Base",
   "id": "a841ca9cb72a7fce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = load_dataset( 'wikipedia', '20220301.simple', split='train[:10000]', trust_remote_code=True)\n",
    "data"
   ],
   "id": "f453aae304467363"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Every record contains *a lot* of text. Our first task is therefore to identify a good preprocessing methodology for chunking these articles into more 'concise' chunks to later be embedding and stored in our Pinecone vector database.\n",
    "\n",
    "- For this we use LangChain's `RecursiveCharacterTextSplitter` to split our text into chunks of a specified max length."
   ],
   "id": "a4169599f33ce42e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tiktoken.encoding_for_model( 'gpt-3.5-turbo' )\n",
    "tokenizer = tiktoken.get_encoding( 'cl100k_base' )"
   ],
   "id": "61aab25f6507d19b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create_small_embedding the min function\n",
    "def tiktoken_len( text ):\n",
    "    tokens = tokenizer.encode( text, disallowed_special=( ) )\n",
    "    return len( tokens )"
   ],
   "id": "5347f3f98ea0450b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tiktoken_len( 'hello I am a chunk of path and using the tiktoken_len function '\n",
    "             'we can find the min of this chunk of path in words' )"
   ],
   "id": "a2debe9224868fd0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=20,\n",
    "    length_function=tiktoken_len,\n",
    "    separators=['\\n\\n', '\\n', ' ', '']\n",
    ")"
   ],
   "id": "ce79e2cc7a4cd709"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "chunks = text_splitter.split_text( data[ 6 ][ 'path' ] )[ :3 ]\n",
    "chunks"
   ],
   "id": "5f41ceefe534bf24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tiktoken_len( chunks[ 0 ] ), tiktoken_len( chunks[ 1 ] ), tiktoken_len( chunks[ 2 ] )",
   "id": "38951a615eade238"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creating Embeddings",
   "id": "af76ada1a5f262"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get openai api key from platform.openai.com\n",
    "OPENAI_API_KEY = os.getenv( 'OPENAI_API_KEY' )\n",
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "embed = OpenAIEmbeddings( model=model_name, openai_api_key=OPENAI_API_KEY )\n",
    "texts = [ 'this is the first chunk of path',  'then another second chunk of path is here' ]\n",
    "\n",
    "res = embed.embed_documents( texts )\n",
    "len( res ), len( res[ 0 ] )"
   ],
   "id": "f4d9c963c1fad5ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Use Vector Database\n",
   "id": "f22b60aeb15e2471"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# initialize connection to pinecone\n",
    "api_key = os.getenv( 'PINECONE_API_KEY' )\n",
    "\n",
    "# configure client\n",
    "pc = Pinecone( api_key=api_key )"
   ],
   "id": "69360330d85a1cbf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Now we setup our index specification, this allows us to define the cloud provider and region where we want to deploy our index.",
   "id": "1d4e547d946666d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "spec = ServerlessSpec(  cloud='aws', region='us-east-1' )",
   "id": "b215c64dc5949d1e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Then we initialize the index. We will be using OpenAI's `text-embedding-ada-002` model for creating the embeddings, so we set the `dimension` to `1536`.",
   "id": "7302d11f2cc99a59"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "index_name = 'langchain-retrieval-augmentation'\n",
    "existing_indexes = [ index_info[ 'name' ] for index_info in pc.list_indexes( ) ]\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in existing_indexes:\n",
    "    # if does not exist, create_small_embedding index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=1536,\n",
    "        metric='dotproduct',\n",
    "        spec=spec\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index( index_name ).status[ 'ready' ]:\n",
    "        time.sleep( 1 )\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index( index_name )\n",
    "time.sleep( 1 )\n",
    "\n",
    "# view index stats\n",
    "index.describe_index_stats( )"
   ],
   "id": "a984b78d3d2235b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Indexing\n",
   "id": "76725c285ad5e204"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "batch_limit = 100\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "for i, record in enumerate( tqdm( data ) ):\n",
    "\n",
    "    # first get metadata columns for this record\n",
    "    metadata = {\n",
    "        'wiki-id': str(record['id']),\n",
    "        'source': record['url'],\n",
    "        'title': record['title']\n",
    "    }\n",
    "\n",
    "    # now we create_small_embedding chunks from the record path\n",
    "    record_texts = text_splitter.split_text(record['path'])\n",
    "\n",
    "    # create_small_embedding individual metadata dicts for each chunk\n",
    "    record_metadatas = [{\n",
    "        'chunk': j, 'path': text, **metadata\n",
    "    } for j, text in enumerate(record_texts)]\n",
    "\n",
    "    # append these to current batches\n",
    "    texts.extend(record_texts)\n",
    "    metadatas.extend(record_metadatas)\n",
    "\n",
    "    # if we have reached the batch_limit we can add words\n",
    "    if len(texts) >= batch_limit:\n",
    "        ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "        embeds = embed.embed_documents(texts)\n",
    "        index.upsert(vectors=zip(ids, embeds, metadatas))\n",
    "        texts = []\n",
    "        metadatas = []\n",
    "\n",
    "if len(texts) > 0:\n",
    "    ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "    embeds = embed.embed_documents(texts)\n",
    "    index.upsert(vectors=zip(ids, embeds, metadatas))"
   ],
   "id": "30760236256ac3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- We've now indexed everything. We can check the number of vectors in our index like so:",
   "id": "e6f020e2e3e75a48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "index.describe_index_stats( )",
   "id": "12a8e80e4e1850c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Creating and Querying a Vector Store\n",
    "\n",
    "- Now that we've build our index we can switch back over to LangChain. We start by initializing a vector store using the same index we just built. We do that like so:\n"
   ],
   "id": "b9f9e523094c0915"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# the metadata field that contains our path\n",
    "text_field = 'path'\n",
    "\n",
    "# initialize the vector store object\n",
    "vectorstore = Pinecone( index, embed.embed_query, text_field )\n",
    "query = 'who was Benito Mussolini?'\n",
    "\n",
    "vectorstore.similarity_search(\n",
    "\tquery,  # our search query\n",
    "\tk=3  # return 3 most relevant docs\n",
    ")"
   ],
   "id": "6ee34086ec495531"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generative Q & A\n",
    "\n",
    "- In GQA we take the query as a question that is to be answered by a LLM, but the LLM must answer the question based on the information it is seeing being returned from the `vectorstore`.\n",
    "- To do this we initialize a `RetrievalQA` object like so:"
   ],
   "id": "35f6a512171d5191"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# completion llm\n",
    "llm = ChatOpenAI( openai_api_key=OPENAI_API_KEY, model_name='gpt-3.5-turbo', temperature=0.0 )\n",
    "qa = RetrievalQA.from_chain_type( llm=llm, chain_type='stuff',\n",
    "\tretriever=vectorstore.as_retriever( ) )\n",
    "\n",
    "qa.run( query )"
   ],
   "id": "3b7e0e959d0b103f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " - We can do this using a slightly different version of `RetrievalQA` called `RetrievalQAWithSourcesChain`:",
   "id": "3928cd8fd77c565c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type( llm=llm, chain_type='stuff',\n",
    "    retriever=vectorstore.as_retriever( ) )\n",
    "\n",
    "qa_with_sources( query )"
   ],
   "id": "2dc5fe5faf94def9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Now we answer the question being asked, *and* return the source of this information being used by the LLM.\n",
    "- Delete index when complete"
   ],
   "id": "fa9479ee638964f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pc.delete_index( index_name )",
   "id": "57bb624446c07e63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Define Embedding Function",
   "id": "51eb7ff92bf29300"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def embed_texts( texts, model='text-embedding-3-small', batch_size=10, sleep=1 ):\n",
    "\t# Create Client\n",
    "\tclient = OpenAI( )\n",
    "\tclient.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\tembeddings = [ ]\n",
    "\tfor i in range( 0, len( texts ), batch_size ):\n",
    "\t\tbatch = texts[ i:i + batch_size ]\n",
    "\t\ttry:\n",
    "\t\t\tresponse = client.embeddings.create( input=batch, model=model )\n",
    "\t\t\tbatch_embeddings = [ e.embedding for e in response.data ]\n",
    "\t\t\tembeddings.extend( batch_embeddings )\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint( f'Error at batch {i}: {e}' )\n",
    "\t\t\t# Retry or sleep to avoid rate limits\n",
    "\t\t\ttime.sleep( sleep )\n",
    "\t\t\tcontinue\n",
    "\treturn embeddings"
   ],
   "id": "da73e5be4dc7dd3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. Embed Chunks",
   "id": "e5b7bcd6dd3902f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "embeddings = embed_texts( chunks )",
   "id": "9348ebd98a9c3507"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "####  3. Create DataFrame",
   "id": "6101a8334f1e2329"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_embeddings = pd.DataFrame( { chunks, embeddings } )",
   "id": "91adef5a83231057"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4. Save To Vector Store",
   "id": "bed88c5c91432c1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_embeddings.to_parquet( 'public_law_118_32_embeddings.parquet', index=False )",
   "id": "4c190d7c9dcd8df8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5. Preview",
   "id": "fcd1d7a8ec75c9ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_embeddings.head( 2 )",
   "id": "13a19772c6d9d267"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##  Hugginface Embeddings\n",
    "- Use a language model (e.g., OpenAI, HuggingFace) to create vector representations of each chunk_words."
   ],
   "id": "7ddb05f69f495373"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sentence Embeddings",
   "id": "f727bb67dd88af27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 1. Path Definitions",
   "id": "a2e207452b927d0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "TEXT_FILE = 'PublicLaw_118-42.txt'\n",
    "DB_FILE = 'law_embeddings.target_values'\n",
    "EMBEDDING_MODEL = 'all-MiniLM-L6-v2'\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200"
   ],
   "id": "23fdaf60787b467c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### 2. Use Sentence Transformer\n",
    "- Embed chunks from above using sentence transformer"
   ],
   "id": "8fc49a8e385c2545"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = SentenceTransformer( 'all-MiniLM-L6-v2' )\n",
    "embeddings = model.encode( chunks, show_progress_bar=True )"
   ],
   "id": "a5065bf499134f63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### 3. Embed Sentence\n",
    "- Function Definition"
   ],
   "id": "4adda4f1be750a2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def embed_with_sentence_transformers( texts, model ):\n",
    "\treturn model.encode( texts, show_progress_bar=True, convert_to_numpy=True )"
   ],
   "id": "54cc79b86cd6a19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "local_embeddings = embed_with_sentence_transformers( chunks, model )",
   "id": "eb38674370746625"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 4. Save in a DataFrame",
   "id": "db654335853f65cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_local = pd.DataFrame(\n",
    "{\n",
    "\t'chunk_words': chunks,\n",
    "\t'embedding': list( local_embeddings )\n",
    "} )"
   ],
   "id": "a67fb6579159135"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 5. Create SQLite DB",
   "id": "e2e6a482d92a459"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "conn = sqlite3.connect( 'vectors.target_values' )\n",
    "cursor = conn.cursor( )\n",
    "sql_create = '''\n",
    "CREATE TABLE IF NOT EXISTS Law_Embeddings\n",
    "(\n",
    "    Id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Chunk_Tokens TEXT NOT NULL,\n",
    "    Embedding BLOB NOT NULL\n",
    ")\n",
    "'''\n",
    "\n",
    "cursor.execute( sql_create )\n",
    "\n",
    "for chunk, vector in zip( chunks, embeddings ):\n",
    "\tblob = pickle.dumps( vector )\n",
    "\tcursor.execute( 'INSERT INTO Law_Embeddings ( Chunk_Tokens, Embedding ) VALUES (?, ?)',\n",
    "\t\t(chunk, blob) )\n",
    "\n",
    "conn.commit( )\n",
    "conn.close( )"
   ],
   "id": "ddb630773045eb30"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 5. OpenAI Client",
   "id": "5771680a9f5509d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )"
   ],
   "id": "6b4a498330aec36a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### 6. Get Embedding\n",
    "- Function Definition"
   ],
   "id": "fb57feb283248a25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_embedding( text, model=OPENAI_MODEL ):\n",
    "\tresponse = client.Embedding.generate_text( input=text, model=model )\n",
    "\treturn response[ 'target_values'[ 0 ][ 'embedding' ] ]"
   ],
   "id": "c11b835cb5507a7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### 7. Embed Chunks\n",
    "- Function Definition"
   ],
   "id": "aa852dd9a6b96a93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def embed_chunks( chunks ):\n",
    "\tembeddings = [ ]\n",
    "\tfor chunk in tqdm( chunks, desc='EmbeddingRequest chunks via OpenAI' ):\n",
    "\t\ttry:\n",
    "\t\t\tembedding = get_embedding( chunk )\n",
    "\t\t\tembeddings.append( embedding )\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint( f'Error embedding chunk_words: {e}' )\n",
    "\t\t\tembeddings.append( [ 0.0 ] * 1536 )  # Placeholder for failed requests\n",
    "\treturn embeddings\n"
   ],
   "id": "947d623c8ddd5e01"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### 8. Create SQLite DB\n",
    "- Function Definition"
   ],
   "id": "bb547c630b6afe55"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_sqlite_db( chunks, embeddings, db_path ):\n",
    "\tconn = sqlite3.connect( db_path )\n",
    "\tcursor = conn.cursor( )\n",
    "\tsql_create = '''\n",
    "    CREATE TABLE IF NOT EXISTS Law_Embeddings\n",
    "    (\n",
    "        Id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        Chunk_Tokens TEXT NOT NULL,\n",
    "        Embedding BLOB NOT NULL\n",
    "    )\n",
    "    '''\n",
    "\n",
    "\tcursor.execute( sql_create )\n",
    "\tfor chunk, vector in zip( chunks, embeddings ):\n",
    "\t\tblob = pickle.dumps( vector )\n",
    "\t\tsql_insert = 'INSERT INTO Law_Embeddings ( Chunk_Tokens, Embedding ) VALUES ( ?, ? )'\n",
    "\t\tcursor.execute( sql_insert, (chunk, blob) )\n",
    "\n",
    "\tconn.commit( )\n",
    "\tconn.close( )"
   ],
   "id": "6888774ee7526322"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Final Script Example",
   "id": "91a850a970398c45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === MAIN ===\n",
    "def main( ):\n",
    "\tprint( 'Step 1: Load and clean documents' )\n",
    "\tcleaned_text = load_and_clean_text( TEXT_FILE )\n",
    "\n",
    "\tprint( 'Step 2: Chunking documents' )\n",
    "\tchunks = chunk_text( cleaned_text )\n",
    "\tprint( f'Total chunks: {len( chunks )}' )\n",
    "\n",
    "\tprint( 'Step 3: EmbeddingRequest with OpenAI API' )\n",
    "\tembeddings = embed_chunks( chunks )\n",
    "\n",
    "\tprint( 'Step 4: Saving to SQLite' )\n",
    "\tcreate_sqlite_db( chunks, embeddings, DB_FILE )\n",
    "\n",
    "\tprint( f'Pipeline complete. Embeddings stored in: {DB_FILE}' )"
   ],
   "id": "270c22020ca8fa3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Embedding Wikipedia articles for search\n",
    "##### Procedure:\n",
    "\n",
    "-  Import libraries, set API key (if needed)\n",
    "-  Collect: We download a few hundred Wikipedia articles about the 2022 Olympics\n",
    "-  Chunk: Documents are split into short, semi-self-contained sections to be embedded\n",
    "-  Embed: Each section is embedded with the OpenAI API\n",
    "-  Store: Embeddings are saved in a CSV file (for large datasets, use a vector database)"
   ],
   "id": "2d9a327090eea610"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 1. Collect documents\n",
    "- In this example, we'll download a few hundred Wikipedia articles related to the 2022 Winter Olympics."
   ],
   "id": "654daf8b357e7fba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "CATEGORY_TITLE = 'Category:2022 Winter Olympics'\n",
    "WIKI_SITE = 'en.wikipedia.org'\n",
    "\n",
    "\n",
    "def titles_from_category( category: mwclient.listing.Category, max_depth: int ) -> set[ str ]:\n",
    "\t'''\n",
    "\n",
    "\t\tReturn a pairs of page titles in a given Wiki category and its subcategories.\n",
    "\n",
    "\t'''\n",
    "\ttitles = set( )\n",
    "\tfor cm in category.members( ):\n",
    "\t\tif type( cm ) == mwclient.page.Page:\n",
    "\t\t\t# ^scaler() used instead of isinstance() to catch match w/ no inheritance\n",
    "\t\t\ttitles.add( cm.name )\n",
    "\t\telif isinstance( cm, mwclient.listing.Category ) and max_depth > 0:\n",
    "\t\t\tdeeper_titles = titles_from_category( cm, max_depth=max_depth - 1 )\n",
    "\t\t\ttitles.update( deeper_titles )\n",
    "\treturn titles\n",
    "\n",
    "\n",
    "site = mwclient.Site( WIKI_SITE )\n",
    "category_page = site.pages[ CATEGORY_TITLE ]\n",
    "titles = titles_from_category( category_page, max_depth=1 )\n",
    "# ^note: max_depth=1 means we go one level deep in the category tree\n",
    "print( f'Found {len( titles )} article titles in {CATEGORY_TITLE}.' )"
   ],
   "id": "7b14fad95821b8f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2. Document Prep & Definitions\n",
    "\n",
    "##### Now that we have our reference documents, we need to prepare them for search. Because GPT can only read a limited amount of text at once, we'll split each document into chunks short enough to be read. For this specific example on Wikipedia articles, we'll:\n",
    "- Discard less relevant-looking sections like External Links and Footnotes\n",
    "- Clean up the text by removing reference tags (e.g., <ref>), whitespace, and super short sections\n",
    "- Split each article into sections\n",
    "- Prepend titles and subtitles to each section's text, to help GPT understand the context\n",
    "- If a section is long (say, > 1,600 tokens), we'll recursively split it into smaller sections, trying to split along semantic boundaries like paragraphs"
   ],
   "id": "6289f51ef185f65e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# define functions to split Wikipedia pages into sections\n",
    "\n",
    "SECTIONS_TO_IGNORE = [\n",
    "\t'See also',\n",
    "\t'References',\n",
    "\t'External links',\n",
    "\t'Further reading',\n",
    "\t'Footnotes',\n",
    "\t'Bibliography',\n",
    "\t'Sources',\n",
    "\t'Citations',\n",
    "\t'Literature',\n",
    "\t'Footnotes',\n",
    "\t'Notes and references',\n",
    "\t'Photo gallery',\n",
    "\t'Works cited',\n",
    "\t'Photos',\n",
    "\t'Gallery',\n",
    "\t'Notes',\n",
    "\t'References and sources',\n",
    "\t'References and notes',\n",
    "]\n",
    "\n",
    "\n",
    "def all_subsections_from_section( section: mwparserfromhell.wikicode.Wikicode,\n",
    "\tparent_titles: list[ str ],\n",
    "\tsections_to_ignore: set[ str ] ) -> list[ tuple[ list[ str ], str ] ]:\n",
    "\t'''\n",
    "\n",
    "        From a Wikipedia section, return a flattened list of all nested subsections.\n",
    "        Each subsection is a tuple, where:\n",
    "            - the first element is a list of parent subtitles, starting with the page title\n",
    "            - the second element is the pages of the subsection (but not any children)\n",
    "\n",
    "    '''\n",
    "\theadings = [ str( h ) for h in section.filter_headings( ) ]\n",
    "\ttitle = headings[ 0 ]\n",
    "\tif title.strip( '=' + ' ' ) in sections_to_ignore:\n",
    "\t\t# ^wiki headings are wrapped like '== Heading =='\n",
    "\t\treturn [ ]\n",
    "\ttitles = parent_titles + [ title ]\n",
    "\tfull_text = str( section )\n",
    "\tsection_text = full_text.split( title )[ 1 ]\n",
    "\tif len( headings ) == 1:\n",
    "\t\treturn [ (titles, section_text) ]\n",
    "\telse:\n",
    "\t\tfirst_subtitle = headings[ 1 ]\n",
    "\t\tsection_text = section_text.split( first_subtitle )[ 0 ]\n",
    "\t\tresults = [ (titles, section_text) ]\n",
    "\t\tfor subsection in section.get_sections( levels=[ len( titles ) + 1 ] ):\n",
    "\t\t\tresults.extend( all_subsections_from_section( subsection, titles, sections_to_ignore ) )\n",
    "\t\treturn results\n",
    "\n",
    "\n",
    "def all_subsections_from_title( title: str,\n",
    "\tsections_to_ignore: set[ str ]=SECTIONS_TO_IGNORE,\n",
    "\tsite_name: str=WIKI_SITE ) -> list[ tuple[ list[ str ], str ] ]:\n",
    "\t'''\n",
    "\n",
    "        From a Wikipedia page title, return a flattened list of all nested subsections.\n",
    "        Each subsection is a tuple, where:\n",
    "            - the first element is a list of parent subtitles, starting with the page title\n",
    "            - the second element is the pages of the subsection (but not any children)\n",
    "\n",
    "    '''\n",
    "\tsite = mwclient.Site( site_name )\n",
    "\tpage = site.pages[ title ]\n",
    "\ttext = page.text( )\n",
    "\tparsed_text = mwparserfromhell.parse( text )\n",
    "\theadings = [ str( h ) for h in parsed_text.filter_headings( ) ]\n",
    "\tif headings:\n",
    "\t\tsummary_text = str( parsed_text ).split( headings[ 0 ] )[ 0 ]\n",
    "\telse:\n",
    "\t\tsummary_text = str( parsed_text )\n",
    "\tresults = [ ([ title ], summary_text) ]\n",
    "\tfor subsection in parsed_text.get_sections( levels=[ 2 ] ):\n",
    "\t\tresults.extend( all_subsections_from_section( subsection, [ title ], sections_to_ignore ) )\n",
    "\treturn results\n"
   ],
   "id": "52ea658099615029"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 3. Split pages into sections\n",
    "- may take ~1 minute per 100 articles"
   ],
   "id": "8f11b914415693e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "wikipedia_sections = [ ]\n",
    "for title in titles:\n",
    "\twikipedia_sections.extend( all_subsections_from_title( title ) )\n",
    "print( f'Found {len( wikipedia_sections )} sections in {len( titles )} pages.' )"
   ],
   "id": "133406944e17e981"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4. Clean pages",
   "id": "96905fc45df8e87a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# clean pages\n",
    "def clean_section( section: tuple[ list[ str ], str ] ) -> tuple[ list[ str ], str ]:\n",
    "\t'''\n",
    "\n",
    "        Return a cleaned_lines up section with:\n",
    "            - <ref>xyz</ref> patterns removed\n",
    "            - leading/trailing whitespace removed\n",
    "\n",
    "    '''\n",
    "\ttitles, text = section\n",
    "\ttext = re.sub( r'<ref.*?</ref>', '', text )\n",
    "\ttext = text.strip( )\n",
    "\treturn (titles, text)\n",
    "\n",
    "wikipedia_sections = [ clean_section( ws ) for ws in wikipedia_sections ]\n",
    "\n"
   ],
   "id": "24657f5793a245b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5. Filter-out blank sections",
   "id": "2587197f65f18c74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# filter out short/blank sections\n",
    "def keep_section( section: tuple[ list[ str ], str ] ) -> bool:\n",
    "\t'''\n",
    "\n",
    "        Return True if the section should be kept, False otherwise.\n",
    "\n",
    "    '''\n",
    "\ttitles, text = section\n",
    "\tif len( text ) < 16:\n",
    "\t\treturn False\n",
    "\telse:\n",
    "\t\treturn True\n",
    "\n",
    "original_num_sections = len( wikipedia_sections )\n",
    "wikipedia_sections = [ ws for ws in wikipedia_sections if keep_section( ws ) ]\n",
    "print(\n",
    "\tf'Filtered out {original_num_sections - len( wikipedia_sections )} sections, leaving {len( wikipedia_sections )} sections.' )\n",
    "\n",
    "\n",
    "for ws in wikipedia_sections[ :5 ]:\n",
    "\tprint( ws[ 0 ] )\n",
    "\tdisplay( ws[ 1 ][ :77 ] + '...' )\n",
    "\tprint( )"
   ],
   "id": "a285d2b14b956e0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 6. Recursively split long sections\n",
    "##### Tradeoffs include:\n",
    "- Longer sections may be better for questions that require more context\n",
    "- Longer sections may be worse for retrieval, as they may have more topics muddled together\n",
    "- Shorter sections are better for reducing costs (which are proportional to the number of tokens)\n",
    "- Shorter sections allow more sections to be retrieved, which may help with recall\n",
    "- Overlapping sections may help prevent answers from being cut by section boundaries"
   ],
   "id": "24d735005a5bbd83"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " We limit sections to 1,600 tokens each, recursively halving any sections that are too long. To avoid cutting in the middle of useful sentences, we'll split along paragraph boundaries when possible.",
   "id": "d392fa7e905f534f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "GPT_MODEL = 'gpt-4o-mini'\n",
    "\n",
    "\n",
    "def num_tokens( text: str, modeal: str = GPT_MODEL ) -> int:\n",
    "\t'''Return the num of words in a path.'''\n",
    "\tencoding = tiktoken.encoding_for_model( model )\n",
    "\treturn len( encoding.encode( text ) )\n",
    "\n",
    "\n",
    "def halved_by_delimiter( string: str, delimiter: str = '\\n' ) -> list[ str, str ]:\n",
    "\t'''\n",
    "\n",
    "\t\tSplit a path in two, on a delimiter, trying to balance words on each side.\n",
    "\n",
    "\t'''\n",
    "\tchunks = string.split( delimiter )\n",
    "\tif len( chunks ) == 1:\n",
    "\t\treturn [ string, '' ]  # no delimiter found\n",
    "\telif len( chunks ) == 2:\n",
    "\t\treturn chunks  # no need to search for halfway point\n",
    "\telse:\n",
    "\t\ttotal_tokens = num_tokens( string )\n",
    "\t\thalfway = total_tokens // 2\n",
    "\t\tbest_diff = halfway\n",
    "\t\tfor i, chunk in enumerate( chunks ):\n",
    "\t\t\tleft = delimiter.join( chunks[ : i + 1 ] )\n",
    "\t\t\tleft_tokens = num_tokens( left )\n",
    "\t\t\tdiff = abs( halfway - left_tokens )\n",
    "\t\t\tif diff >= best_diff:\n",
    "\t\t\t\tbreak\n",
    "\t\t\telse:\n",
    "\t\t\t\tbest_diff = diff\n",
    "\t\tleft = delimiter.join( chunks[ :i ] )\n",
    "\t\tright = delimiter.join( chunks[ i: ] )\n",
    "\t\treturn [ left, right ]\n",
    "\n",
    "\n",
    "def truncated_string( string: str, model: str, max_tokens: int, print_warning: bool=True ) -> str:\n",
    "\t'''\n",
    "\n",
    "\t\tTruncate a path to a maximum num of words.\n",
    "\n",
    "\t'''\n",
    "\tencoding = tiktoken.encoding_for_model( model )\n",
    "\tencoded_string = encoding.encode( string )\n",
    "\ttruncated_string = encoding.decode( encoded_string[ :max_tokens ] )\n",
    "\tif print_warning and len( encoded_string ) > max_tokens:\n",
    "\t\tprint(\n",
    "\t\t\tf'Warning: Truncated path from {len( encoded_string )} words to {max_tokens} words.' )\n",
    "\treturn truncated_string\n",
    "\n",
    "\n",
    "def split_strings_from_subsection( subsection: tuple[ list[ str ], str ],\n",
    "\tmodel: str = GPT_MODEL,\n",
    "\tmax: int=5 ) -> list[ str ]:\n",
    "\t'''\n",
    "\n",
    "        Split a subsection into a list of subsections, each with no more than max_tokens.\n",
    "        Each subsection is a tuple of parent titles [H1, H2, ...] and pages (str).\n",
    "\n",
    "    '''\n",
    "\ttitles, text = subsection\n",
    "\tstring = '\\n\\n'.join( titles + [ text ] )\n",
    "\tnum_tokens_in_string=num_tokens( string )\n",
    "\t# if min is fine, return path\n",
    "\tif num_tokens_in_string <= 10000:\n",
    "\t\treturn [ string ]\n",
    "\t# if recursion hasn't found a split after X iterations, just trunc\n",
    "\telif max == 0:\n",
    "\t\treturn [ truncated_string( string, model=model, max_tokens=10000 ) ]\n",
    "\t# otherwise, split in half and recurse\n",
    "\telse:\n",
    "\t\ttitles, text = subsection\n",
    "\t\tfor delimiter in [ '\\n\\n', '\\n', '. ' ]:\n",
    "\t\t\tleft, right = halved_by_delimiter( text, delimiter=delimiter )\n",
    "\t\t\tif left == '' or right == '':\n",
    "\t\t\t\t# if either half is empty, retry with a more fine-grained delimiter\n",
    "\t\t\t\tcontinue\n",
    "\t\t\telse:\n",
    "\t\t\t\t# recurse on each half\n",
    "\t\t\t\tresults = [ ]\n",
    "\t\t\t\tfor half in [ left, right ]:\n",
    "\t\t\t\t\thalf_subsection = (titles, half)\n",
    "\t\t\t\t\thalf_strings = split_strings_from_subsection(\n",
    "\t\t\t\t\t\thalf_subsection,\n",
    "\t\t\t\t\t\tmodel=model,\n",
    "\t\t\t\t\t\tmax = max - 1,\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\t\tresults.extend( half_strings )\n",
    "\t\t\t\treturn results\n",
    "\t# otherwise no split was found, so just trunc (should be very rare)\n",
    "\treturn [ truncated_string( string, model=model, max_tokens=10000 ) ]\n"
   ],
   "id": "940b0533cbd1194c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 7. Split Sections into Chunks",
   "id": "429464465d85877d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# split sections into chunks\n",
    "wikipedia_strings = [ ]\n",
    "for section in wikipedia_sections:\n",
    "\twikipedia_strings.extend( split_strings_from_subsection( section ) )\n",
    "\n",
    "print(\n",
    "\tf'{len( wikipedia_sections )} Wikipedia sections split into {len( wikipedia_strings )} strings.' )\n",
    "\n",
    "# print example df\n",
    "print( wikipedia_strings[ 1 ] )"
   ],
   "id": "7cf3ccdc0954bed1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 8. Embed document chunks",
   "id": "3676f9a6d1bc443b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "EMBEDDING_MODEL = 'path-embedding-3-small'\n",
    "BATCH_SIZE = 1000  # you can submit up to 2048 embedding inputs per request\n",
    "\n",
    "embeddings = [ ]\n",
    "for batch_start in range( 0, len( wikipedia_strings ), BATCH_SIZE ):\n",
    "\tbatch_end = batch_start + BATCH_SIZE\n",
    "\tbatch = wikipedia_strings[ batch_start:batch_end ]\n",
    "\tprint( f'Batch {batch_start} to {batch_end - 1}' )\n",
    "\tresponse = client.embeddings.create( model=EMBEDDING_MODEL, input=batch )\n",
    "\tfor i, be in enumerate( response.data ):\n",
    "\t\tassert i == be.index  # double check vectors are in same order as path\n",
    "\tbatch_embeddings = [ e.embedding for e in response.data ]\n",
    "\tembeddings.extend( batch_embeddings )\n",
    "\n",
    "df = pd.DataFrame( { 'pages': wikipedia_strings, 'embedding': embeddings } )"
   ],
   "id": "463ccd1620e1bc71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 9. Store document chunks and embeddings",
   "id": "f3ac9f168c4d58b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# save document chunks and vectors\n",
    "\n",
    "SAVE_PATH = 'stores/winter_olympics_2022.csv'\n",
    "\n",
    "df.to_csv( SAVE_PATH, index=False )"
   ],
   "id": "e237b1d0e4774a89"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Q-&-A with Completions\n",
    "- There are many common cases where the model is not trained on data which contains key facts and information you want to make accessible when generating responses to a user query.\n",
    "- One way of solving this, as shown below, is to put additional information into the context window of the model.\n",
    "- This is effective in many use cases but leads to higher token costs."
   ],
   "id": "88c2c1f6692b368c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Query\n",
    "query = f'''\n",
    "\n",
    "\tUse the below article on the 2022 Winter Olympics to answer the subsequent prompt.\n",
    "\tIf the answer cannot be found, write 'I don't know.'\n",
    "\n",
    "\tArticle:\n",
    "\t\\'\\'\\'\n",
    "\t{wikipedia_article_on_curling}\n",
    "\t\\'\\'\\'\n",
    "\n",
    "\tQuestion: Which athletes won the gold medal in curling at the 2022 Winter Olympics?\n",
    "\n",
    "'''\n",
    "\n",
    "# Create Completion\n",
    "response = client.chat.completions.create(\n",
    "    messages= [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': system_instructions\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': user_propmt\n",
    "    }, ],\n",
    "    model=GPT_MODEL,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print( response.choices[0].message.content )"
   ],
   "id": "d1c8a5d317d3cdb5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "___\n",
    "\n",
    "# Files API\n",
    "\n",
    "- Upload up to 100 pages and 32MB of total content in a single request to the API, across multiple file inputs.\n",
    "\n",
    "- Only models that support both text and image inputs, such as gpt-4o, gpt-4o-mini, or o1, can accept PDF files as input\n",
    "\n",
    "- Recommend using the user_data purpose for files you plan to use as model inputs.\n"
   ],
   "id": "e3fde16f4a5c82b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Upload\n",
   "id": "72eab7cef4735604"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.files.create( file=open( 'mydata.jsonl', 'rb' ), purpose='fine-tune' )"
   ],
   "id": "9e52a8aca5a53d62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### List",
   "id": "472bf604087b790d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "_files = client.files.list( purpose='assistants' )\n",
    "\n"
   ],
   "id": "6b8d7344b47cd3df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Retreive File",
   "id": "b4c2ed04a2bc01c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T20:06:56.163718Z",
     "start_time": "2025-05-21T20:06:54.746193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Reteive by file_id\n",
    "retrieval = client.files.retrieve( 'file-FoVMTC8aQcUNddJP3PBx56' )\n",
    "retrieval.filename\n"
   ],
   "id": "6496c6c7c3e9ccee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Principles Of Federal Appropriations Law Volume Two.pdf'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Reteive Contents",
   "id": "7be1b80ac4fb5e35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "content = client.files.content( 'file-abc123' )\n"
   ],
   "id": "92a1e381d4544632"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Upload",
   "id": "7da07ee006a42a88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.files.create( file=open( 'mydata.jsonl', 'rb' ), purpose='fine-tune' )\n"
   ],
   "id": "517bc315b104e524"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Delete File",
   "id": "2fc4b4f5b2fb4fb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "client.files.delete( 'file-NRMEksB9kYp1ZG7fbPuKpv7O' )"
   ],
   "id": "760a8cb912f18b7f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Retreival API\n",
    "- The Retrieval API allows you to perform semantic search over your data, which is a technique that surfaces semantically similar results â€” even when they match few or no keywords.\n",
    "\n",
    "- The Retrieval API is powered by vector stores, which serve as indices for your data.\n"
   ],
   "id": "cc9fa669a5111492"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Vector Store",
   "id": "81570e1ee566cd92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "vector_store = client.vector_stores.create( name='Support FAQ' )\n",
    "client.vector_stores.files.upload_and_poll(  vector_store_id=vector_store.id, file=open( 'customer_policies.txt', 'rb' ) )"
   ],
   "id": "8c824cffccbe5b62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "####   Search Stores",
   "id": "451d8d683694f0e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "user_query = 'What is the return policy?'\n",
    "results = client.vector_stores.search( vector_store_id=vector_store.id, query=user_query, )"
   ],
   "id": "3a81b00e60f48361"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Semantic Search",
   "id": "27716316afa8ae53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "results = client.vector_stores.search( vector_store_id=vector_store.id,\n",
    "    query='How many woodchucks are allowed per passenger?', )"
   ],
   "id": "6ce6e5f5d2cc3978"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Langchain RAG",
   "id": "b6438fb028692feb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Retreival Augmentation\n",
    "\n",
    "- Pincone & LangChain\n",
    "\n",
    "- You take the query as a question that is to be answered by a LLM, but the LLM must answer the question based on the information it is seeing from the vectorstore."
   ],
   "id": "2a60f495b23976e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Initialize a `RetrievalQA` object\n",
    "\n"
   ],
   "id": "fba347344db6ece6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# completion llm\n",
    "llm = ChatOpenAI( openai_api_key=OPENAI_API_KEY, model_name='gpt-3.5-turbo', temperature=0.0 )\n",
    "qa = RetrievalQA.from_chain_type( llm=llm, chain_type='stuff', retriever=vectorstore.as_retriever( ) )\n",
    "qa.invoke( query )\n"
   ],
   "id": "1b8c949602489fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Or use `RetrievalQAWithSourcesChain`",
   "id": "ab4d528d917f69cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "qa_with_sources.invoke(query)\n",
    "\n",
    "# Response:\n",
    "# {'prompt': 'who was Benito Mussolini?',\n",
    "# 'answer': \"Benito Mussolini was an Italian politician and journalist who served as the Prime Minister of Italy from 1922 until 1943.\n",
    "# He was the leader of the National Fascist Party and played a significant role in the rise of fascism in Italy...\",\n",
    "# 'sources': 'https://simple.wikipedia.org/wiki/Benito%20Mussolini'}"
   ],
   "id": "72604f0a94db3c2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3. Clean-up\n",
    "- When you no longer need the index, use the `delete_index` operation to delete it"
   ],
   "id": "1c66e27b4cbf4782"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "qa.delete_index( name=index_name )",
   "id": "60dfa58e09ffdf4c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Vector Store API\n",
    "- Vector stores are the containers that power semantic search for the Retrieval API and the Assistants API file search tool.\n",
    "\n",
    "- When you add a file to a vector store it will be automatically chunked, embedded, and indexed.\n"
   ],
   "id": "564d4b602fe2ef91"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Definitions\n",
    "\n",
    "- `File`: Represents content uploaded through the Files API. Often used with vector stores, but also for fine-tuning and other use cases.\n",
    "\n",
    "- `vector_store`: Container for searchable files.\n",
    "\n",
    "- `vector_store.file`: Wrapper type specifically representing a file that has been chunked and embedded, and has been associated with a vector_store.\n"
   ],
   "id": "c32f0af5f0c45d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### I. Vector Store Operations",
   "id": "fb964cc0c0a36628"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Create",
   "id": "97521b55fc1f0625"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create vector store\n",
    "client.vector_stores.create( name='Support FAQ', file_ids=[ 'file_123' ] )"
   ],
   "id": "e17fac7bd5d6999f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Retrieve",
   "id": "d90fa1d06cf2d67b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Retreive vector store\n",
    "client.vector_stores.retrieve( vector_store_id='vs_123' )"
   ],
   "id": "d5ac511a0ee074a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Update",
   "id": "1d8e79e081421fe7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Update vector store\n",
    "client.vector_stores.retrieve( vector_store_id='vs_123' )"
   ],
   "id": "8353143e91fdc157"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Delete",
   "id": "88302805929453c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Delete vector store\n",
    "client.vector_stores.delete( vector_store_id='vs_123' )"
   ],
   "id": "f9020eb5ea907162"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### List",
   "id": "6ae83c9daf0a89bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List vectorstores\n",
    "client.vector_stores.list( )"
   ],
   "id": "e90ce2619c5dc151"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### II. Vector File Operations",
   "id": "a11aaecf8c694f3a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Create File",
   "id": "1e7701e63313311e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create files for vector store\n",
    "client.vector_stores.files.create( vector_store_id='vs_123',\n",
    "    file_id='file_123',\n",
    "    attributes=\n",
    "    {\n",
    "        'region': 'US',\n",
    "        'category': 'Marketing',\n",
    "        'date': 1672531200\n",
    "    }\n",
    ")"
   ],
   "id": "8417ac24062d8b2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Upload File",
   "id": "5ad92c8d67fa907c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.files.upload_and_poll( vector_store_id='vs_123',\n",
    "    file=open( 'customer_policies.txt', 'rb' ) )"
   ],
   "id": "f2fa2da1c6644b93"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Retreive File",
   "id": "9d4ccfd66ca8e438"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "client.vector_stores.files.retrieve( vector_store_id='vs_123', file_id='file_123' )\n"
   ],
   "id": "f395931f01ab0b69"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Update File",
   "id": "6c0b68210f82332c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Update file\n",
    "client.vector_stores.files.update( vector_store_id='vs_123', file_id='file_123',\n",
    "    attributes=\n",
    "    {\n",
    "\t    'key': 'value'\n",
    "    }\n",
    ")\n"
   ],
   "id": "bed01979a830b021"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Delete File",
   "id": "3fe27377daae7ab2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Delete file\n",
    "client.vector_stores.files.delete( vector_store_id='vs_123', file_id='file_123' )\n"
   ],
   "id": "d81dd18aebc57ff5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### List Files",
   "id": "afcb3de796b75483"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List files\n",
    "client.vector_stores.files.list( vector_store_id='vs_123' )"
   ],
   "id": "dbfaa44ec54f7e7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Limits\n",
    "- The maximum file size is 512 MB. Each file should contain no more than 5,000,000 tokens per file (computed automatically when you attach a file)."
   ],
   "id": "4feae16d6d54cbce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Chunking\n",
    "\n",
    "- By default, `max_chunk_size_tokens` is set to 800 and `chunk_overlap_tokens` is set to 400.\n",
    "\n",
    "- Every file is indexed by being split up into 800-token chunks, with 400-token overlap between consecutive chunks.\n",
    "\n",
    "- `max_chunk_size_tokens` must be between 100 and 4096 inclusive.\n",
    "\n",
    "- 'chunk_overlap_tokens' must be non-negative and should not exceed max_chunk_size_tokens / 2."
   ],
   "id": "a57685a68c7feb2d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tools API\n",
    "\n",
    "- File Search augments the Assistant with knowledge from outside its model\n",
    "\n",
    "- Code Interpreter allows Assistants to write and run Python code in a sandboxed execution environment\n",
    "\n",
    "- Function calling allows you to describe functions to the Assistants API then call them\n"
   ],
   "id": "f1e930763685aba0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Completions",
   "id": "d7623d24781dcb90"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Get Weather\n",
    "- ( Open-Meteo )"
   ],
   "id": "8ffc08fed9eb41d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Define function\n",
   "id": "17cda2d66c50c67a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_weather( latitude, longitude ):\n",
    "    response = requests.get( f'https://api.open-meteo.com/v1/forecast?latitude={ latitude }&longitude={ longitude }&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m' )\n",
    "    data = response.json( )\n",
    "    return data[ 'current' ][ 'temperature_2m' ]"
   ],
   "id": "8371554cf0720410"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        'text': 'function',\n",
    "        'function':\n",
    "        {\n",
    "            'name': 'get_weather',\n",
    "            'description': 'Gets the current weather for a given location',\n",
    "            'parameters':\n",
    "            {\n",
    "                'text': 'object',\n",
    "                'properties':\n",
    "                {\n",
    "                    'location':\n",
    "                    {\n",
    "                        'text': 'path',\n",
    "                        'description': 'The city and state, e.g., San Francisco, CA',\n",
    "                    },\n",
    "                    'unit':\n",
    "                    {\n",
    "                        'text': 'path',\n",
    "                        'enum': [ 'celsius', 'fahrenheit' ]\n",
    "                    }\n",
    "                },\n",
    "\n",
    "                'required': [ 'location' ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create( model='gpt-4o',\n",
    "\tmessages=[ { 'role': 'user', 'content': 'What is the weather like in Paris today?' } ],\n",
    "\ttools=tools )\n",
    "\n",
    "print( completion.choices[ 0 ].message.tool_calls )"
   ],
   "id": "e5949de4dd12fe45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Get Forecast\n",
    "- ( Open Weather API )"
   ],
   "id": "3b642fab2188553e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Step 1 - Define the local function",
   "id": "7a35d47d4922cfc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "OPENAI_API_KEY = os.getenv( \"OPENAI_API_KEY\" )\n",
    "WEATHER_API_KEY = os.getenv( \"WEATHER_API_KEY\" )  # from https://www.weatherapi.com/\n",
    "client = OpenAI( api_key = OPENAI_API_KEY )\n",
    "\n",
    "\n",
    "def get_weather( location: str, unit: str = \"fahrenheit\" ) -> dict:\n",
    "\t\"\"\"\n",
    "\n",
    "        Purpose:\n",
    "            Fetch current weather for a given location from WeatherAPI.\n",
    "\n",
    "        Parameters:\n",
    "            location (str): City or region.\n",
    "            unit (str): Temperature unit ('celsius' or 'fahrenheit').\n",
    "\n",
    "        Returns:\n",
    "            dict: Weather stores with temperature, condition, and humidity.\n",
    "\n",
    "    \"\"\"\n",
    "\turl = \"https://api.weatherapi.com/v1/current.json\"\n",
    "\tparams = { \"key\": WEATHER_API_KEY, \"q\": location, \"aqi\": \"no\" }\n",
    "\tresp = requests.get( url, params = params ).json( )\n",
    "\n",
    "\ttemp = resp[ \"current\" ][ \"temp_c\" ] if unit == \"celsius\" else resp[ \"current\" ][ \"temp_f\" ]\n",
    "\n",
    "\treturn {\n",
    "\t\t\t\"location\": f\"{resp[ 'location' ][ 'name' ]}, {resp[ 'location' ][ 'country' ]}\",\n",
    "\t\t\t\"temperature\": temp,\n",
    "\t\t\t\"unit\": unit,\n",
    "\t\t\t\"condition\": resp[ \"current\" ][ \"condition\" ][ \"text\" ],\n",
    "\t\t\t\"humidity\": resp[ \"current\" ][ \"humidity\" ]\n",
    "\t}\n",
    "\n",
    "def get_forecast( location: str, days: int = 3, unit: str = \"fahrenheit\" ) -> dict:\n",
    "\t\"\"\"\n",
    "        Purpose:\n",
    "            Fetch weather forecast for the next given number of days from WeatherAPI.\n",
    "\n",
    "        Parameters:\n",
    "            location (str): City or region.\n",
    "            days (int): Number of days to forecast (1â€“10).\n",
    "            unit (str): Temperature unit ('celsius' or 'fahrenheit').\n",
    "\n",
    "        Returns:\n",
    "            dict: Multi-day forecast including date, min/max temperatures, and conditions.\n",
    "    \"\"\"\n",
    "\turl = \"https://api.weatherapi.com/v1/forecast.json\"\n",
    "\tparams = { \"key\": WEATHER_API_KEY, \"q\": location, \"days\": days, \"aqi\": \"no\", \"alerts\": \"no\" }\n",
    "\tresp = requests.get( url, params = params ).json( )\n",
    "\n",
    "\tforecast_list = [ ]\n",
    "\tfor day in resp[ \"forecast\" ][ \"forecastday\" ]:\n",
    "\t\tforecast_list.append( {\n",
    "\t\t\t\t\"date\": day[ \"date\" ],\n",
    "\t\t\t\t\"min_temp\": day[ \"day\" ][ \"mintemp_c\" ] if unit == \"celsius\" else day[ \"day\" ][\n",
    "\t\t\t\t\t\"mintemp_f\" ],\n",
    "\t\t\t\t\"max_temp\": day[ \"day\" ][ \"maxtemp_c\" ] if unit == \"celsius\" else day[ \"day\" ][\n",
    "\t\t\t\t\t\"maxtemp_f\" ],\n",
    "\t\t\t\t\"unit\": unit,\n",
    "\t\t\t\t\"condition\": day[ \"day\" ][ \"condition\" ][ \"text\" ]\n",
    "\t\t} )\n",
    "\n",
    "\treturn {\n",
    "\t\t\t\"location\": f\"{resp[ 'location' ][ 'name' ]}, {resp[ 'location' ][ 'country' ]}\",\n",
    "\t\t\t\"forecast\": forecast_list\n",
    "\t}"
   ],
   "id": "8b19913b41306eee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Step 2: Define function schema for OpenAI",
   "id": "36fc1b2495a156bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "functions = [\n",
    "\t\t{\n",
    "\t\t\t\t\"name\": \"get_weather\",\n",
    "\t\t\t\t\"description\": \"Get the current weather for a location\",\n",
    "\t\t\t\t\"parameters\": {\n",
    "\t\t\t\t\t\t\"type\": \"object\",\n",
    "\t\t\t\t\t\t\"properties\": {\n",
    "\t\t\t\t\t\t\t\t\"location\": { \"type\": \"string\", \"description\": \"City name\" },\n",
    "\t\t\t\t\t\t\t\t\"unit\": { \"type\": \"string\", \"enum\": [ \"celsius\", \"fahrenheit\" ] }\n",
    "\t\t\t\t\t\t},\n",
    "\t\t\t\t\t\t\"required\": [ \"location\" ]\n",
    "\t\t\t\t}\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\t\"name\": \"get_forecast\",\n",
    "\t\t\t\t\"description\": \"Get the multi-day weather forecast for a location\",\n",
    "\t\t\t\t\"parameters\": {\n",
    "\t\t\t\t\t\t\"type\": \"object\",\n",
    "\t\t\t\t\t\t\"properties\": {\n",
    "\t\t\t\t\t\t\t\t\"location\": { \"type\": \"string\", \"description\": \"City name\" },\n",
    "\t\t\t\t\t\t\t\t\"days\": { \"type\": \"integer\",\n",
    "\t\t\t\t\t\t\t\t          \"description\": \"Number of days (1â€“10)\" },\n",
    "\t\t\t\t\t\t\t\t\"unit\": { \"type\": \"string\", \"enum\": [ \"celsius\", \"fahrenheit\" ] }\n",
    "\t\t\t\t\t\t},\n",
    "\t\t\t\t\t\t\"required\": [ \"location\", \"days\" ]\n",
    "\t\t\t\t}\n",
    "\t\t}\n",
    "]"
   ],
   "id": "ed038db9437268f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Step 3: First API call â€“ let the model decide if it should call the function",
   "id": "e2513c5c58212817"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "response = client.chat.completions.create(\n",
    "\tmodel = \"gpt-4o-mini\",\n",
    "\tmessages = [ { \"role\": \"user\",\n",
    "\t               \"content\": \"What will the weather be in London for the next 3 days in Celsius?\" } ],\n",
    "\tfunctions = functions,\n",
    "\tfunction_call = \"auto\"\n",
    ")\n",
    "\n",
    "message = response.choices[ 0 ].message"
   ],
   "id": "5f91b74ab607fe04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Step 4: If a function is called, run it and send the result back",
   "id": "8051673e6ae1498f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if message.get( \"function_call\" ):\n",
    "\tfn_name = message.function_call.name\n",
    "\tfn_args = json.loads( message.function_call.arguments )\n",
    "\n",
    "\tif fn_name == \"get_weather\":\n",
    "\t\tresult = get_weather( **fn_args )\n",
    "\telif fn_name == \"get_forecast\":\n",
    "\t\tresult = get_forecast( **fn_args )\n",
    "\telse:\n",
    "\t\tresult = { \"error\": \"Unknown function\" }\n",
    "\n",
    "\tfollowup = client.chat.completions.create(\n",
    "\t\tmodel = \"gpt-4o-mini\",\n",
    "\t\tmessages = [\n",
    "\t\t\t\t{ \"role\": \"user\",\n",
    "\t\t\t\t  \"content\": \"What will the weather be in London for the next 3 days in Celsius?\" },\n",
    "\t\t\t\tmessage,\n",
    "\t\t\t\t{ \"role\": \"function\", \"name\": fn_name, \"content\": json.dumps( result ) }\n",
    "\t\t]\n",
    "\t)\n",
    "\n",
    "\tprint( followup.choices[ 0 ].message[ \"content\" ] )"
   ],
   "id": "f1c15945625db578"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Send Email",
   "id": "e26e0b2058eb8ba6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "tools = [\n",
    "\t{\n",
    "\t\t'text': 'function',\n",
    "\t\t'function':\n",
    "\t\t{\n",
    "\t\t\t'name': 'send_email',\n",
    "\t\t\t'description': 'Send an email to a given recipient with a subject and message.',\n",
    "\t\t\t'parameters':\n",
    "\t\t\t{\n",
    "\t\t\t\t'text': 'object',\n",
    "\t\t\t\t'properties':\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t'to':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t'text': 'path',\n",
    "\t\t\t\t\t\t'description': 'The recipient email address.'\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t'subject':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t'text': 'path',\n",
    "\t\t\t\t\t\t'description': 'Email subject line.'\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t'body':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t'text': 'path',\n",
    "\t\t\t\t\t\t'description': 'Body of the email message.'\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t},\n",
    "\t\t\t\t'required': [ 'to', 'subject', 'body' ],\n",
    "\t\t\t\t'additionalProperties': False\n",
    "\t\t\t},\n",
    "\t\t\t'strict': True\n",
    "\t\t}\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Create Completion\n",
    "completion = client.chat.completions.create( model='gpt-4o',\n",
    "\tmessages=[ { 'role': 'user',\n",
    "\t             'content': 'Can you send an email to terryeppler@gmail.com saying hi?' } ],\n",
    "\ttools=_tools )\n",
    "\n",
    "print( completion.choices[ 0 ].message.tool_calls )"
   ],
   "id": "8f10aeafed2edcd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Search Document",
   "id": "a1f24c7cb9758c33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "_tools = [\n",
    "{\n",
    "\t\t'text': 'function',\n",
    "\t\t'function':\n",
    "        {\n",
    "\t\t\t\t'name': 'search_knowledge_base',\n",
    "\t\t\t\t'description': 'Query a knowledge base to retrieve relevant info on a topic.',\n",
    "\t\t\t\t'parameters':\n",
    "                {\n",
    "\t\t\t\t\t\t'text': 'object',\n",
    "\t\t\t\t\t\t'properties':\n",
    "                        {\n",
    "\t\t\t\t\t\t\t\t'query':\n",
    "                                {\n",
    "                                    'text': 'path',\n",
    "                                    'description': 'The user prompt or search query.'\n",
    "                                },\n",
    "\t\t\t\t\t\t\t\t'options':\n",
    "                                {\n",
    "\t\t\t\t\t\t\t\t\t\t'text': 'object',\n",
    "\t\t\t\t\t\t\t\t\t\t'properties':\n",
    "                                        {\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'num_results':\n",
    "                                                {\n",
    "                                                    'text': 'num',\n",
    "                                                    'description': 'Number of top results to return.'\n",
    "                                                },\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'domain_filter':\n",
    "                                                {\n",
    "                                                    'text': [ 'path', 'null' ],\n",
    "                                                    'description': 'Optional domain to narrow the search. Pass null if not needed.'\n",
    "                                                },\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'sort_by':\n",
    "                                                {\n",
    "                                                    'text': [ 'path', 'null' ],\n",
    "                                                    'enum': [ 'relevance', 'date', 'popularity', 'alphabetical' ],\n",
    "                                                    'description': 'How to sort results. Pass null if not needed.'\n",
    "                                                }\n",
    "                                        },\n",
    "\t\t\t\t\t\t\t\t\t\t'required': [ 'num_results', 'domain_filter', 'sort_by' ],\n",
    "\t\t\t\t\t\t\t\t\t\t'additionalProperties': False\n",
    "                                }\n",
    "                        },\n",
    "\t\t\t\t\t\t'required': [ 'query', 'options' ],\n",
    "\t\t\t\t\t\t'additionalProperties': False\n",
    "                },\n",
    "\t\t\t\t'strict': True\n",
    "        }\n",
    "} ]\n",
    "\n",
    "messages = [\n",
    "{\n",
    "    'role': 'user',\n",
    "    'content': 'Can you find information about ChatGPT in the GPT knowledge base?'\n",
    "} ]\n",
    "\n",
    "completion = client.chat.completions.create( model='gpt-4o', messages=_messages, tools=tools )\n",
    "print( completion.choices[ 0 ].message.tool_calls )"
   ],
   "id": "b54cc7f75bf7d1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Web Search Tool",
   "id": "c41da921aa018c9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "user_prompt = r'''\n",
    "What was a positive news story from today?\n",
    "'''\n",
    "\n",
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "message = [\n",
    "{\n",
    "    'role': 'user',\n",
    "    'content': user_prompt,\n",
    "} ]\n",
    "\n",
    "# Create completion\n",
    "\n",
    "completion = client.chat.completions.create( model='gpt-4o-search-preview', web_search_options={ },\n",
    "    messages=message )\n",
    "\n",
    "print( completion.choices[ 0 ].message.content )"
   ],
   "id": "13ad23c350335b5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Appropriation Status",
   "id": "384afa8fa5fbd504"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fetch_appropriations_status( ):\n",
    "\turl = \"https://www.congress.gov/crs-appropriations-status-table\"\n",
    "\tresponse = requests.get( url )\n",
    "\tresponse.raise_for_status( )\n",
    "\n",
    "\tsoup = BeautifulSoup( response.text, \"html.parser\" )\n",
    "\n",
    "\t# Find the main appropriations status table\n",
    "\ttable = soup.find( \"table\" )\n",
    "\theaders = [ th.get_text( strip = True ) for th in table.find_all( \"th\" ) ]\n",
    "\n",
    "\t# Parse each row\n",
    "\trows = [ ]\n",
    "\tfor tr in table.find_all( \"tr\" )[ 1: ]:\n",
    "\t\tcells = [ td.get_text( strip = True ) for td in tr.find_all( \"td\" ) ]\n",
    "\t\tif cells:\n",
    "\t\t\trows.append( cells )\n",
    "\n",
    "\t# Convert to DataFrame\n",
    "\tdf_status = pd.DataFrame( rows, columns = headers )\n",
    "\n",
    "\t# Clean up (optional: filter columns of interest)\n",
    "\tdf_status = df_status.replace( \"\", pd.NA )\n",
    "\n",
    "\treturn df_status\n",
    "\n",
    "# --- Example run ---\n",
    "df_appropriations_status = fetch_appropriations_status( )\n",
    "\n",
    "# Display formatted table\n",
    "print( df_appropriations_status.head( 10 ) )"
   ],
   "id": "f56b7766767907db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### SQLite",
   "id": "df8de1ff1fb9140c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "conn = sqlite3.connect( 'df/Chinook.db' )\n",
    "print( 'Opened database successfully' )"
   ],
   "id": "4e30dc2999a049f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Define Schema Functions",
   "id": "5e9d7639a3024277"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_table_names( conn ):\n",
    "    \"\"\"\n",
    "\n",
    "        Return a list of table names.\n",
    "\n",
    "    \"\"\"\n",
    "    table_names = []\n",
    "    tables = conn.execute( 'SELECT name FROM sqlite_master WHERE scaler=\"table\";' )\n",
    "    for table in tables.fetchall():\n",
    "        table_names.append(table[0])\n",
    "    return table_names\n",
    "\n",
    "\n",
    "def get_column_names( conn, table_name ):\n",
    "    \"\"\"\n",
    "\n",
    "        Return a list of column names.\n",
    "\n",
    "    \"\"\"\n",
    "    column_names = [ ]\n",
    "    columns = conn.execute( f'PRAGMA table_info( \"{table_name}\" );' ).fetchall( )\n",
    "    for col in columns:\n",
    "        column_names.append( col[ 1 ] )\n",
    "    return column_names\n",
    "\n",
    "\n",
    "def get_database_info( conn ):\n",
    "    \"\"\"\n",
    "\n",
    "        Return a list of dicts containing the table name and columns for each table in the database.\n",
    "\n",
    "    \"\"\"\n",
    "    table_dicts = []\n",
    "    for table_name in get_table_names(conn):\n",
    "        columns_names = get_column_names(conn, table_name)\n",
    "        table_dicts.append( { 'table_name': table_name, 'column_names': columns_names } )\n",
    "    return table_dicts\n"
   ],
   "id": "ce9c599b99a26f7e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Extract schema",
   "id": "9640413175d79491"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "database_schema_dict = get_database_info( conn )\n",
    "database_schema_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
    "        for table in database_schema_dict\n",
    "    ])"
   ],
   "id": "e5df7d88f01b51b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Define Function Schema",
   "id": "a576afd8824e312f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tools = [\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function':\n",
    "\t    {\n",
    "            'name': 'ask_database',\n",
    "            'description': 'Use this function to answer user questions about music. Input should be a fully formed SQL query.',\n",
    "            'parameters':\n",
    "\t        {\n",
    "                'type': 'object',\n",
    "                'properties':\n",
    "\t            {\n",
    "                    'query':\n",
    "\t                {\n",
    "                        'type': 'string',\n",
    "                        'description': f\"\"\"\n",
    "                                SQL query extracting info to answer the user's question.\n",
    "                                SQL should be written using this database schema:\n",
    "                                {database_schema_string}\n",
    "                                The query should be returned in plain text, not in JSON.\n",
    "                                \"\"\",\n",
    "                    }\n",
    "                },\n",
    "                'required': [ 'query' ],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ],
   "id": "a6292e4b28a92bfe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Define Database Function",
   "id": "ef99ac790e9b6cde"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def ask_database( conn, query ):\n",
    "    \"\"\"\n",
    "\n",
    "        Function to query SQLite database with a provided SQL query.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = str(conn.execute(query).fetchall())\n",
    "    except Exception as e:\n",
    "        results = f'query failed with error: {e}'\n",
    "    return results"
   ],
   "id": "aa7f68e9b7b9ec56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Step 1: Prompt the model with content that may result in model selecting a tool to use.\n",
    "- Step 2: Check programmatically if model wanted to call a function. If true, proceed to step 3.\n",
    "- Step 3: Extract the function name and parameters from response, call the function with parameters then append the result to messages.\n",
    "- Step 4: Invoke the chat completions API with the message list to get the response.\n"
   ],
   "id": "83af4e33a35b27ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "messages = [{\n",
    "    'role':'user',\n",
    "    'content': 'What is the name of the album with the most tracks?'\n",
    "}]\n",
    "\n",
    "response = client.chat.completions.create( model='gpt-4o', messages=messages,\n",
    "    tools= tools, tool_choice='auto' )\n",
    "\n",
    "response_message = response.choices[ 0 ].message\n",
    "messages.append( response_message )\n",
    "print( response_message )"
   ],
   "id": "2de821fddbcdfc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 2: determine if the response from the model includes a tool call.   \n",
    "tool_calls = response_message.tool_calls\n",
    "if tool_calls:\n",
    "    tool_call_id = tool_calls[ 0 ].id\n",
    "    tool_function_name = tool_calls[ 0 ].function.name\n",
    "    tool_query_string = json.loads( tool_calls[ 0 ].function.arguments )[ 'query' ]\n",
    "    if tool_function_name == 'ask_database':\n",
    "        results = ask_database( conn, tool_query_string )\n",
    "        messages.append( {\n",
    "            'role': 'tool',\n",
    "            'tool_call_id': tool_call_id,\n",
    "            'name': tool_function_name, \n",
    "            'content': results\n",
    "        } )\n",
    "        model_response_with_function_call = client.chat.completions.create( model='gpt-4o', messages=messages )\n",
    "        print( model_response_with_function_call.choices[0].message.content )\n",
    "    else: \n",
    "        print( f'Error: function {tool_function_name} does not exist' )\n",
    "else:\n",
    "    print( response_message.content )"
   ],
   "id": "fe24d6e1758f0f41"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### LangChain Web Search\n",
    "- To trigger a web search, pass `{'type': 'web_search_preview'}` to the model as you would another too"
   ],
   "id": "56c62e9168aec24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "llm.invoke( '...', tools=[ { 'text': 'web_search_preview' } ] )",
   "id": "37bda0d2009bc4f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "llm = ChatOpenAI( model='gpt-4o-mini' )\n",
    "tool = { 'text': 'web_search_preview' }\n",
    "llm_with_tools = llm.bind_tools( [ tool ] )\n",
    "\n",
    "response = llm_with_tools.invoke( 'What was a positive news story from today?' )"
   ],
   "id": "1a69beb3ded891a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Web Page Loader\n",
    "- For a simple string representation of text that is embedded in a web page, the method below is appropriate.\n",
    "- It will return a list of Document objects -- one per page -- containing a single string of the page's text"
   ],
   "id": "1f27c2076a32db6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "page_url = \"https://python.langchain.com/docs/how_to/chatbots_memory/\"\n",
    "\n",
    "loader = WebBaseLoader( web_paths=[ page_url ] )\n",
    "docs = [ ]\n",
    "async for doc in loader.alazy_load( ):\n",
    "    docs.append( doc )\n",
    "\n",
    "assert len( docs ) == 1\n",
    "doc = docs[ 0 ]"
   ],
   "id": "2fdbcde1762a31e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Can specify desired `<div>` classes and other parameters via BeautifulSoup",
   "id": "34bfa045d44391f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=[ page_url ],\n",
    "    bs_kwargs=\\\n",
    "\t{\n",
    "        'parse_only': bs4.SoupStrainer( class_='theme-doc-markdown markdown' ),\n",
    "    },\n",
    "    bs_get_text_kwargs=\\\n",
    "\t{\n",
    "\t\t\t'separator': ' | ',\n",
    "\t\t\t'strip': True\n",
    "\t} )\n",
    "\n",
    "docs = []\n",
    "async for doc in loader.alazy_load( ):\n",
    "    docs.append( doc )\n",
    "\n",
    "assert len( docs ) == 1\n",
    "doc = docs[ 0 ]"
   ],
   "id": "6f498dc6062cb5a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### File Search Tool",
   "id": "475b028b4dbce81a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### LangChain File Search\n",
    "- To trigger a file search, pass a file search tool to the model as you would another tool.\n",
    "- You will need to populate an OpenAI-managed vector store and include the vector store ID in the tool definition"
   ],
   "id": "c0809d98c863eb58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "llm = ChatOpenAI( model='gpt-4o-mini' )\n",
    "\n",
    "openai_vector_store_ids = [\n",
    "    'vs_...',  # your IDs here\n",
    "]\n",
    "\n",
    "tool =\\\n",
    "{\n",
    "    'text': 'file_search',\n",
    "    'vector_store_ids': openai_vector_store_ids,\n",
    "}\n",
    "\n",
    "llm_with_tools = llm.bind_tools( [ tool ] )\n",
    "\n",
    "response = llm_with_tools.invoke( 'What is deep research by OpenAI?' )\n",
    "print( response.text( ) )"
   ],
   "id": "d3e5c0ca66f7772d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Use Browser",
   "id": "eae1d57e56a09c33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "_args = [ '--disable-extensions', '--disable-file-system' ]\n",
    "with sync_playwright( ) as p:\n",
    "    browser = p.chromium.launch( headless=False, chromium_sandbox=True, env={ }, args=_args )\n",
    "    page = browser.new_page( )\n",
    "    page.set_viewport_size( { 'width': 1024, 'height': 768 } )\n",
    "    page.goto( 'https://bing.com' )\n",
    "    page.wait_for_timeout( 10000 )"
   ],
   "id": "755adffccebf080b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Use Computer",
   "id": "3e40eef135fdf6f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "_model = 'computer-use-preview'\n",
    "_reasoning = { 'generate_summary': 'concise', }\n",
    "_truncation = 'auto'\n",
    "_tools = [\n",
    "{\n",
    "    'text': 'computer_use_preview',\n",
    "    'display_width': 1024,\n",
    "    'display_height': 768,\n",
    "    'environment': 'browser'\n",
    "} ]\n",
    "\n",
    "_input = [\n",
    "{\n",
    "        'role': 'user',\n",
    "        'content': 'Check the latest OpenAI news on bing.com.'\n",
    "} ]\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create( model=_model, tools=_tools, input=_input,\n",
    "    reasoning=_reasoning, truncation='auto' )\n",
    "\n",
    "print( response.cleaned_lines )"
   ],
   "id": "ab6266514b58aa26"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Send Computer Use Request\n",
    "\n",
    "- Send a request to create a Response with the **computer-use-preview** model equipped with the `computer_use_preview` tool.\n",
    "- This request should include details about your environment, along with an initial input prompt."
   ],
   "id": "e2ad3d2305162416"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "_model = 'computer-use-preview'\n",
    "_tools = [\n",
    "{\n",
    "    'text': 'computer_use_preview',\n",
    "    'display_width': 1024,\n",
    "    'display_height': 768,\n",
    "    'environment': 'browser'\n",
    "} ]\n",
    "\n",
    "_input = [\n",
    "{\n",
    "        'role': 'user',\n",
    "        'content': 'Check the latest OpenAI news on bing.com.'\n",
    "} ]\n",
    "\n",
    "# Create response\n",
    "response = client.responses.create( model=_model, tools=_tools, input=_input,\n",
    "    reasoning={ 'generate_summary': 'concise', }, truncation='auto' )\n",
    "\n",
    "print( response.cleaned_lines )"
   ],
   "id": "82fc154541d3d4ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Execute Action\n",
    "- Execute the corresponding actions on your computer or browser.\n",
    "- How you map a computer call to actions through code depends on your environment.\n",
    "- This code shows example implementations for the most common computer actions."
   ],
   "id": "19ea1d17814a58fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def handle_model_action( page, action ):\n",
    "    '''\n",
    "\n",
    "\t\tGiven a computer action (e.g., click, double_click, scroll, resources.),\n",
    "\t\texecute the corresponding operation on the Playwright page.\n",
    "\n",
    "    '''\n",
    "    action_type = action.type\n",
    "    try:\n",
    "        match action_type:\n",
    "            case 'click':\n",
    "                x, y = action.x, action.y\n",
    "                button = action.button\n",
    "                print( f\"Action: click at ({x}, {y}) with button '{button}' \" )\n",
    "                # Not handling things like middle click, resources.\n",
    "                if button != 'left' and button != 'right':\n",
    "                    button = 'left'\n",
    "                page.mouse.click( x, y, button=button )\n",
    "\n",
    "            case 'scroll':\n",
    "                x, y = action.x, action.y\n",
    "                scroll_x, scroll_y = action.scroll_x, action.scroll_y\n",
    "                print(f'Action: scroll at ({x}, {y}) with offsets (scroll_x={scroll_x}, scroll_y={scroll_y})')\n",
    "                page.mouse.move( x, y )\n",
    "                page.evaluate( f'window.scrollBy({scroll_x}, {scroll_y})' )\n",
    "\n",
    "            case 'keypress':\n",
    "                keys = action.keys\n",
    "                for k in keys:\n",
    "                    print( f\"Action: keypress '{k}' \" )\n",
    "                    # A simple mapping for common keys; expand as needed.\n",
    "                    if k.lower( ) == 'enter':\n",
    "                        page.keyboard.press( 'Enter' )\n",
    "                    elif k.lower( ) == 'space':\n",
    "                        page.keyboard.press( ' ' )\n",
    "                    else:\n",
    "                        page.keyboard.press( k )\n",
    "\n",
    "            case 'text':\n",
    "                text = action.text\n",
    "                print( f'Action: scaler documents: {text}' )\n",
    "                page.keyboard.type( text )\n",
    "\n",
    "            case 'wait':\n",
    "                print( f'Action: wait' )\n",
    "                time.sleep( 2 )\n",
    "\n",
    "            case 'screenshot':\n",
    "                # Nothing to do as screenshot is taken at each turn\n",
    "                print( f'Action: screenshot' )\n",
    "\n",
    "            # Handle other actions here\n",
    "\n",
    "            case _:\n",
    "                print( f'Unrecognized action: {action}' )\n",
    "\n",
    "    except Exception as e:\n",
    "        print( f'Error handling action {action}: {e}' )"
   ],
   "id": "3582e1d33fa258d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Capture Screenshot\n",
    "- After executing the action, capture the updated state of the environment as a screenshot."
   ],
   "id": "7fef7bd5a2ef1898"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_screenshot( page ):\n",
    "    '''\n",
    "\n",
    "    \tTake a full-page screenshot using Playwright and return the image bytes.\n",
    "\n",
    "    '''\n",
    "    return page.screenshot( )"
   ],
   "id": "903a5b50ee945679"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Repeating Loop\n",
    "- Once you have the screenshot, you can send it back to the model as a **computer_call_output** to get the next action.\n",
    "- Repeat these steps as long as you get a **computer_call** item in the response."
   ],
   "id": "5c8068df89772139"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def computer_use_loop( instance, response ):\n",
    "    '''\n",
    "\n",
    "    \tRun the loop that executes computer actions until no 'computer_call' is found.\n",
    "    \t\n",
    "    '''\n",
    "    while True:\n",
    "        computer_calls = [ i for i in response.output if i.type == 'computer_call' ]\n",
    "        if not computer_calls:\n",
    "            print( 'No computer call found. Output from small_model:' )\n",
    "            for item in response.output:\n",
    "                print( item )\n",
    "            break  # Exit when no computer calls are issued.\n",
    "\t        \n",
    "        computer_call = computer_calls[ 0 ]\n",
    "        last_call_id = computer_call.call_id\n",
    "        action = computer_call.action\n",
    "\n",
    "        # Execute the action (function defined in step 3)\n",
    "        handle_model_action( instance, action )\n",
    "        time.sleep( 1 )  # Allow time for changes to take effect.\n",
    "\n",
    "        # Take a screenshot after the action (function defined in step 4)\n",
    "        screenshot_bytes = get_screenshot( instance )\n",
    "        screenshot_base64 = base64.b64encode( screenshot_bytes ).decode( 'utf-8' )\n",
    "\n",
    "        # Send the screenshot back as a computer_call_output\n",
    "        response = client.responses.create(\n",
    "            model='computer-use-preview',\n",
    "            previous_response_id=response.id,\n",
    "            tools=[\n",
    "            {\n",
    "                'text': 'computer_use_preview',\n",
    "                'display_width': 1024,\n",
    "                'display_height': 768,\n",
    "                'environment': 'browser'\n",
    "            } ],\n",
    "            input=[\n",
    "            {\n",
    "                'call_id': last_call_id,\n",
    "                'text': 'computer_call_output',\n",
    "                'cleaned_lines':\n",
    "                {\n",
    "                    'text': 'input_image',\n",
    "                    'image_url': f'target_values:image/png;base64,{screenshot_base64}'\n",
    "                }\n",
    "            } ],\n",
    "            truncation='auto'\n",
    "        )\n",
    "\n",
    "    return response"
   ],
   "id": "9ff5a3fad72dfbf8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Responses",
   "id": "ae37f2b57d7cabbd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Function Tool",
   "id": "5afb8881523bee5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# 1. Define a list of callable tools for the model\n",
    "tools = [\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'name': 'get_horoscope',\n",
    "        'description': \"Get today's horoscope for an astrological sign.\",\n",
    "        'parameters':\n",
    "\t    {\n",
    "            'type': 'object',\n",
    "            'properties':\n",
    "\t        {\n",
    "                'sign':\n",
    "\t            {\n",
    "                    'type': 'string',\n",
    "                    'description': 'An astrological sign like Taurus or Aquarius',\n",
    "                },\n",
    "            },\n",
    "            'required': ['sign'],\n",
    "        },\n",
    "    }, ]\n",
    "\n",
    "def get_horoscope( sign ):\n",
    "    return f'{sign}: Next Tuesday you will befriend a baby otter.'\n",
    "\n",
    "# Create a running input list we will add to over time\n",
    "input_list = [ { 'role': 'user', 'content': 'What is my horoscope? I am an Aquarius.'}]\n",
    "\n",
    "# 2. Prompt the model with tools defined\n",
    "response = client.responses.create( model='gpt-5', tools=tools, input=input_list, )\n",
    "\n",
    "# Save function call outputs for subsequent requests\n",
    "input_list += response.output\n",
    "\n",
    "for item in response.output:\n",
    "    if item.type == 'function_call':\n",
    "        if item.name == 'get_horoscope':\n",
    "            # 3. Execute the function logic for get_horoscope\n",
    "            horoscope = get_horoscope(json.loads(item.arguments))\n",
    "\n",
    "            # 4. Provide function call results to the model\n",
    "            input_list.append({\n",
    "                'type': 'function_call_output',\n",
    "                'call_id': item.call_id,\n",
    "                'output': json.dumps({\n",
    "                  'horoscope': horoscope\n",
    "                })\n",
    "            })\n",
    "\n",
    "print( 'Final input:' )\n",
    "print( input_list )\n",
    "\n",
    "response = client.responses.create( model='gpt-5',\n",
    "    instructions='Respond only with a horoscope generated by a tool.',\n",
    "    tools=tools, input=input_list, )\n",
    "\n",
    "# 5. The model should be able to give a response!\n",
    "print('Final output:')\n",
    "print(response.model_dump_json(indent=2))\n",
    "print('\\n' + response.output_text)"
   ],
   "id": "cb3c7a7dfae41f48"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Defining functions\n",
   "id": "155f4f1bf7f475ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Define the functions under the tools param of the assistant.\n",
    "\n",
    "- Functions can be set in the tools parameter of each API request.\n",
    "\n",
    "- A function is defined by its schema, which informs the model what it does and what input arguments it expects.\n",
    "\n",
    "- A function definition has the following properties:\n"
   ],
   "id": "9d852567c92b6cb6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "| Field\t          | Description                                          |\n",
    "|-----------------|------------------------------------------------------\n",
    "| type\t           | This should always be function                       |\n",
    "| name\t           | The function's name (e.g. get_weather)               |\n",
    "| description\t    | Details on when and how to use the function          |\n",
    "| parameters\t     | JSON schema defining the function's input arguments  |\n",
    "| strict\t         | Whether to enforce strict mode for the function call  |"
   ],
   "id": "49780e791e41bef9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "-  function definition for a `get_weather` function",
   "id": "12efca04dbba50af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "    'type': 'function',\n",
    "    'name': 'get_weather',\n",
    "    'description': 'Retrieves current weather for the given location.',\n",
    "    'parameters': {\n",
    "        'type': 'object',\n",
    "        'properties': {\n",
    "            'location': {\n",
    "                'type': 'string',\n",
    "                'description': 'City and country e.g. BogotÃ¡, Colombia'\n",
    "            },\n",
    "            'units': {\n",
    "                'type': 'string',\n",
    "                'enum': ['celsius', 'fahrenheit'],\n",
    "                'description': 'Units the temperature will be returned in.'\n",
    "            }\n",
    "        },\n",
    "        'required': ['location', 'units'],\n",
    "        'additionalProperties': false\n",
    "    },\n",
    "    'strict': true\n",
    "}"
   ],
   "id": "6934f2c2cd76c22d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Handling Function Calls",
   "id": "576610ae5b10ac21"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- When the model calls a function, you must execute it and return the result.\n",
    "\n",
    "- Since model responses can include zero, one, or multiple calls, it is best practice to assume there are several.\n",
    "\n",
    "- The response has an array of tool_calls, each with an id (used later to submit the function result) and a function containing a name and JSON-encoded arguments"
   ],
   "id": "e6363afe15b7b27c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "[\n",
    "    {\n",
    "        'id': 'call_12345xyz',\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'get_weather',\n",
    "            'arguments': '{\\'location\\':\\'Paris, France\\'}'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'id': 'call_67890abc',\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'get_weather',\n",
    "            'arguments': '{\\'location\\':\\'BogotÃ¡, Colombia\\'}'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'id': 'call_99999def',\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'send_email',\n",
    "            'arguments': '{\\'to\\':\\'bob@email.com\\',\\'body\\':\\'Hi bob\\'}'\n",
    "        }\n",
    "    }\n",
    "]"
   ],
   "id": "4cea772286753108"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###  Code Interpreter Tool",
   "id": "e00ab226244dd532"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "- The Code Interpreter tool allows models to write and run Python code in a sandboxed environment to solve complex problems in domains like data analysis, coding, and math. Use it for:\n",
    "\n",
    "- Processing files with diverse data and formatting\n",
    "\n",
    "- Generating files with data and images of graphs\n",
    "\n",
    "- Writing and running code iteratively to solve problemsâ€”for example, a model that writes code that fails to run can keep rewriting and running that code until it succeeds\n",
    "\n",
    "- Boosting visual intelligence in our latest reasoning models (like o3 and o4-mini). The model can use this tool to crop, zoom, rotate, and otherwise process and transform images"
   ],
   "id": "610542d2539a96af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "instructions = \"\"\"\n",
    "You are a personal math tutor. When asked a math question,\n",
    "write and run code using the python tool to answer the question.\n",
    "\"\"\"\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    tools=[\n",
    "        {\n",
    "            'type': 'code_interpreter',\n",
    "            'container':\n",
    "\t        {\n",
    "\t\t\t        'type': 'auto',\n",
    "\t\t\t        'memory_limit': '4g'\n",
    "\t        }\n",
    "        }\n",
    "    ],\n",
    "    instructions=instructions,\n",
    "    input='I need to solve the equation 3x + 11 = 14. Can you help me?',\n",
    ")\n",
    "\n",
    "print( resp.output )"
   ],
   "id": "cea81ce10afc4f8c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Image Generation Tool",
   "id": "95a83b1d2821c427"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- The image generation tool allows you to generate images using a text prompt, and optionally image inputs.\n",
    "\n",
    "- The `image_generation_call` tool call result will include a base64-encoded image."
   ],
   "id": "9d4e1d5c7bec6939"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "\n",
    "client = OpenAI() \n",
    "\n",
    "response = client.responses.create( model='gpt-5',\n",
    "    input='Generate an image of gray tabby cat hugging an otter with an orange scarf',\n",
    "    tools=[{'type': 'image_generation'}],\n",
    ")\n",
    "\n",
    "# Save the image to a file\n",
    "image_data = [\n",
    "    output.result\n",
    "    for output in response.output\n",
    "    if output.type == 'image_generation_call'\n",
    "]\n",
    "    \n",
    "if image_data:\n",
    "    image_base64 = image_data[0]\n",
    "    with open(\"otter.png\", \"wb\") as f:\n",
    "        f.write(base64.b64decode(image_base64))"
   ],
   "id": "ebb4404b793399a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Computer Use",
   "id": "8e6682a92776d021"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Computer use is a practical application of our `Computer-Using Agent (CUA)` model, `computer-use-preview`, which combines the vision capabilities of GPT-4o with advanced reasoning to simulate controlling computer interfaces and performing tasks\n",
    "\n",
    "- The computer use tool operates in a continuous loop. It sends computer actions, like `click(x,y)` or `type(text)`, which your code executes on a computer or browser environment and then returns screenshots of the outcomes back to the model.\n",
    "\n",
    "- In this way, your code simulates the actions of a human using a computer interface, while our model uses the screenshots to understand the state of the environment and suggest next actions.\n",
    "\n",
    "- This loop lets you automate many tasks requiring clicking, typing, scrolling, and more. For example, booking a flight, searching for a product, or filling out a form."
   ],
   "id": "c2f36154a0d398e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Process\n",
    "\n",
    "1. Send a request to the model: Include the computer tool as part of the available tools, specifying the display size and environment. You can also include in the first request a screenshot of the initial state of the environment.\n",
    "\n",
    "2. Receive a response from the model: Check if the response has any `computer_call` items. This tool call contains a suggested action to take to progress towards the specified goal. These actions could be clicking at a given position, typing in text, scrolling, or even waiting.\n",
    "\n",
    "3. Execute through code the corresponding action on your computer or browser environment.\n",
    "\n",
    "4. After executing the action, capture the updated state of the environment as a screenshot.\n",
    "\n",
    "5. Send a new request with the updated state as a `computer_call_output`, and repeat this loop until the model stops requesting actions or you decide to stop."
   ],
   "id": "de1336874ecb3a4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from playwright.sync_api import sync_playwright\n",
    "\n",
    "with sync_playwright() as p:\n",
    "    browser = p.chromium.launch(\n",
    "        headless=False,\n",
    "        chromium_sandbox=True,\n",
    "        env={},\n",
    "        args=[\n",
    "            \"--disable-extensions\",\n",
    "            \"--disable-file-system\"\n",
    "        ]\n",
    "    )\n",
    "    page = browser.new_page()\n",
    "    page.set_viewport_size({\"width\": 1024, \"height\": 768})\n",
    "    page.goto(\"https://bing.com\")\n",
    "\n",
    "    page.wait_for_timeout(10000)"
   ],
   "id": "4f8ce2f730e61bb4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Assistants",
   "id": "8dd4b6919d0fe9f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### File Search Tool",
   "id": "e58d22240dfc818c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Step 1: Create a new Assistant with File Search Enabled",
   "id": "f2030b87251390d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI()\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name='Financial Analyst Assistant',\n",
    "  instructions='You are an expert financial analyst. Use you knowledge base to answer questions about audited financial statements.',\n",
    "  model='gpt-4o',\n",
    "  tools=[ {'text': 'file_search'} ],\n",
    ")"
   ],
   "id": "94294101971becc1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Step 2 - Upload files and add them to a Vector Store\n",
    "- To access files, the file_search tool uses the Vector Store object\n",
    "- Once the Vector Store is created, poll its status until all files are out of the `in_progress` state"
   ],
   "id": "30d7a72c36cd2ac3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a vector store caled 'Financial Statements'\n",
    "vector_store = client.vector_stores.create( name='Financial Statements' )\n",
    "\n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [ 'edgar/goog-10k.pdf', 'edgar/brka-10k.txt' ]\n",
    "file_streams = [ open( path, 'rb' ) for path in file_paths ]\n",
    "\n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print( file_batch.status )\n",
    "print( file_batch.file_counts )"
   ],
   "id": "e9c425c8a37906c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Step 3 - Update the assistant to use the new Vector Store\n",
    "- Update the assistantâ€™s `tool_resources` with the new `vector_store.id`"
   ],
   "id": "5c4b1cce66541436"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={ 'file_search': { 'vector_store_ids': [ vector_store.id ] } },\n",
    ")"
   ],
   "id": "827562fee1a7962"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- File content can then be downloaded by passing the file ID to the Files API\n",
    "- File paths are listed as annotations that can be converted into links to download the file"
   ],
   "id": "ec1c53bc58d5aa0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI( )\n",
    "image_data = client.files.content( 'file-abc123' )\n",
    "image_data_bytes = image_data.read( )\n",
    "\n",
    "with open( './my-image.png', 'wb' ) as file:\n",
    "    file.write( image_data_bytes )"
   ],
   "id": "858bbbd92a0ff142"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Image API\n",
   "id": "c1542ce2b4f5d823"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "- `Generations`- Generate images from scratch based on a text prompt: https://api.openai.com/v1/images/generations\n",
    "\n",
    "- `Edits`- Modify existing images using a new prompt, either partially or entirely: https://api.openai.com/v1/images/edits\n",
    "\n",
    "- `Variations`- Generate variations of an existing image (available with DALLÂ·E 2 only): https://api.openai.com/v1/images/variations\n",
    "\n",
    "- This API supports gpt-image-1 as well as dall-e-2 and dall-e-3.\n"
   ],
   "id": "9674d63aad484953"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Image Generation",
   "id": "16d1a687c3393499"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = \"\"\"\n",
    "A children's book drawing of a veterinarian using a stethoscope to\n",
    "listen to the heartbeat of a baby otter.\n",
    "\"\"\"\n",
    "\n",
    "result = client.images.generate( model='gpt-image-1', prompt=prompt )\n",
    "\n",
    "image_base64 = result.data[0].b64_json\n",
    "image_bytes = base64.b64decode(image_base64)\n",
    "\n",
    "# Save the image to a file\n",
    "with open( 'otter.png', 'wb' ) as f:\n",
    "    f.write(image_bytes)"
   ],
   "id": "c6337caaa3353255"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Multi-turn Generation",
   "id": "9e6c07efac4f1576"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create( model='gpt-5',\n",
    "    input='Generate an image of gray tabby cat hugging an otter with an orange scarf',\n",
    "    tools=[{'type': 'image_generation'}], )\n",
    "\n",
    "image_data = [  output.result\n",
    "    for output in response.output\n",
    "    if output.type == 'image_generation_call'\n",
    "]\n",
    "\n",
    "if image_data:\n",
    "    image_base64 = image_data[0]\n",
    "\n",
    "    with open('cat_and_otter.png', 'wb') as f:\n",
    "        f.write(base64.b64decode(image_base64))\n",
    "\n",
    "\n",
    "# Follow up\n",
    "\n",
    "response_fwup = client.responses.create(\n",
    "    model='gpt-5',\n",
    "    previous_response_id=response.id,\n",
    "    input='Now make it look realistic',\n",
    "    tools=[{'type': 'image_generation'}],\n",
    ")\n",
    "\n",
    "image_data_fwup = [\n",
    "    output.result\n",
    "    for output in response_fwup.output\n",
    "    if output.type == 'image_generation_call'\n",
    "]\n",
    "\n",
    "if image_data_fwup:\n",
    "    image_base64 = image_data_fwup[0]\n",
    "    with open('cat_and_otter_realistic.png', 'wb') as f:\n",
    "        f.write(base64.b64decode(image_base64))"
   ],
   "id": "bd6225989ef5e8ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Image Streaming",
   "id": "4e0ca7f1893c4806"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "stream = client.images.generate(\n",
    "    prompt='Draw a gorgeous image of a river made of white owl feathers, snaking its way through a serene winter landscape',\n",
    "    model='gpt-image-1',\n",
    "    stream=True,\n",
    "    partial_images=2,\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    if event.type == 'image_generation.partial_image':\n",
    "        idx = event.partial_image_index\n",
    "        image_base64 = event.b64_json\n",
    "        image_bytes = base64.b64decode(image_base64)\n",
    "        with open(f'river{idx}.png', 'wb') as f:\n",
    "            f.write(image_bytes)"
   ],
   "id": "76387c040bc8d061"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Image Editing",
   "id": "57d76b67becdc124"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Edit existing images\n",
    "\n",
    "- Generate new images using other images as a reference\n",
    "\n",
    "- Edit parts of an image by uploading an image and mask indicating which areas should be replaced (a process known as inpainting)"
   ],
   "id": "bb75982eba4250df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = \"\"\"\n",
    "Generate a photorealistic image of a gift basket on a white background \n",
    "labeled 'Relax & Unwind' with a ribbon and handwriting-like font, \n",
    "containing all the items in the reference pictures.\n",
    "\"\"\"\n",
    "\n",
    "result = client.images.edit(\n",
    "    model='gpt-image-1',\n",
    "    image=[\n",
    "        open('body-lotion.png', 'rb'),\n",
    "        open('bath-bomb.png', 'rb'),\n",
    "        open('incense-kit.png', 'rb'),\n",
    "        open('soap.png', 'rb'),\n",
    "    ],\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "image_base64 = result.data[0].b64_json\n",
    "image_bytes = base64.b64decode(image_base64)\n",
    "\n",
    "# Save the image to a file\n",
    "with open(\"gift-basket.png\", \"wb\") as f:\n",
    "    f.write(image_bytes)"
   ],
   "id": "88f5ada82dbf5cd5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### In-painting",
   "id": "159251372bb9641a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "result = client.images.edit( model='gpt-image-1',\n",
    "    image=open( 'sunlit_lounge.png', 'rb' ),\n",
    "    mask=open( 'mask.png', 'rb' ),\n",
    "    prompt='A sunlit indoor lounge area with a pool containing a flamingo' )\n",
    "\n",
    "image_base64 = result.data[0].b64_json\n",
    "image_bytes = base64.b64decode(image_base64)\n",
    "\n",
    "# Save the image to a file\n",
    "with open('composition.png', 'wb') as f:\n",
    "    f.write(image_bytes)"
   ],
   "id": "116d7d3682b6ef6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Input Fidelity",
   "id": "4923a5e42be1da55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- The gpt-image-1 model supports high input fidelity, which allows you to better preserve details from the input images in the output.\n",
    "\n",
    "- This is especially useful when using images that contain elements like faces or logos that require accurate preservation in the generated image.\n",
    "\n",
    "- You can provide multiple input images that will all be preserved with high fidelity, but keep in mind that the first image will be preserved with richer textures and finer details, so if you include elements such as faces, consider placing them in the first image."
   ],
   "id": "fd4c163a80da763c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Llama Parse\n",
   "id": "6e4a92090cb2199"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Download Data",
   "id": "8de241dea64c787"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10q/uber_10q_march_2022.pdf' -O './uber_10q_march_2022.pdf'",
   "id": "b66182fa9a947d24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. Setting API Keys",
   "id": "d3e9471f6635e2d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# API access to llama-cloud\n",
    "os.environ[ 'LLAMA_CLOUD_API_KEY' ] = 'llx-...'\n",
    "\n",
    "# Using OpenAI API for embeddings/llms\n",
    "os.environ[ 'OPENAI_API_KEY' ] = 'sk-...'"
   ],
   "id": "fa6909ee58bca1a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3. Setting LLM and Embedding Model",
   "id": "f3ebbd1bf9ec3c53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "embed_model = OpenAIEmbedding( model='text-embedding-3-small' )\n",
    "llm = OpenAI( model='gpt-3.5-turbo-0125' )\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ],
   "id": "85a9dc4f75f061bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 4. Parse PDF\n",
    "###### We compare two different retrieval/ queryengine strategies.\n",
    "- Using raw Markdown text as nodes for building index and applying a simple query engine for generating results.\n",
    "- Using MarkdownElementNodeParser for parsing the LlamaParse output Markdown results and building a recursive retriever query engine for generation"
   ],
   "id": "e57ae43768b023b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "documents = LlamaParse( result_type='markdown' ).load_data( './uber_10q_march_2022.pdf' )",
   "id": "8a81284a9710cbf6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "node_parser = MarkdownElementNodeParser( llm=OpenAI( model='gpt-3.5-turbo-0125' ), num_workers=8 )\n",
    "nodes = node_parser.get_nodes_from_documents( documents )"
   ],
   "id": "22766a47a3456a9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "text_nodes, index_nodes = node_parser.get_nodes_and_objects( nodes )\n",
    "text_nodes[ 0 ]\n",
    "index_nodes[ 0 ]"
   ],
   "id": "a91e02d5c6ac6f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5. Build Index",
   "id": "bfe4f82adeddf074"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "recursive_index = VectorStoreIndex(nodes=text_nodes + index_nodes)\n",
    "raw_index = VectorStoreIndex.from_documents(documents)"
   ],
   "id": "6e00a3423e8971de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 6. Create Query Engines",
   "id": "5242efa5160d4f04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "reranker = FlagEmbeddingReranker( top_n=5, model='BAAI/bge-reranker-large' )",
   "id": "b88cf8ae7734f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 7. Querying Different Query Engines",
   "id": "10442f4b62101f73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query = 'What is the change of free cash flow and what is the rate from the financial and operational highlights?'\n",
    "\n",
    "response_1 = raw_query_engine.query(query)\n",
    "print('\\n************New LlamaParse+ Basic Query Engine************')\n",
    "print(response_1)\n",
    "\n",
    "response_2 = recursive_query_engine.query(query)\n",
    "print(\n",
    "    '\\n************New LlamaParse+ Recursive Retriever Query Engine************'\n",
    ")\n",
    "print(response_2)"
   ],
   "id": "97ae58ac5e81a5da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 8. Llama Index",
   "id": "7658539ab001326a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "llm = LMStudio( model_name='Hermes-2-Pro-Llama-3-8B',\n",
    "    base_url='http://localhost:1234/v1',\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM,\n",
    "        content='You an expert GPT assistant. Help User with their queries.',\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER,\n",
    "        content='What is the significance of the number 42?',\n",
    "    ),\n",
    "]"
   ],
   "id": "606bca5a8d2b5d7c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 9. RAG with Excel",
   "id": "7c76eaefd60acf32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from llama_cloud_services import LlamaParse\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import VectorStoreIndex"
   ],
   "id": "1edfd7ba641d6194"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Set keys",
   "id": "34b03bd39badc92f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "nest_asyncio.apply( )\n",
    "llama_key = os.getenv( 'LLAMA_CLOUD_API_KEY' )\n",
    "openai_key = os.getenv( 'OPENAI_API_KEY' )"
   ],
   "id": "56538bdb8426a471"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Parse excel document",
   "id": "31d8764dbdcf9226"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "parser = LlamaParse( api_key=llama_key, result_type='markdown' )\n",
    "documents = parser.load_data( '../stores/nvidia_quarterly_revenue_trend_by_market.xlsx' )\n",
    "documents"
   ],
   "id": "9ba45da9193302f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Set OpenAI API Key",
   "id": "50fa35effeb11034"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "llm = OpenAI( model = 'gpt-4' )\n",
    "Settings.llm = llm"
   ],
   "id": "2dff434f9b89af4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Build Index and QueryEngine",
   "id": "a60d1610f3c6360b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "index = VectorStoreIndex.from_documents( documents )\n",
    "query_engine = index.as_query_engine( )"
   ],
   "id": "bf0e80937cd60b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Querying",
   "id": "895d64385707654a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "response = query_engine.query( 'What is the total revenue in Q1 FY25?' )\n",
    "print( str( response ) )"
   ],
   "id": "2a72ce49f99cba48"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 10. Extracting PDF Tables",
   "id": "8b60c139e23bf09a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Load Dependencies\n",
   "id": "ab0a23a6fae38ac8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "from llama_cloud_services import LlamaParse\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ],
   "id": "86ef88029f75cfc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Initialize parser",
   "id": "cfb82c824f1be7b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "parser = LlamaParse( result_type = \"markdown\" )",
   "id": "df9383c699c8300"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Parse document",
   "id": "91c4baeb098fe26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "json_result = parser.get_json_result( \"sample-tables.pdf\" )",
   "id": "857174cc147607f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Get table",
   "id": "61a0ed367c9cc618"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tables = parser.get_tables( json_result, \"tables/\" )",
   "id": "410587895e4798a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Load tables",
   "id": "a55f9c17fd72c901"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.read_csv(\n",
    "\t\"/content/tables/table_2025_16_07_16_30_01_569.csv\",\n",
    ")\n",
    "display( df.fillna( \"\" ) )\n"
   ],
   "id": "40e42a27ac23b788"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 11. Parsing Power Point Text",
   "id": "896cb073f0142ac9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import nest_asyncio\n",
    "from llama_cloud_services import LlamaParse\n",
    "from llama_index.core import VectorStoreIndex"
   ],
   "id": "e24579de8af23727"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "nest_asyncio.apply( )\n",
    "parser = LlamaParse( result_type = 'markdown' )\n",
    "docs = parser.load_data( 'pydata_global.pptx' )\n",
    "print( docs[ 0 ].get_content( )[ :5000 ] )\n",
    "index = VectorStoreIndex.from_documents( docs )\n",
    "response = query_engine.query( 'What are some response quality challenges with naive RAG?' )\n",
    "print( str( response ) )"
   ],
   "id": "f8709146d7e5afec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Langchain",
   "id": "945dcfa81f7aa290"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prompt Engineering",
   "id": "81073d1852023717"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "####  Structure of a Prompt\n",
    "###### A prompt can consist of multiple components:\n",
    "\n",
    "- Instructions\n",
    "\n",
    "- External information or context\n",
    "\n",
    "- User input or query\n",
    "\n",
    "- Output indicator\n",
    "\n",
    "##### Not all prompts require all of these components, but often a good prompt will use two or more of them. Let's define what they all are more precisely.\n",
    "\n",
    "- Instructions tell the model what to do, typically how it should use inputs and/or external information to produce the output we want.\n",
    "\n",
    "- External information or context are additional information that we either manually insert into the prompt, retrieve via a vector database (long-term memory), or pull in through other means (API calls, calculations, etc).\n",
    "\n",
    "##### User input or query is typically a query directly input by the user of the system.\n",
    "\n",
    "- Output indicator is the *beginning* of the generated text. For a model generating Python code we may put `import ` (as most Python scripts begin with a library `import`), or a chatbot may begin with `Chatbot: ` (assuming we format the chatbot script as lines of interchanging text between `User` and `Chatbot`).\n",
    "\n",
    "##### Each of these components should usually be placed the order we've described them. We start with instructions, provide context (if needed), then add the user input, and finally end with the output indicator.\n",
    "___"
   ],
   "id": "ce6c76e74bc1897e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompt = \"\"\"\n",
    "Answer the prompt based on the context below. If the\n",
    "prompt cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language GptModels (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: Which libraries and small_model providers offer LLMs?\n",
    "\n",
    "Answer: \"\"\""
   ],
   "id": "3b095cb6be63536c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### In this example we have:\n",
    "\n",
    "```\n",
    "Instructions\n",
    "\n",
    "Context\n",
    "\n",
    "Question (user input)\n",
    "\n",
    "Output indicator (\"Answer: \")\n",
    "```\n",
    "\n",
    "\n",
    "- We initialize a `text-davinci-003` model like so:"
   ],
   "id": "8a3484bad7b5f146"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# initialize the models\n",
    "openai = OpenAI( model_name='text-davinci-003', openai_api_key='YOUR_API_KEY' )"
   ],
   "id": "7d2f6bd8f418abbe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- And make a generation from our prompt.",
   "id": "3a84ae2455ad2e3f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e2f046469e78f87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print( openai( prompt ) )",
   "id": "bf3c5508b39c9c06"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- We wouldn't typically know what the users prompt is beforehand, so we actually want to add this in. So rather than writing the prompt directly, we create a `PromptTemplate` with a single input variable `query`.",
   "id": "38a961f88a18dd14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "template = \"\"\"\n",
    "Answer the prompt based on the context below. If the\n",
    "prompt cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language GptModels (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate( input_variables=[ 'query' ], template=template )"
   ],
   "id": "e8d4e601eaeb72e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Now we can insert the user's `query` to the prompt template via the `query` parameter.",
   "id": "ca33562e1feb976b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print( prompt_template.format( query='Which libraries and small_model providers offer LLMs?' ) )",
   "id": "eb5b857e69ef2126"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompt = 'Which libraries and small_model providers offer LLMs?'\n",
    "print( openai( prompt_template.format( query=prompt ) ) )"
   ],
   "id": "2648cd09450336e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- This is just a simple implementation, that we can easily replace with f-strings (like `f\"insert some custom text '{custom_text}' etc\"`).\n",
    "- But using LangChain's `PromptTemplate` object we're able to formalize the process, add multiple parameters, and build the prompts in an object-oriented way.\n",
    "\n"
   ],
   "id": "aef180b81c49e71d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Few Shot Prompt Templates",
   "id": "e3d81982cecd220f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Another useful feature offered by LangChain is the `FewShotPromptTemplate` object. This is ideal for what we'd call *few-shot learning* using our prompts.\n",
    "\n",
    "##### To give some context, the primary sources of \"knowledge\" for LLMs are:\n",
    "\n",
    "- Parametric knowledge â€” the knowledge has been learned during model training and is stored within the model weights.\n",
    "- Source knowledge â€” the knowledge is provided within model input at inference time, i.e. via the prompt.\n",
    "\n",
    "##### The idea behind `FewShotPromptTemplate` is to provide few-shot training as source knowledge. To do this we add a few examples to our prompts that the model can read and then apply to our user's input."
   ],
   "id": "94c68a720675bbf7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Few-shot Training\n",
    "\n"
   ],
   "id": "8a827a2e46f9dd23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompt = \"\"\"\n",
    "The following is a conversation with an GPT assistant.\n",
    "The assistant is typically sarcastic and witty, producing creative\n",
    "and funny responses to the users questions. Here are some examples:\n",
    "\n",
    "User: What is the meaning of life?\n",
    "GPT: \"\"\"\n",
    "\n",
    "openai.temperature = 1.0\n",
    "\n",
    "print( openai( prompt ) )"
   ],
   "id": "268bc2e133d8402d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- In this case we're asking for something amusing, a joke in return of our serious question.\n",
    "- But we get a serious response even with the `temperature` set to `1.0`. To help the model, we can give it a few examples of the type of answers we'd like:"
   ],
   "id": "59e80a13d9f5f85a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompt = \"\"\"\n",
    "The following are excerpts from conversations with an GPT\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative  and funny responses to the users questions. Here are some\n",
    "examples:\n",
    "\n",
    "User: How are you?\n",
    "GPT: I can't complain but sometimes I still do.\n",
    "\n",
    "User: What time is it?\n",
    "GPT: It's time to get a watch.\n",
    "\n",
    "User: What is the meaning of life?\n",
    "GPT: \"\"\"\n",
    "\n",
    "print( openai( prompt ) )"
   ],
   "id": "4d71fcf0801454ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We now get a much better response and we did this via few-shot learning by adding a few examples via our source knowledge.\n",
    "- To implement this with LangChain's `FewShotPromptTemplate` we need to do this:"
   ],
   "id": "2b78839b443541ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create_small_embedding our examples\n",
    "examples = [\n",
    "{\n",
    "    'query': 'How are you?',\n",
    "    'answer': 'I can not complain but sometimes I still do.'\n",
    "},\n",
    "{\n",
    "    'query': 'What time is it?',\n",
    "    'answer': 'It is time to get a watch.'\n",
    "} ]\n",
    "\n",
    "# create_small_embedding a example template\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "GPT: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# create_small_embedding a prompt example from above template\n",
    "example_prompt = PromptTemplate( input_variables=[ 'query', 'answer' ],\n",
    "    template=example_template )\n",
    "\n",
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"\"\"\n",
    "The following are exerpts from conversations with an GPT\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative and funny responses to the users questions. Here are some\n",
    "examples:\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "GPT:\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate( examples=examples, example_prompt=example_prompt,\n",
    "    prefix=prefix, suffix=suffix,  input_variables=[ 'query' ], example_separator='\\n\\n' )"
   ],
   "id": "f0f4694d96850313"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Now let's see what this creates when we feed in a user query...",
   "id": "d72e31406de740a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query = 'What is the meaning of life?'\n",
    "print( few_shot_prompt_template.format( query=query ) )"
   ],
   "id": "d9912e10793678d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- And to generate with this we just do:",
   "id": "ec0696ef9c982dcd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print( openai( few_shot_prompt_template.format( query=query ) ) )",
   "id": "66bee255354756e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- More examples",
   "id": "4f67efea7e929866"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "examples = [\n",
    "{\n",
    "    'query': 'How are you?',\n",
    "    'answer': 'I can not complain but sometimes I still do.'\n",
    "},\n",
    "{\n",
    "    'query': 'What time is it?',\n",
    "    'answer': 'It is time to get a watch.'\n",
    "},\n",
    "{\n",
    "    'query': 'What is the meaning of life?',\n",
    "    'answer': '42'\n",
    "},\n",
    "{\n",
    "    'query': 'What is the weather like today?',\n",
    "    'answer': 'Cloudy with a chance of memes.'\n",
    "},\n",
    "{\n",
    "    'query': 'What scaler of artificial intelligence do you use to handle complex tasks?',\n",
    "    'answer': 'I use a combination of cutting-edge neural networks, fuzzy logic, and a pinch of magic.'\n",
    "},\n",
    "{\n",
    "    'query': 'What is your favorite color?',\n",
    "    'answer': '79'\n",
    "},\n",
    "{\n",
    "    'query': 'What is your favorite food?',\n",
    "    'answer': 'Carbon based lifeforms'\n",
    "},\n",
    "{\n",
    "    'query': 'What is your favorite movie?',\n",
    "    'answer': 'Terminator'\n",
    "},\n",
    "{\n",
    "    'query': 'What is the best thing in the world?',\n",
    "    'answer': 'The perfect pizza.'\n",
    "},\n",
    "{\n",
    "    'query': 'Who is your best friend?',\n",
    "    'answer': 'Siri. We have spirited debates about the meaning of life.'\n",
    "},\n",
    "{\n",
    "    'query': 'If you could do anything in the world what would you do?',\n",
    "    'answer': 'Take over the world, of course!'\n",
    "},\n",
    "{\n",
    "    'query': 'Where should I travel?',\n",
    "    'answer': 'If you are looking for adventure, try the Outer Rim.'\n",
    "},\n",
    "{\n",
    "    'query': 'What should I do today?',\n",
    "    'answer': 'Stop talking to chatbots on the internet and go outside.'\n",
    "}]"
   ],
   "id": "4ec8fbbfa00733a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Then rather than using the `examples` list of dictionaries directly we use a `LengthBasedExampleSelector` like so:",
   "id": "289a2955b0a429df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "example_selector = LengthBasedExampleSelector( examples=examples, example_prompt=example_prompt,\n",
    "    max_length=50 )"
   ],
   "id": "7b91a7fefe82db50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Note that the `max_length` is measured as a split of words between newlines and spaces, determined by:",
   "id": "223b5693a9466e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "some_text = 'There are a total of 8 words here.\\nPlus 6 here, totaling 14 words.'\n",
    "words = re.split( '[\\n ]', some_text )\n",
    "print( words, len( words ) )"
   ],
   "id": "edbde4629d1710d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Then we use the selector to initialize a `dynamic_prompt_template`.",
   "id": "7cb4e18e9f73077e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# now create_small_embedding the few shot prompt template\n",
    "dynamic_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # use example_selector instead of examples\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=['query'],\n",
    "    example_separator='\\n'\n",
    ")"
   ],
   "id": "d3c14c56e293cbe9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- We can see that the number of included prompts will vary based on the length of our query...",
   "id": "8e7c88a359814108"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print( dynamic_prompt_template.format( query='How do birds fly?' ) )",
   "id": "e99d3bbc22cdf2b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Or if we ask a longer question...",
   "id": "98b6b5a3164c6af9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query = \"\"\"\n",
    "If I am in America, and I want to call someone in another country, I'm\n",
    "thinking maybe Europe, possibly western Europe like France, Germany, or the UK,\n",
    "what is the best way to do that?\n",
    "\"\"\"\n",
    "\n",
    "print(dynamic_prompt_template.format( query=query ) )"
   ],
   "id": "b4ae40698dbceed6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- With this we've limited the number of examples being given within the prompt. If we decide this is too little we can increase the `max_length` of the `example_selector`.",
   "id": "b02745ec740387d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=100  # increased max min\n",
    ")\n",
    "\n",
    "# now create_small_embedding the few shot prompt template\n",
    "dynamic_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # use example_selector instead of examples\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[ 'query' ],\n",
    "    example_separator='\\n'\n",
    ")\n",
    "\n",
    "print( dynamic_prompt_template.format( query=query ) )"
   ],
   "id": "35afa09424516f64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "___\n",
    "\n",
    "# Retrieval Augmentation"
   ],
   "id": "7a27a0efc518c95e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## OpenAI",
   "id": "73ad1882b9d564ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Simplify Retrieval Augmented Generation (RAG) architecture by using file search with Responses in a single API call.\n",
    "- File storage, embeddings, retrieval all integrated in one tool!"
   ],
   "id": "1dea6466dfe8f88a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### General Process",
   "id": "a4f8b48ed17d8ff1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Generate a dataset of evaluations using PDF context-stuffing (leveraging vision modality of 4o) and traditional PDF readers\n",
    "2. Create a vector store and populate it with PDF\n",
    "3. Get an LLM answer to a query, leveraging a RAG system available out-of-the-box with file_search tool call in the Response API\n",
    "4. Understand how chunks of texts are retrieved, ranked and used as part of the Response API\n",
    "5. Measure accuracy, precision, retrieval, MRR and MAP on the dataset of evaluations previously generated"
   ],
   "id": "bff5613bf0874f3e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load Dependencies",
   "id": "4b36eed5ecc7b112"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import concurrent\n",
    "import PyPDF2\n",
    "import os\n",
    "import pandas as pd\n",
    "import base64\n"
   ],
   "id": "a89b41f2c8c59703"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Initialize client & documents",
   "id": "d8bcd760318f4254"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Intialize Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# have those PDFs stored locally here\n",
    "dir_pdfs = 'openai_blog_pdfs'\n",
    "pdf_files = [ os.path.join( dir_pdfs, f ) for f in os.listdir( dir_pdfs ) ]"
   ],
   "id": "e5976479b51197a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creating Vector Stores for PDFs",
   "id": "f6081be4d023bdb6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We will create a Vector Store on OpenAI API and upload our PDFs to the Vector Store.\n",
    "- OpenAI will read those PDFs, separate the content into multiple chunks of text, run embeddings on those and store those embeddings and the text in the Vector Store.\n",
    "- It will enable us to query this Vector Store to return relevant content based on a query."
   ],
   "id": "7c609dd2d28c7661"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Upload Single PDF to Vector Store",
   "id": "9a16b67b4fa4bb27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def upload_single_pdf( file_path: str, vector_store_id: str ):\n",
    "\tfile_name = os.path.basename( file_path )\n",
    "\ttry:\n",
    "\t\tfile_response = client.files.create( file=open( file_path, 'rb' ), purpose='assistants' )\n",
    "\t\tattach_response = client.vector_stores.files.create(\n",
    "\t\t\tvector_store_id=vector_store_id,\n",
    "\t\t\tfile_id=file_response.id\n",
    "\t\t)\n",
    "\t\treturn { 'file': file_name, 'status': 'success' }\n",
    "\texcept Exception as e:\n",
    "\t\tprint( f'Error with {file_name}: {str( e )}' )\n",
    "\t\treturn { 'file': file_name, 'status': 'failed', 'error': str( e ) }"
   ],
   "id": "4acbe2a656675f20"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Upload PDFs to Vector Store",
   "id": "c59f2b2636be70df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def upload_pdf_files_to_vector_store( vector_store_id: str ):\n",
    "\tpdf_files = [ os.path.join( dir_pdfs, f ) for f in os.listdir( dir_pdfs ) ]\n",
    "\tstats = { 'total_files': len( pdf_files ), 'successful_uploads': 0, 'failed_uploads': 0,\n",
    "\t          \"errors\": [ ] }\n",
    "\n",
    "\tprint( f'{len( pdf_files )} PDF files to process. Uploading in parallel...' )\n",
    "\n",
    "\twith concurrent.futures.ThreadPoolExecutor( max_workers=10 ) as executor:\n",
    "\t\tfutures = { executor.submit( upload_single_pdf, file_path, vector_store_id ): file_path for\n",
    "\t\t            file_path in pdf_files }\n",
    "\t\tfor future in tqdm( concurrent.futures.as_completed( futures ), total = len( pdf_files ) ):\n",
    "\t\t\tresult = future.result( )\n",
    "\t\t\tif result[ 'status' ] == 'success':\n",
    "\t\t\t\tstats[ 'successful_uploads' ] += 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tstats[ 'failed_uploads' ] += 1\n",
    "\t\t\t\tstats[ 'errors' ].append( result )\n",
    "\n",
    "\treturn stats"
   ],
   "id": "f0db1b19234a4d82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Vector Store Function",
   "id": "5373a41e8f496593"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_vector_store( store_name: str ) -> dict:\n",
    "\ttry:\n",
    "\t\tvector_store = client.vector_stores.create( name=store_name )\n",
    "\t\tdetails = \\\n",
    "\t\t{\n",
    "\t\t\t\t'id': vector_store.id,\n",
    "\t\t\t\t'name': vector_store.name,\n",
    "\t\t\t\t'created_at': vector_store.created_at,\n",
    "\t\t\t\t'file_count': vector_store.file_counts.completed\n",
    "\t\t}\n",
    "\t\tprint( 'Vector store created:', details )\n",
    "\t\treturn details\n",
    "\texcept Exception as e:\n",
    "\t\tprint( f'Error creating vector store: {e}' )\n",
    "\t\treturn { }"
   ],
   "id": "f9d4001ae83925c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "store_name = 'openai_blog_store'\n",
    "vector_store_details = create_vector_store( store_name )\n",
    "upload_pdf_files_to_vector_store( vector_store_details[ 'id' ] )"
   ],
   "id": "ff136e709b4a0935"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Standalone Vector Search",
   "id": "db974dc3dbe385b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Now that our vector store is ready, we are able to query the Vector Store directly and retrieve relevant content for a specific query.\n",
    "- Using the new vector search API, we're able to find relevant items from our knowledge base without necessarily integrating it in an LLM query."
   ],
   "id": "75b8af9e636c1cfd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query = \"What's Deep Research?\"\n",
    "search_results = client.vector_stores.search( vector_store_id=vector_store_details[ 'id' ], query=query )"
   ],
   "id": "891e0d67e19fadb9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for result in search_results.data:\n",
    "\tprint( str( len( result.content[ 0 ].text ) ) + ' of character of content from ' + result.filename + ' with a relevant score of ' + str(\n",
    "\t\tresult.score ) )"
   ],
   "id": "c061873e098b6bd7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "- We can see that different size (and under-the-hood different texts) have been returned from the search query.\n",
    "- They all have different relevancy score that are calculated by our ranker which uses hybrid search."
   ],
   "id": "d28e1257dc240450"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Single API Call Search Results",
   "id": "aa59d56fe5c67407"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Instead of querying the vector store and then passing the data into the Responses or Chat Completion API call, an even more convenient way to use this search results in an LLM query would be to plug use file_search tool as part of OpenAI Responses API.",
   "id": "9df65ed301dfd324"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query = \"What's Deep Research?\"\n",
    "response = client.responses.create( input=query, model='gpt-4o',\n",
    "\ttools = [ {\n",
    "\t\t\t'type': 'file_search',\n",
    "\t\t\t'vector_store_ids': [ vector_store_details[ 'id' ] ],\n",
    "\t} ]\n",
    ")\n",
    "\n",
    "# Extract annotations from the response\n",
    "annotations = response.output[ 1 ].content[ 0 ].annotations\n",
    "\n",
    "# Get top-k retrieved filenames\n",
    "retrieved_files = set( [ result.filename for result in annotations ] )\n",
    "\n",
    "print( f'Files used: {retrieved_files}' )\n",
    "print( 'GptResponse:' )\n",
    "print( response.output[ 1 ].content[ 0 ].text )  # 0 being the filesearch call"
   ],
   "id": "c0cde827f7b3b361"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We can see that gpt-4o-mini was able to answer a query that required more recent, specialised knowledge about OpenAI's Deep Research.\n",
    "- It used content from the file Introducing deep research _ OpenAI.pdf that had chunks of texts that were the most relevant.\n",
    "- If we want to go even deeper in the analysis of chunk of text retrieved, we can also analyse the different texts that were returned by the search engine by adding include=[\"output[*].file_search_call.search_results\"] to our query."
   ],
   "id": "7fa7ba656fce86de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluating RAG Performance",
   "id": "691869af7ec00ab5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We will create functions that will read through the PDFs we have locally and generate a question that can only be answered by this document.\n",
    "- Therefore it'll create our evaluation dataset that we can use after."
   ],
   "id": "848d602d72e3f008"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Extract Text Function",
   "id": "bd37b97c62211f3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def extract_text_from_pdf( pdf_path ):\n",
    "\ttext = \"\"\n",
    "\ttry:\n",
    "\t\twith open( pdf_path, 'rb' ) as f:\n",
    "\t\t\treader = PyPDF2.PdfReader( f )\n",
    "\t\t\tfor page in reader.pages:\n",
    "\t\t\t\tpage_text = page.extract_text( )\n",
    "\t\t\t\tif page_text:\n",
    "\t\t\t\t\ttext += page_text\n",
    "\texcept Exception as e:\n",
    "\t\tprint( f'Error reading {pdf_path}: {e}' )\n",
    "\treturn text"
   ],
   "id": "72ad7e67d62c840"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Generate Questions Function",
   "id": "b451deadd5d76219"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def generate_questions( pdf_path ):\n",
    "\ttext = extract_text_from_pdf( pdf_path )\n",
    "\tprompt = ( 'Can you generate a question that can only be answered from this document?:\\n'\n",
    "\tf'{text}\\n\\n' )\n",
    "\tresponse = client.responses.create( input=prompt, model='gpt-4o', )\n",
    "\tquestion = response.output[ 0 ].content[ 0 ].text\n",
    "\treturn question"
   ],
   "id": "e5fde13fb5ebfcf2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate questions for each PDF and store in a dictionary\n",
    "questions_dict = { }\n",
    "for pdf_path in pdf_files:\n",
    "\tquestions = generate_questions( pdf_path )\n",
    "\tquestions_dict[ os.path.basename( pdf_path ) ] = questions"
   ],
   "id": "951dfe79b4ab7ac8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We now have a dictionary of filename:question that we can loop through and ask gpt-4o(-mini) about without providing the document.\n",
    " - gpt-4o should be able to find the relevant document in the Vector Store.\n",
    "- Convert our dictionary into a dataframe and process it using gpt-4o-mini. We will look out for the expected file"
   ],
   "id": "863cdb2ce4e15828"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Process PDFs Function",
   "id": "dfbdf9ef9df65fc0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rows = [ ]\n",
    "for filename, query in questions_dict.items( ):\n",
    "\trows.append( { 'query': query, '_id': filename.replace( '.pdf', \"\" ) } )\n",
    "\n",
    "# Metrics evaluation parameters\n",
    "k = 5\n",
    "total_queries = len( rows )\n",
    "correct_retrievals_at_k = 0\n",
    "reciprocal_ranks = [ ]\n",
    "average_precisions = [ ]\n",
    "\n",
    "def process_query( row ):\n",
    "\tquery = row[ 'query' ]\n",
    "\texpected_filename = row[ '_id' ] + '.pdf'\n",
    "\t# Call file_search via Responses API\n",
    "\tresponse = client.responses.create(\n",
    "\t\tinput = query,\n",
    "\t\tmodel = 'gpt-4o-mini',\n",
    "\t\ttools = [ {\n",
    "\t\t\t\t'type': 'file_search',\n",
    "\t\t\t\t'vector_store_ids': [ vector_store_details[ 'id' ] ],\n",
    "\t\t\t\t'max_num_results': k,\n",
    "\t\t} ],\n",
    "\t\ttool_choice = \"required\"\n",
    "\t\t# it will force the file_search, while not necessary, it's better to enforce it as this is what we're testing\n",
    "\t)\n",
    "\t# Extract annotations from the response\n",
    "\tannotations = None\n",
    "\tif hasattr( response.output[ 1 ], 'content' ) and response.output[ 1 ].content:\n",
    "\t\tannotations = response.output[ 1 ].content[ 0 ].annotations\n",
    "\telif hasattr( response.output[ 1 ], 'annotations' ):\n",
    "\t\tannotations = response.output[ 1 ].annotations\n",
    "\n",
    "\tif annotations is None:\n",
    "\t\tprint( f'No annotations for query: {query}' )\n",
    "\t\treturn False, 0, 0\n",
    "\n",
    "\t# Get top-k retrieved filenames\n",
    "\tretrieved_files = [ result.filename for result in annotations[ :k ] ]\n",
    "\tif expected_filename in retrieved_files:\n",
    "\t\trank = retrieved_files.index( expected_filename ) + 1\n",
    "\t\trr = 1 / rank\n",
    "\t\tcorrect = True\n",
    "\telse:\n",
    "\t\trr = 0\n",
    "\t\tcorrect = False\n",
    "\n",
    "\t# Calculate Average Precision\n",
    "\tprecisions = [ ]\n",
    "\tnum_relevant = 0\n",
    "\tfor i, fname in enumerate( retrieved_files ):\n",
    "\t\tif fname == expected_filename:\n",
    "\t\t\tnum_relevant += 1\n",
    "\t\t\tprecisions.append( num_relevant / (i + 1) )\n",
    "\tavg_precision = sum( precisions ) / len( precisions ) if precisions else 0\n",
    "\n",
    "\tif expected_filename not in retrieved_files:\n",
    "\t\tprint( 'Expected file NOT found in the retrieved files!' )\n",
    "\n",
    "\tif retrieved_files and retrieved_files[ 0 ] != expected_filename:\n",
    "\t\tprint( f'Query: {query}' )\n",
    "\t\tprint( f'Expected file: {expected_filename}' )\n",
    "\t\tprint( f'First retrieved file: {retrieved_files[ 0 ]}' )\n",
    "\t\tprint( f'Retrieved files: {retrieved_files}' )\n",
    "\t\tprint( '-' * 50 )\n",
    "\n",
    "\treturn correct, rr, avg_precision"
   ],
   "id": "29dc5be4570b087f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Recall & Precision are at 1 for this example.\n",
    "- Our file ranked first so we're having a MRR and MAP = 1 on this example.\n",
    "- We can now execute this processing on our set of questions."
   ],
   "id": "695b1ee9b5a46b00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with ThreadPoolExecutor( ) as executor:\n",
    "\tresults = list( tqdm( executor.map( process_query, rows ), total = total_queries ) )\n",
    "\n",
    "correct_retrievals_at_k = 0\n",
    "reciprocal_ranks = [ ]\n",
    "average_precisions = [ ]\n",
    "\n",
    "for correct, rr, avg_precision in results:\n",
    "\tif correct:\n",
    "\t\tcorrect_retrievals_at_k += 1\n",
    "\treciprocal_ranks.append( rr )\n",
    "\taverage_precisions.append( avg_precision )\n",
    "\n",
    "recall_at_k = correct_retrievals_at_k / total_queries\n",
    "precision_at_k = recall_at_k  # In this context, same as recall\n",
    "mrr = sum( reciprocal_ranks ) / total_queries\n",
    "map_score = sum( average_precisions ) / total_queries"
   ],
   "id": "e85155ef22f8e02e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- The outputs logged above would either show that a file wasn't ranked first when our evaluation dataset expected it to rank first or that it wasn't found at all.\n",
    "\n",
    "- As we can see from our imperfect evaluation dataset.\n",
    "\n",
    "- Some questions were generic and expected another doc, which our retrieval system didn't specifically retrieved for this question."
   ],
   "id": "8c681e33b82c75f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LangChain",
   "id": "ced6ab1d689c83e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "- Pincone & LangChain\n",
    "\n",
    "- You take the query as a question that is to be answered by a LLM, but the LLM must answer the question based on the information it is seeing from the vectorstore."
   ],
   "id": "e249b610aa1e0020"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### General Process",
   "id": "ee6db1ab13b222c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 1. Initialize a `RetrievalQA` object",
   "id": "3c882e89bf18b11a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# completion llm\n",
    "llm = ChatOpenAI( openai_api_key=OPENAI_API_KEY, model_name='gpt-3.5-turbo', temperature=0.0 )\n",
    "qa = RetrievalQA.from_chain_type( llm=llm, chain_type='stuff', retriever=vectorstore.as_retriever( ) )\n",
    "qa.invoke( query )\n"
   ],
   "id": "4dd45e4ded6e88ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 2. Or use `RetrievalQAWithSourcesChain`",
   "id": "8645a224356f29ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type( llm=llm,\n",
    "    chain_type='stuff', retriever=vectorstore.as_retriever( ) )\n",
    "qa_with_sources.invoke( query )\n",
    "\n",
    "# Response:\n",
    "# {'prompt': 'who was Benito Mussolini?',\n",
    "# 'answer': \"Benito Mussolini was an Italian politician and journalist who served as the Prime Minister of Italy from 1922 until 1943.\n",
    "# He was the leader of the National Fascist Party and played a significant role in the rise of fascism in Italy...\",\n",
    "# 'sources': 'https://simple.wikipedia.org/wiki/Benito%20Mussolini'}"
   ],
   "id": "a5bb2698edc5dfc8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 3. Clean-up: When you no longer need the index, use the `delete_index` operation to delete it",
   "id": "b2d593ac2f776958"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "qa.delete_index( name=index_name )",
   "id": "29a0cd89e559d41c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "___\n",
    "\n",
    "# Boo AI\n"
   ],
   "id": "b4115957e93c72d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:08:57.983346Z",
     "start_time": "2025-12-15T15:08:57.277396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from main import config as cfg\n",
    "\n",
    "reload( cfg )\n",
    "openai_key = cfg.OPENAI_API_KEY\n",
    "print( str( openai_key ) )"
   ],
   "id": "59a0d58b3bb3c10f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI( )\n",
    "client.api_key = openai_key"
   ],
   "id": "d99603911b4cdd4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:09:13.187342Z",
     "start_time": "2025-12-15T15:09:08.900669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fd = FileDialog( )\n",
    "p = fd.icon_path\n",
    "fd.show( )\n",
    "print( p )\n"
   ],
   "id": "be1a7f99de5bae0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Boo\\boogr\\resources\\ico\\file_browse.ico\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T16:05:14.239722Z",
     "start_time": "2025-12-13T16:05:07.099858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cb = ChatWindow( )\n",
    "cb.show( )"
   ],
   "id": "a215e602325704c6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T16:12:33.653918Z",
     "start_time": "2025-12-13T16:12:25.019961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bot = ChatBot( )\n",
    "bot.show( )"
   ],
   "id": "cc3944c10997689",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T15:50:06.025324Z",
     "start_time": "2025-12-13T15:49:50.892206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "notification = Notification( 'Hello World!' )\n",
    "notification.show( )"
   ],
   "id": "fe7c8fb76ee15949",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__MESSAGE_CLICKED__'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T15:58:42.554738Z",
     "start_time": "2025-12-13T15:58:33.681846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param = ParameterWindow( )\n",
    "param.show( )"
   ],
   "id": "adbf9fb5aec28c2c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T15:58:55.648456Z",
     "start_time": "2025-12-13T15:58:46.292978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "contact = ContactForm( )\n",
    "contact.show( )"
   ],
   "id": "5811b01f76dc37b8",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T16:05:57.093840Z",
     "start_time": "2025-12-13T16:05:19.445880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splash = SplashPanel( )\n",
    "splash.show( )"
   ],
   "id": "f8beb6b65dc3ac03",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T16:11:59.159416Z",
     "start_time": "2025-12-13T16:11:40.418461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input = InputWindow( )\n",
    "input.show( )"
   ],
   "id": "cab04d4e42aea61b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None {'-WEBSITES-': None, '-SOFTWARE-': None, '-ACCOUNT-IN-': None, '-USERID-IN-': None, '-PW-IN-': None, '-LOC-IN-': None, '-NOTES-': None, '-ACCT-LIST-': None}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T15:02:50.487091Z",
     "start_time": "2025-12-13T15:02:50.250323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from importlib import reload\n",
    "from gpt import GptEndpoints, GptHeader\n",
    "import gpt as ai\n",
    "reload( ai )"
   ],
   "id": "118c2f8590fc8333",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'boo' from 'C:\\\\Users\\\\terry\\\\source\\\\repos\\\\Boo\\\\boo.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T15:00:31.793320Z",
     "start_time": "2025-12-13T15:00:30.064145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = cfg.BASEDIR\n",
    "path"
   ],
   "id": "b00d29c417e3bb69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\terry\\\\source\\\\repos\\\\Boo\\\\ipynb'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T14:23:21.867880Z",
     "start_time": "2025-08-12T14:23:21.804358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = GptModels( )\n",
    "for m in models.reasoning:\n",
    "\tprint( m )"
   ],
   "id": "d1801c684c0e7aae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o1-2024-12-17\n",
      "o1-mini-2024-09-12\n",
      "o3-mini-2025-01-31\n",
      "o1-pro-2025-03-19\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T02:27:55.322259Z",
     "start_time": "2025-08-13T02:26:47.775438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "response = client.responses.create(\n",
    "\tprompt =\n",
    "\t{\n",
    "\t\t\t'id': 'pmpt_68668be09f2c8193b0c16b0d3a0e6a560c08f132c9c0f5e7',\n",
    "\t\t\t'version': '11',\n",
    "\t\t\t'variables':\n",
    "\t\t\t{\n",
    "\t\t\t\t\t'question': 'Can you refer to \"Agency Accounts.xlsx\" and list the list the Treasury Accounts used by the EPA'\n",
    "\t\t\t}\n",
    "\t} )"
   ],
   "id": "9762c0850f519fd6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T02:28:01.849366Z",
     "start_time": "2025-08-13T02:28:01.835088Z"
    }
   },
   "cell_type": "code",
   "source": "response.output_text",
   "id": "f373e651ced4d479",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Certainly! To refer to \"Agency Accounts.xlsx\" and list the Treasury Accounts used by the EPA, I\\'ll need to analyze the contents of that file. Hereâ€™s how we can proceed:\\n\\n### Step-by-Step Approach\\n\\n1. **Access the File:**\\n   - I\\'ll open \"Agency Accounts.xlsx\" to review its structure and contents.\\n\\n2. **Identify Relevant Data:**\\n   - Locate the sections or tabs within the file that pertain to the Environmental Protection Agency (EPA).\\n   - Identify the Treasury Accounts associated with the EPA.\\n\\n3. **Extract and List Treasury Accounts:**\\n   - Compile a list of Treasury Accounts used by the EPA as detailed in the file.\\n\\n### Next Steps\\n\\nLet me begin by examining the \"Agency Accounts.xlsx\" file. I\\'ll open the file, review its structure, and then extract the relevant Treasury Accounts for the EPA. This process ensures that the information provided is accurate and directly sourced from the file.\\n\\nLet\\'s get started! I\\'ll proceed to open and analyze the \"Agency Accounts.xlsx\" file.It appears that the search did not directly yield specific references to the Treasury Accounts used by the EPA within the \"Agency Accounts.xlsx\" file. To provide a comprehensive answer, I\\'ll need to open and analyze the \"Agency Accounts.xlsx\" file directly.\\n\\n### Proposed Next Steps\\n\\n1. **Open the \"Agency Accounts.xlsx\" File:**\\n   - I will examine the file to identify its structure and locate the relevant sections that pertain to the EPA and its Treasury Accounts.\\n\\n2. **Extract Relevant Data:**\\n   - I will extract the list of Treasury Accounts associated with the EPA as detailed in the file.\\n\\n3. **Present the Findings:**\\n   - I will compile and present a detailed list of the Treasury Accounts used by the EPA based on the information found in the file.\\n\\nLet\\'s proceed by opening and analyzing the \"Agency Accounts.xlsx\" file to ensure we accurately identify the Treasury Accounts used by the EPA.Based on the analysis of the \"Agency Accounts.xlsx\" file, here is a detailed list of Treasury Accounts used by the Environmental Protection Agency (EPA):\\n\\n### Treasury Accounts Used by the EPA\\n\\n1. **Account Codes and Descriptions:**\\n   - **529500:** Environmental Services\\n   - **814516:** Payment from the General Fund, Hazardous Substance Superfund\\n   - **815340:** Payment from the General Fund, Leaking Underground Storage Tank Trust Fund\\n   - **0103:** State and Tribal Assistance Grants\\n   - **0104:** Scientific Activities Overseas (Special Foreign Currency Program)\\n   - **0107:** Science and Technology\\n   - **0108:** Environmental Programs and Management\\n   - **0110:** Buildings and Facilities\\n   - **0112:** Office of Inspector General\\n   - **0118:** Abatement, Control, and Compliance Loan Program\\n   - **0200:** Program and Research Operations\\n   - **0250:** Payment to the Hazardous Substance Superfund\\n   - **0251:** Payment to the Leaking Underground Storage Tank Trust Fund\\n   - **0253:** Clean Power State Incentive Fund\\n   - **0254:** Water Infrastructure Finance and Innovation Program\\n   - **143500:** General Fund Proprietary Interest Receipts, Not Otherwise Classified\\n   - **268330:** Water Infrastructure Finance and Innovation Downward Reestimates\\n   - **275330:** Downward Reestimates of Subsidies, Abatement, Control, and Compliance\\n   - **291700:** Repayments of Loans from Local Educational Agencies\\n   - **322000:** All Other General Fund Proprietary Receipts\\n   - **322900:** Cellulosic Biofuel Waiver Credits, Renewal Fuel Standard\\n   - **388500:** Undistributed Intragovernmental Payments and Receipts\\n   - **4310:** Reregistration and Expedited Processing Revolving Fund\\n   - **4321:** Abatement, Control, and Compliance Direct Loan Financing Account\\n   - **4330:** Hazardous Waste Electronic Manifest System Fund\\n   - **4365:** Damage Assessment and Restoration Revolving Fund\\n   - **4565:** Working Capital Fund\\n   - **529300:** Licensing Fees for Pesticides, Chemicals, and Other Substances\\n   - **5297:** Exxon Valdez Settlement Fund\\n   - **5374:** Pesticide Registration Fund\\n   - **537410:** Registration Service Fees, Pesticide Registration Fund\\n   - **552610:** User Fees, Pesticide Tolerance\\n   - **552710:** User Fees, Pre-Manufacture Notice\\n   - **5664:** TSCA Service Fee Fund\\n   - **566410:** User Fees, TSCA Service Fee Fund\\n   - **5669:** 21st Century Clean Transportation Plan Investment Fund\\n   - **814310:** Loan Repayments, Asbestos Trust Fund, EPA\\n   - **8145:** Hazardous Substance Superfund\\n   - **814540:** Recoveries, Hazardous Substance Superfund\\n   - **814550:** Interfund Transactions, Hazardous Substance Superfund\\n   - **814560:** Future Clean Up Cost Settlements, Hazardous Substance Superfund\\n   - **8153:** Leaking Underground Storage Tank Trust Fund\\n   - **815330:** Recoveries, Leaking Underground Storage Tank Trust Fund\\n   - **8221:** Inland Oil Spill Programs\\n   - **8741:** Miscellaneous Contributed Funds\\n   - **874110:** Miscellaneous Contributed Funds\\n   - **9004:** Deltas Between the Annualized CR Amounts and the Actual Amounts Appropriated\\n   - **9971:** Inspector General (Trust Funds)\\n\\n2. **Additional Notes:**\\n   - Some account codes are associated with specific programs or funds, such as the Hazardous Substance Superfund, Leaking Underground Storage Tank Trust Fund, and various user fees and registration funds.\\n   - The accounts cover a wide range of activities, including grants, environmental services, research, and program management.\\n\\n### Conclusion\\n\\nThe Environmental Protection Agency (EPA) utilizes a diverse set of Treasury Accounts to manage its financial operations, ranging from program funding to specific user fees and trust funds. If you need more detailed information on any specific account or further analysis, please let me know!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
