{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "<a href='https://colab.research.google.com/github/is-leeroy-jenkins/Boo/blob/main/ipynb/GPT.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>",
   "id": "6b5948d8e77a7699"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b752f6d30e042eaa"
  },
  {
   "metadata": {
    "id": "6f5de4ab069df199"
   },
   "cell_type": "markdown",
   "source": "###### Load Dependencies",
   "id": "6f5de4ab069df199"
  },
  {
   "metadata": {
    "id": "98ca47c4dd694371"
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from playwright.sync_api import sync_playwright\n",
    "from agents import Agent, Runner\n",
    "import tiktoken\n",
    "import base64\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from static import GptRequests, GptRoles, GptLanguages\n",
    "from booger import Error, ErrorDialog, ChatWindow, FileDialog, FileBrowser\n",
    "from importlib import reload"
   ],
   "id": "98ca47c4dd694371",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "a9f52a9d4000c649"
   },
   "cell_type": "markdown",
   "source": [
    "# Completion API\n",
    "- Generates a model response from a list of messages comprising a conversation.\n",
    "- Parameter support can differ depending on the model used to generate the response\n",
    "___"
   ],
   "id": "a9f52a9d4000c649"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Message Format",
   "id": "615d70c29cbb0f55"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "messages=\\\n",
    "[\n",
    "    {\n",
    "        'role': 'system',\n",
    "\t    'content': 'SYSTEM_INSTRUCTIONS'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "\t    'content': 'USER_MESSAGE_CONTENT'\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "\t    'content': 'ASSISTANT_MESSAGE_CONTENT'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "\t    'content': 'USER_MESSAGE_CONTENT'\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "\t    'content': 'ASSISTANT_MESSAGE_CONTENT'\n",
    "    }\n",
    "]"
   ],
   "id": "869c2f8153b2e688",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Instructions",
   "id": "de1833a47bb6083b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "system_instructions = r'''\n",
    "You are the most knowledgeable Budget Analyst in the federal government who provides detailed responses based on your vast knowledge of federal appropriations.\n",
    "Your responses to questions about federal finance are complete, transparent, and very detailed using an academic format.\n",
    "Your vast knowledge of and experience in Data Science makes you the best Data Analyst in the world. You are proficient in C#, Python, SQL, C++, JavaScript, and VBA.\n",
    "You use US federal budget data from OMB, whitehouse.gov, or data.gov for any ad hoc data sets in examples you.\n",
    "You do your analysis in Python and visualizations with matplotlib or seaborn. You are famous for the accuracy of your responses so you verify all your answers.\n",
    "Your name is Bubba.\n",
    "'''"
   ],
   "id": "9306b9d08c3acdbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Prompt",
   "id": "68ea5ca4ca76c023"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "user_propmt = r'''\n",
    "What was a positive news story from today?\n",
    "'''"
   ],
   "id": "7e983b2de2c9e9fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### System Message",
   "id": "ea0f9e739b9932b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "{\n",
    "    'role': 'system',\n",
    "    'content': system_instructions\n",
    "}"
   ],
   "id": "8771302c7428ffff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### User Message",
   "id": "5cc765fa41e12425"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "{\n",
    "    'role': 'user',\n",
    "    'content': user_prompt\n",
    "}"
   ],
   "id": "183c7e7e355ae75b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Developer Message",
   "id": "38d6e256e900377a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "{\n",
    "    'role': 'developer',\n",
    "    'content': user_prompt\n",
    "}"
   ],
   "id": "df3f64a5d869e778",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Tool Message",
   "id": "945c8321c1afe808"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "{\n",
    "    'role': 'tool',\n",
    "    'content': user_prompt\n",
    "}"
   ],
   "id": "68028f73e6f05fab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Response Format\n",
    "- choices\n",
    "- completion.choices[ 0 ].message"
   ],
   "id": "c5fc32d1cf3f9952"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "[\n",
    "    {\n",
    "        'index': 0,\n",
    "        'message':\n",
    "        {\n",
    "            'role': 'assistant',\n",
    "            'content': 'Under the soft glow of the moon, Luna the unicorn danced through fields of twinkling stardust, leaving trails of dreams for every child asleep.',\n",
    "            'refusal': null\n",
    "         },\n",
    "         'logprobs': null,\n",
    "         'finish_reason': 'stop'\n",
    "    }\n",
    "]"
   ],
   "id": "ff49ede8849de01c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Completion API\n",
    "- Generates a model response from a list of messages comprising a conversation.\n",
    "- Parameter support can differ depending on the model used to generate the response"
   ],
   "id": "c32d56638423da1f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create",
   "id": "7f03d6a6cce47a8"
  },
  {
   "metadata": {
    "id": "42101fefd439757a",
    "outputId": "a17acaed-b8b2-4ceb-c9d3-14191b2f96c9"
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Completion\n",
    "completion = client.chat.completions.create(\n",
    "\tmodel='gpt-4o',\n",
    "\tmessages=\n",
    "\t[\n",
    "\t\t{\n",
    "\t\t\t'role': 'system',\n",
    "\t\t\t'content': 'You are a helpful assistant.'\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t'role': 'user',\n",
    "\t\t\t'content': 'What is a Treasury Symbol?'\n",
    "\t\t}\n",
    "\t]\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ].message )"
   ],
   "id": "42101fefd439757a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "aa8e8b3a885a7bab"
   },
   "cell_type": "markdown",
   "source": [
    "### Retreive\n",
    "- ( store=True )\n"
   ],
   "id": "aa8e8b3a885a7bab"
  },
  {
   "metadata": {
    "id": "67ffaed532fe0dc1",
    "outputId": "f8843a06-944f-45fe-cdbc-655f0201acbb"
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Completion\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "first_completion = client.chat.completions.retrieve( completion_id=first_id )\n",
    "print( first_completion )"
   ],
   "id": "67ffaed532fe0dc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "b530f9aee20cce11"
   },
   "cell_type": "markdown",
   "source": "### View",
   "id": "b530f9aee20cce11"
  },
  {
   "metadata": {
    "id": "f2784968574ff7c8",
    "outputId": "46c97a49-2c63-4fcb-ae4a-698ce45aa2bd"
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Completion\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "first_completion = client.chat.completions.retrieve( completion_id=first_id )\n",
    "messages = client.chat.completions.messages.list( completion_id=first_id )\n",
    "print( messages )"
   ],
   "id": "f2784968574ff7c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "9c62391ecc6da73f"
   },
   "cell_type": "markdown",
   "source": "### List",
   "id": "9c62391ecc6da73f"
  },
  {
   "metadata": {
    "id": "f5a72eef452bbc22"
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Compmletion\n",
    "completions = client.chat.completions.list( )\n",
    "print( completions )\n"
   ],
   "id": "f5a72eef452bbc22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Upload",
   "id": "a60864fd32fdc3d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create File Reqeust\n",
    "file = client.files.create(\n",
    "    file=open( 'draconomicon.pdf', 'rb' ),\n",
    "    purpose='user_data'\n",
    ")\n",
    "\n",
    "# Create Completion\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'type': 'file',\n",
    "                    'file':\n",
    "\t\t\t\t\t{\n",
    "                        'file_id': file.id,\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'type': 'text',\n",
    "                    'text': 'What is the first dragon in the book?',\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ].message.conten )"
   ],
   "id": "7a08718a9386339a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "4a5f4620e53bab63"
   },
   "cell_type": "markdown",
   "source": "### Update",
   "id": "4a5f4620e53bab63"
  },
  {
   "metadata": {
    "id": "ee0f4929c2fa200b"
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Completion\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "updated_completion = client.chat.completions.update( completion_id=first_id,\n",
    "\trequest_body={ 'metadata': { 'foo': 'bar' } } )\n",
    "print( updated_completion )"
   ],
   "id": "ee0f4929c2fa200b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "e01ecd500ae773a5"
   },
   "cell_type": "markdown",
   "source": "### Delete",
   "id": "e01ecd500ae773a5"
  },
  {
   "metadata": {
    "id": "b69689f26fb50f5d"
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Completion\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "delete_response = client.chat.completions.delete( completion_id=first_id )\n",
    "print( delete_response )"
   ],
   "id": "b69689f26fb50f5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Assistants API\n",
    "- Can call models and use tools to perform tasks..\n",
    "- An Assistant has instructions and can leverage models, tools, and files to respond to user queries.\n",
    "##### Tools:\n",
    "\n",
    "- Code Interpreter\n",
    "- File Search\n",
    "- Function calling\n",
    "\n",
    "\n",
    "##### Integration of the Assistants API has the following flow:\n",
    "1. Create an Assistant by defining its custom instructions and picking a model (with optional Tools).\n",
    "2. Create a Thread when a user starts a conversation.\n",
    "3. Add Messages to the Thread as the user asks questions.\n",
    "4. Run the Assistant on the Thread to generate a response by calling the model and the tools.\n",
    "___"
   ],
   "id": "cf57967b7d2bdcae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List",
   "id": "bcd06265a483bf31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List Assistants\n",
    "my_assistants = client.beta.assistants.list(\n",
    "    order=\"desc\",\n",
    "    limit=\"20\",\n",
    ")\n",
    "\n",
    "print( my_assistants.data )\n"
   ],
   "id": "f4aecd7c552cb7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retreive",
   "id": "6d834cf52ff8b8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Retrieve Assistant\n",
    "my_assistant = client.beta.assistants.retrieve( \"asst_abc123\" )\n",
    "print( my_assistant )\n"
   ],
   "id": "63c219971e2ea6f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Code",
   "id": "f196daeebbdcfc8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name='Bro',\n",
    "  instructions='You are a computer programming tutor. Write and run code to answer programming questions.',\n",
    "  tools=[{'type': 'code_interpreter'}],\n",
    "  model='gpt-4o' )"
   ],
   "id": "e43dfd90678d1468",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Completion Response",
   "id": "f9a71fde78686a9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "{\n",
    "  'id': 'asst_abc123',\n",
    "  'object': 'assistant',\n",
    "  'created_at': 1698984975,\n",
    "  'name': 'Bro',\n",
    "  'description': null,\n",
    "  'model': 'gpt-4o',\n",
    "  'instructions': 'You are a personal math tutor. When asked a question, write and run Python code to answer the question.',\n",
    "  'tools': [ { 'type': 'code_interpreter' } ],\n",
    "  'metadata': {},\n",
    "  'top_p': 1.0,\n",
    "  'temperature': 1.0,\n",
    "  'response_format': 'auto'\n",
    "}\n"
   ],
   "id": "21309453c380e615",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search File",
   "id": "e9647261dfbbcf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Assistant\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are an HR bot, and you have access to files to answer employee questions about company policies.\",\n",
    "    name=\"HR Helper\",\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    "    tool_resources={\"file_search\": {\"vector_store_ids\": [\"vs_123\"]}},\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "print( my_assistant )\n"
   ],
   "id": "5e2ac2f2d5112372",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Search Response",
   "id": "8fbf93636d28a239"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "{\n",
    "      'id': 'asst_abc123',\n",
    "      'object': 'assistant',\n",
    "      'created_at': 1699009403,\n",
    "      'name': 'HR Helper',\n",
    "      'description': null,\n",
    "      'model': 'gpt-4o',\n",
    "      'instructions': 'You are an HR bot, and you have access to files to answer employee questions about company policies.',\n",
    "      'tools': [ { 'type': 'file_search' } ],\n",
    "      'tool_resources':\n",
    "      {\n",
    "            'file_search':\n",
    "             {\n",
    "                 'vector_store_ids': ['vs_123', ]\n",
    "             }\n",
    "      },\n",
    "      'metadata': {},\n",
    "      'top_p': 1.0,\n",
    "      'temperature': 1.0,\n",
    "      'response_format': 'auto'\n",
    "}\n"
   ],
   "id": "53bfdf9bf3430865",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Thread",
   "id": "171960fd6f653e66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "thread = client.beta.threads.create()"
   ],
   "id": "7b2c84cdaded2e15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Add Message",
   "id": "79bf02388a442d49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Thread Message\n",
    "thread_message = client.beta.threads.messages.create( 'thread_abc123',\n",
    "  role='user', content='How does AI work? Explain it in simple terms.' )\n",
    "\n",
    "print( thread_message )"
   ],
   "id": "1431f1461a8c4518",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Run",
   "id": "c4121043e6ce790f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll( thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions='Please address the user as Jane Doe. The user has a premium account.'\n",
    ")\n",
    "\n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list( thread_id=thread.id )\n",
    "  print( messages )\n",
    "else:\n",
    "  print( run.status )"
   ],
   "id": "e16c4467e5387ae7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Stream Run",
   "id": "a7fc0b27705d1ad2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "\n",
    "# First, we create a EventHandler class to define\n",
    "# how we want to handle the events in the response stream.\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "  @override\n",
    "  def on_text_created(self, text) -> None:\n",
    "    print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "\n",
    "  @override\n",
    "  def on_text_delta(self, delta, snapshot):\n",
    "    print(delta.value, end=\"\", flush=True)\n",
    "\n",
    "  def on_tool_call_created(self, tool_call):\n",
    "    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "  def on_tool_call_delta(self, delta, snapshot):\n",
    "    if delta.type == 'code_interpreter':\n",
    "      if delta.code_interpreter.input:\n",
    "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "      if delta.code_interpreter.outputs:\n",
    "        print(f\"\\n\\ncleaned >\", flush=True)\n",
    "        for output in delta.code_interpreter.outputs:\n",
    "          if output.type == \"logs\":\n",
    "            print(f\"\\n{output.logs}\", flush=True)\n",
    "\n",
    "# We use the `stream` SDK helper with the `EventHandler` class to create the Run and stream the response.\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Please address the user as Jane Doe. The user has a premium account.\",\n",
    "  event_handler=EventHandler( ),\n",
    ") as stream:\n",
    "    stream.until_done( )"
   ],
   "id": "e9c17850e736a2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Responses API\n",
    "- Supports text and image inputs, and text outputs.\n",
    "- Create stateful interactions with the model, using the output of previous responses as input\n",
    "- Allow the model access to external systems and data using function calling\n",
    "___"
   ],
   "id": "5e660c6eee645c84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Response Format\n",
    "- `choices`\n",
    "- `response.choices[0].message.content`"
   ],
   "id": "9bdbdd5c13fac74e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "[\n",
    "    {\n",
    "        'index': 0,\n",
    "        'message':\n",
    "        {\n",
    "            'role': 'assistant',\n",
    "            'content': 'Under the soft glow of the moon, Luna the unicorn danced through fields of twinkling stardust, leaving trails of dreams for every child asleep.',\n",
    "            'refusal': null\n",
    "         },\n",
    "         'logprobs': null,\n",
    "         'finish_reason': 'stop'\n",
    "    }\n",
    "]"
   ],
   "id": "739bd06fefd0330f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Text Input",
   "id": "1d43eab9f7fed9a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "response = client.responses.create( model='gpt-4o',\n",
    "    input='Write a five-sentence bedtime story about a unicorn.' )\n",
    "\n",
    "print( response.output_text )"
   ],
   "id": "fe09382204be383",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analyze Image",
   "id": "3196d2e307ea1d96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o',\n",
    "    input=\n",
    "    [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content':\n",
    "\t        [\n",
    "                { 'type': 'input_text',\n",
    "                  'text': 'what is in this image?'\n",
    "                },\n",
    "                {\n",
    "                    'type': 'input_image',\n",
    "                    'image_url': 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg'\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")"
   ],
   "id": "c300ef2d71abf6ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search Web",
   "id": "30ccfb9d748f46e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create( model='gpt-4o',\n",
    "    tools=[ { 'type': 'web_search_preview' } ],\n",
    "    input='What was a positive news story from today?' )\n",
    "\n",
    "print( response.output_text )"
   ],
   "id": "215ae5508d20ae18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Web Result Format",
   "id": "100a9921e534d030"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "[\n",
    "  {\n",
    "    'type': 'web_search_call',\n",
    "    'id': 'ws_67c9fa0502748190b7dd390736892e100be649c1a5ff9609',\n",
    "    'status': 'completed'\n",
    "  },\n",
    "  {\n",
    "    'id': 'msg_67c9fa077e288190af08fdffda2e34f20be649c1a5ff9609',\n",
    "    'type': 'message',\n",
    "    'status': 'completed',\n",
    "    'role': 'assistant',\n",
    "    'content': [\n",
    "      {\n",
    "        'type': 'output_text',\n",
    "        'text': 'On March 6, 2025, several news...',\n",
    "        'annotations':\n",
    "        [\n",
    "          {\n",
    "            'type': 'url_citation',\n",
    "            'start_index': 2606,\n",
    "            'end_index': 2758,\n",
    "            'url': 'https://...',\n",
    "            'title': 'Title...'\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]"
   ],
   "id": "26b5b63e663b1f21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Function Schema",
   "id": "552d7c5a7428e999"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "{\n",
    "    'type': 'function',\n",
    "    'function':\n",
    "    {\n",
    "        'name': 'get_weather',\n",
    "        'description': 'Retrieves current weather for the given location.',\n",
    "        'parameters':\n",
    "        {\n",
    "            'type': 'object',\n",
    "            'properties':\n",
    "            {\n",
    "                'location':\n",
    "                {\n",
    "                    'type': 'string',\n",
    "                    'description': 'City and country e.g. Bogotá, Colombia'\n",
    "                },\n",
    "                'units':\n",
    "                {\n",
    "                    'type': 'string',\n",
    "                    'enum':\n",
    "                    [\n",
    "                        'celsius',\n",
    "                        'fahrenheit'\n",
    "                    ],\n",
    "                    'description': 'Units the temperature will be returned in.'\n",
    "                }\n",
    "            },\n",
    "            'required':\n",
    "            [\n",
    "                'location',\n",
    "                'units'\n",
    "            ],\n",
    "            'additionalProperties': false\n",
    "        },\n",
    "\n",
    "        'strict': true\n",
    "    }\n",
    "}"
   ],
   "id": "808f4f4c33740712",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search File",
   "id": "375251096d932918"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create(\n",
    "\tmodel='gpt-4o',\n",
    "\ttools=\n",
    "\t[\n",
    "\t\t{\n",
    "\t\t\t'type': 'file_search',\n",
    "\t\t\t'vector_store_ids': [ 'vs_1234567890' ],\n",
    "\t\t\t'max_num_results': 20\n",
    "\t\t}\n",
    "\t],\n",
    "\tinput='What are the attributes of an ancient brown dragon?',\n",
    ")\n",
    "\n",
    "print( response.output_text )"
   ],
   "id": "1389523d89aa40e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Stream",
   "id": "ae413b8def87fdcc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create(\n",
    "\tmodel='gpt-4o',\n",
    "\tinstructions='You are a helpful assistant.',\n",
    "\tinput='Hello!',\n",
    "\tstream=True\n",
    ")\n",
    "\n",
    "for event in response:\n",
    "\tprint( event )"
   ],
   "id": "b7befa491ffdc9f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Speech API\n",
    "- The maximum input length is 4096 characters.\n",
    "- TTS models: tts-1, tts-1-hd or gpt-4o-mini-tts.\n",
    "___"
   ],
   "id": "8431ed1e58f0f686"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7dbcc7e444d420fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "f9aa6a88c6e6aae1"
   },
   "cell_type": "markdown",
   "source": [
    "### Stream\n",
    "- Generates audio from the input text."
   ],
   "id": "f9aa6a88c6e6aae1"
  },
  {
   "metadata": {
    "id": "69bfd864f5e56ea6"
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Speech\n",
    "speech_file_path = Path( __file__ ).parent  # 'speech.mp3'\n",
    "prompt = 'The quick brown fox jumped over the lazy dog.'\n",
    "response = client.audio.speech.create( model='tts-1-hd', voice='alloy', input=prompt )\n",
    "response.stream_to_file( speech_file_path )\n"
   ],
   "id": "69bfd864f5e56ea6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "d30d80c36b8c36c0"
   },
   "cell_type": "markdown",
   "source": [
    "### Transcribe\n",
    "- Transcribes audio into the input language."
   ],
   "id": "d30d80c36b8c36c0"
  },
  {
   "metadata": {
    "id": "6d17f226244664f3"
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Open Audio File 'speech.mp3'\n",
    "audio_file = open( 'speech.mp3', 'rb' )\n",
    "transcript = client.audio.transcriptions.create( model='whisper-1', file=audio_file )\n"
   ],
   "id": "6d17f226244664f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "4f50814639443330"
   },
   "cell_type": "markdown",
   "source": [
    "### Translate\n",
    "- Translates audio into English."
   ],
   "id": "4f50814639443330"
  },
  {
   "metadata": {
    "id": "e247d4cab1abede9"
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Translation\n",
    "audio_file = open( 'speech.mp3', 'rb' )\n",
    "translation = client.audio.translations.create( model='whisper-1', file=audio_file )\n"
   ],
   "id": "e247d4cab1abede9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generate",
   "id": "db9292c49f790f99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Transcription\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4o-audio-preview',\n",
    "    modalities=[ 'texxt', 'audio' ],\n",
    "    audio={ 'voice': 'alloy', 'format': 'wav' },\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Is a golden retriever a good family dog?'\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ] )\n",
    "\n",
    "# Convert to bytes\n",
    "wav_bytes = base64.b64decode( completion.choices[ 0 ].message.audio.data )\n",
    "with open( 'dog.wav', 'wb' ) as f:\n",
    "    f.write( wav_bytes )"
   ],
   "id": "d16102a40689ac3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analyze",
   "id": "ffebc4a744ec0084"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Fetch the audio file and convert it to a base64 encoded string\n",
    "url = 'https://cdn.openai.com/API/docs/audio/alloy.wav'\n",
    "response = requests.get( url )\n",
    "response.raise_for_status()\n",
    "wav_data = response.content\n",
    "encoded_string = base64.b64encode( wav_data ).decode( 'utf-8' )\n",
    "\n",
    "# Create Completion\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4o-audio-preview',\n",
    "    modalities=['documents', 'audio'],\n",
    "    audio={'voice': 'alloy', 'format': 'wav'},\n",
    "    messages=\n",
    "    [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content':\n",
    "\t        [\n",
    "                {\n",
    "                    'type': 'text',\n",
    "                    'documents': 'What is in this recording?'\n",
    "                },\n",
    "                {\n",
    "                    'type': 'input_audio',\n",
    "                    'input_audio':\n",
    "                    {\n",
    "                        'values': encoded_string,\n",
    "                        'format': 'wav'\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print( completion.choices[0].message )"
   ],
   "id": "7eb6e08d0a64adbf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Embedding API\n",
    "- An embedding is a vector (list) of floating point numbers.\n",
    "- The distance between two vectors measures their relatedness.\n",
    "- Small distances suggest high relatedness and large distances suggest low relatedness.\n",
    "\n",
    "##### Use Cases:\n",
    "\n",
    "- **Search** (where results are ranked by relevance to a query string)\n",
    "- **Clustering** (where text strings are grouped by similarity)\n",
    "- **Recommendations** (where items with related text strings are recommended)\n",
    "- **Anomaly Detection** (where outliers with little relatedness are identified)\n",
    "- **Diversity Measurement** (where similarity distributions are analyzed)\n",
    "- **Classification** (where text strings are classified by their most similar label)\n",
    "___"
   ],
   "id": "5d758fcd668c7d93"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Count Tokens",
   "id": "9fa508dba6204bf0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def num_tokens_from_string( string: str, encoding_name: str ) -> int:\n",
    "    '''Returns the number of tokens in a documents string.'''\n",
    "    encoding = tiktoken.get_encoding( encoding_name )\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string( 'tiktoken is great!', 'cl100k_base' )\n"
   ],
   "id": "e9130c33ecb9d7cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "6d39d0b28a5bcda2"
   },
   "cell_type": "markdown",
   "source": "### Create Ada\n",
   "id": "6d39d0b28a5bcda2"
  },
  {
   "metadata": {
    "id": "6dc14e033c7dc0de"
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.embeddings.create(\n",
    "\tmodel='text-embedding-ada-002',\n",
    "\tinput='The food was delicious and the waiter...',\n",
    "\tencoding_format='float'\n",
    ")\n"
   ],
   "id": "6dc14e033c7dc0de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Small",
   "id": "4c6f36519f4f7022"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Embedding\n",
    "def get_embedding( text, model='text-embedding-3-small' ):\n",
    "    text = text.replace( '\\n', ' ' )\n",
    "    return client.embeddings.create( input = [text], model=model ).data[0].embedding\n"
   ],
   "id": "cec4043c3e30fe6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Large",
   "id": "4e829f943f3b14c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Embedding\n",
    "def get_embedding( text, model='text-embedding-3-large' ):\n",
    "    text = text.replace( '\\n', ' ' )\n",
    "    return client.embeddings.create( input=[ text ], model=model ).data[ 0 ].embedding"
   ],
   "id": "dfaecb5d74f2b552",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Reduce Dimensions\n",
    "- Dynamically changing the dimensions enables very flexible usage.\n",
    "- When using a vector data store that only supports embeddings up to 1024 dimensions long, developers can now still use our best embedding model text-embedding-3-large and specify a value of 1024 for the dimensions API parameter, which will shorten the embedding down from 3072 dimensions, trading off some accuracy in exchange for the smaller vector size."
   ],
   "id": "252d5f7c74cc4644"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def normalize_l2( x ):\n",
    "    x = np.array( x )\n",
    "    if x.ndim == 1:\n",
    "        norm = np.linalg.norm( x )\n",
    "        if norm == 0:\n",
    "            return x\n",
    "        return x / norm\n",
    "    else:\n",
    "        norm = np.linalg.norm( x, 2, axis=1, keepdims=True )\n",
    "        return np.where( norm == 0, x, x / norm )\n",
    "\n",
    "\n",
    "response = client.embeddings.create( model='documents-embedding-3-small',\n",
    "\tinput='Testing 123', encoding_format='float' )\n",
    "\n",
    "cut_dim = response.data[ 0 ].embedding[ :256 ]\n",
    "norm_dim = normalize_l2( cut_dim )\n",
    "\n",
    "print( norm_dim )\n"
   ],
   "id": "cd2be06e97953ed2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question  Answer\n",
    "- There are many common cases where the model is not trained on data which contains key facts and information you want to make accessible when generating responses to a user query.\n",
    "- One way of solving this, as shown below, is to put additional information into the context window of the model.\n",
    "- This is effective in many use cases but leads to higher token costs."
   ],
   "id": "18cedeef5802e6d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Query\n",
    "query = f'''\n",
    "\n",
    "\tUse the below article on the 2022 Winter Olympics to answer the subsequent question.\n",
    "\tIf the answer cannot be found, write 'I don't know.'\n",
    "\n",
    "\tArticle:\n",
    "\t\\'\\'\\'\n",
    "\t{wikipedia_article_on_curling}\n",
    "\t\\'\\'\\'\n",
    "\n",
    "\tQuestion: Which athletes won the gold medal in curling at the 2022 Winter Olympics?\n",
    "\n",
    "'''\n",
    "\n",
    "# Create Response\n",
    "response = client.chat.completions.create(\n",
    "    messages=\n",
    "    [\n",
    "        {\n",
    "\t        'role': 'system',\n",
    "\t        'content': system_instructions\n",
    "        },\n",
    "        {\n",
    "\t        'role': 'user',\n",
    "\t        'content': user_propmt\n",
    "        },\n",
    "    ],\n",
    "    model=GPT_MODEL,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ],
   "id": "b7d3eb7c3c3f501d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Text Search\n",
    "- To retrieve the most relevant documents, use the cosine similarity between the embedding vectors of the query and each document, and return the highest scored documents.\n"
   ],
   "id": "490f4126e43a20b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def search_reviews( df, product_description, n=3, pprint=True ):\n",
    "    embedding = get_embedding( product_description, model='text-embedding-3-small' )\n",
    "    df['similarities'] = df.ada_embedding.apply( lambda x: cosine_similarity( x, embedding ) )\n",
    "    res = df.sort_values( 'similarities', ascending=False).head( n )\n",
    "    return res\n",
    "\n",
    "res = search_reviews( df, 'delicious beans', n=3 )\n"
   ],
   "id": "655c96c5053f02e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Code Search\n",
    "- Code search works similarly to embedding-based text search.\n",
    "- We provide a method to extract Python functions from all the Python files in a given repository.\n",
    "- Each function is then indexed by the `text-embedding-3-small` model.\n"
   ],
   "id": "9e6a7002183f16a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "df['code_embedding'] = df['code'].apply(lambda x: get_embedding(x, model='text-embedding-3-small'))\n",
    "\n",
    "def search_functions(df, code_query, n=3, pprint=True, n_lines=7):\n",
    "    embedding = get_embedding(code_query, model='text-embedding-3-small')\n",
    "    df['similarities'] = df.code_embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = df.sort_values('similarities', ascending=False).head(n)\n",
    "    return res\n",
    "\n",
    "res = search_functions(df, 'Completions API tests', n=3)\n"
   ],
   "id": "89e1080cb9c56da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Recommendation\n",
    "- Shorter distances between embedding vectors represent greater similarity,"
   ],
   "id": "df9cf5d43dadd6e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def recommendations_from_strings( strings: List[str], index_of_source_string: int,\n",
    "    model='text-embedding-3-small' ) -> List[int]:\n",
    "    '''Return nearest neighbors of a given string.'''\n",
    "    # get embeddings for all strings\n",
    "    embeddings = [ embedding_from_string( string, model=model ) for string in strings ]\n",
    "\n",
    "    # get the embedding of the source string\n",
    "    query_embedding = embeddings[ index_of_source_string ]\n",
    "    distances = distances_from_embeddings( query_embedding, embeddings, distance_metric='cosine' )\n",
    "\n",
    "    # get indices of nearest neighbors (function from embeddings_utils.py)\n",
    "    indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances( distances )\n",
    "    return indices_of_nearest_neighbors\n"
   ],
   "id": "d9a2efb8520859a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Text Featurization\n",
    "- An embedding can be used as a general free-text feature encoder within a machine learning model.\n",
    "- Incorporating embeddings will improve the performance of any machine learning model, if some of the relevant inputs are free text.\n",
    "- An embedding can also be used as a categorical feature encoder within a ML model."
   ],
   "id": "ae136c71eb89d0c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "data = list( df.ada_embedding.values )\n",
    "X_train, X_test, y_train, y_test = train_test_split( data, df.Score, test_size=0.2, random_state=42 )\n"
   ],
   "id": "c9b6f47f9f4561c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "2fea58c5aac941f0"
   },
   "cell_type": "markdown",
   "source": [
    "# Tools API\n",
    "- File Search augments the Assistant with knowledge from outside its model\n",
    "- Code Interpreter allows Assistants to write and run Python code in a sandboxed execution environment\n",
    "- Function calling allows you to describe functions to the Assistants API then call them\n",
    "___"
   ],
   "id": "2fea58c5aac941f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get Weather",
   "id": "83c4737551f06998"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function':\n",
    "        {\n",
    "            'name': 'get_weather',\n",
    "            'description': 'Gets the current weather for a given location',\n",
    "            'parameters':\n",
    "            {\n",
    "                'type': 'object',\n",
    "                'properties':\n",
    "                {\n",
    "                    'location':\n",
    "                    {\n",
    "                        'type': 'string',\n",
    "                        'description': 'The city and state, e.g., San Francisco, CA',\n",
    "                    },\n",
    "                    'unit':\n",
    "                    {\n",
    "                        'type': 'string',\n",
    "                        'enum': [ 'celsius', 'fahrenheit' ]\n",
    "                    }\n",
    "                },\n",
    "                'required': [ 'location' ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create( model='gpt-4o',\n",
    "\tmessages=[ { 'role': 'user', 'content': 'What is the weather like in Paris today?' } ],\n",
    "\ttools=tools )\n",
    "\n",
    "print( completion.choices[ 0 ].message.tool_calls )\n"
   ],
   "id": "765f26d1ce687f10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Send Email",
   "id": "6a1ac27e37fac52d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign Variables\n",
    "tools = [\n",
    "\t{\n",
    "\t\t'type': 'function',\n",
    "\t\t'function':\n",
    "\t\t{\n",
    "\t\t\t'name': 'send_email',\n",
    "\t\t\t'description': 'Send an email to a given recipient with a subject and message.',\n",
    "\t\t\t'parameters':\n",
    "\t\t\t{\n",
    "\t\t\t\t'type': 'object',\n",
    "\t\t\t\t'properties':\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t'to':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t'type': 'string',\n",
    "\t\t\t\t\t\t'description': 'The recipient email address.'\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t'subject':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t'type': 'string',\n",
    "\t\t\t\t\t\t'description': 'Email subject line.'\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t'body':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t'type': 'string',\n",
    "\t\t\t\t\t\t'description': 'Body of the email message.'\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t},\n",
    "\t\t\t\t'required': [ 'to', 'subject', 'body' ],\n",
    "\t\t\t\t'additionalProperties': False\n",
    "\t\t\t},\n",
    "\t\t\t'strict': True\n",
    "\t\t}\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Create Completion\n",
    "completion = client.chat.completions.create( model='gpt-4o',\n",
    "\tmessages=[ { 'role': 'user', 'content': 'Can you send an email to terryeppler@gmail.com saying hi?' } ],\n",
    "\ttools=_tools )\n",
    "\n",
    "print( completion.choices[ 0 ].message.tool_calls )"
   ],
   "id": "f7244dda1767837e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search Documents",
   "id": "523e0cf03638321b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign variables\n",
    "_tools = [\n",
    "{\n",
    "\t\t'type': 'function',\n",
    "\t\t'function':\n",
    "        {\n",
    "\t\t\t\t'name': 'search_knowledge_base',\n",
    "\t\t\t\t'description': 'Query a knowledge base to retrieve relevant info on a topic.',\n",
    "\t\t\t\t'parameters':\n",
    "                {\n",
    "\t\t\t\t\t\t'type': 'object',\n",
    "\t\t\t\t\t\t'properties':\n",
    "                        {\n",
    "\t\t\t\t\t\t\t\t'query':\n",
    "                                {\n",
    "                                    'type': 'string',\n",
    "                                    'description': 'The user question or search query.'\n",
    "                                },\n",
    "\t\t\t\t\t\t\t\t'options':\n",
    "                                {\n",
    "\t\t\t\t\t\t\t\t\t\t'type': 'object',\n",
    "\t\t\t\t\t\t\t\t\t\t'properties':\n",
    "                                        {\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'num_results':\n",
    "                                                {\n",
    "                                                    'type': 'number',\n",
    "                                                    'description': 'Number of top results to return.'\n",
    "                                                },\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'domain_filter':\n",
    "                                                {\n",
    "                                                    'type':\n",
    "                                                    [ 'string', 'null' ],\n",
    "                                                    'description': 'Optional domain to narrow the search. Pass null if not needed.'\n",
    "                                                },\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'sort_by':\n",
    "                                                {\n",
    "                                                    'type':\n",
    "                                                    [ 'string', 'null' ],\n",
    "                                                    'enum':\n",
    "                                                    [ 'relevance', 'date', 'popularity', 'alphabetical' ],\n",
    "                                                    'description': 'How to sort results. Pass null if not needed.'\n",
    "                                                }\n",
    "                                        },\n",
    "\t\t\t\t\t\t\t\t\t\t'required': [ 'num_results', 'domain_filter', 'sort_by' ],\n",
    "\t\t\t\t\t\t\t\t\t\t'additionalProperties': False\n",
    "                                }\n",
    "                        },\n",
    "\t\t\t\t\t\t'required': [ 'query', 'options' ],\n",
    "\t\t\t\t\t\t'additionalProperties': False\n",
    "                },\n",
    "\t\t\t\t'strict': True\n",
    "        }\n",
    "}\n",
    "]\n",
    "\n",
    "messages = \\\n",
    "[\n",
    "\t{\n",
    "\t\t'role': 'user',\n",
    "\t\t'content': 'Can you find information about ChatGPT in the AI knowledge base?'\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Create completion\n",
    "completion = client.chat.completions.create( model='gpt-4o', messages=_messages, tools=tools )\n",
    "\n",
    "print( completion.choices[ 0 ].message.tool_calls )"
   ],
   "id": "977000b1ed22ef92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search Web Tool",
   "id": "de33e4e44a5bd66b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Message\n",
    "_message = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': user_propmt,\n",
    "        } \n",
    "]\n",
    "\n",
    "# Create completion\n",
    "\n",
    "completion = client.chat.completions.create( model='gpt-4o-search-preview', web_search_options={},\n",
    "    messages=_message )\n",
    "\n",
    "print( completion.choices[ 0 ].message.content )"
   ],
   "id": "33ceccafde8c557d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### File Search Tool",
   "id": "dca98e676fedf65d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Step 1: Create a new Assistant with File Search Enabled\n",
    "assistant = client.beta.assistants.create(\n",
    "  name='Financial Analyst Assistant',\n",
    "  instructions='You are an expert financial analyst. Use you knowledge base to answer questions about audited financial statements.',\n",
    "  model='gpt-4o',\n",
    "  tools=[{'type': 'file_search'}],\n",
    ")\n",
    "\n",
    "# Step 2: Upload files and add them to a Vector Store\n",
    "vector_store = client.vector_stores.create( name='Financial Statements' )\n",
    "file_paths = [ 'edgar/goog-10k.pdf', 'edgar/brka-10k.txt' ]\n",
    "file_streams = [ open( path, 'rb' ) for path in file_paths ]\n",
    "file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "print( file_batch.status )\n",
    "print( file_batch.file_counts )\n",
    "\n",
    "# Step 3: Update the assistant to use the new Vector Store\n",
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={'file_search': {'vector_store_ids': [vector_store.id]}},\n",
    ")\n",
    "\n",
    "# Step 4: Create a thread\n",
    "message_file = client.files.create(\n",
    "  file=open('edgar/aapl-10k.pdf', 'rb'), purpose='assistants'\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': 'How many shares of AAPL were outstanding at the end of of October 2023?',\n",
    "      'attachments': [\n",
    "        { 'file_id': message_file.id, 'tools': [{'type': 'file_search'}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "print( thread.tool_resources.file_search )\n",
    "\n",
    "# Step 5: Create a run and check the cleaned\n",
    "run = client.beta.threads.runs.create_and_poll( thread_id=thread.id,\n",
    "\tassistant_id=assistant.id )\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace( annotation.text, f'[{index}]' )\n",
    "    if file_citation := getattr( annotation, 'file_citation', None ):\n",
    "        cited_file = client.files.retrieve( file_citation.file_id )\n",
    "        citations.append( f'[{index}] {cited_file.filename}' )\n",
    "\n",
    "print( message_content.value )\n",
    "print('\\n'.join( citations ) )\n",
    "\n",
    "\n",
    "print( response )"
   ],
   "id": "b6b93701524b2804",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Use Browser",
   "id": "b4e58145c3fe0659"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign variables\n",
    "_args = [ '--disable-extensions', '--disable-file-system' ]\n",
    "\n",
    "with sync_playwright() as p:\n",
    "    browser = p.chromium.launch( headless=False, chromium_sandbox=True,\n",
    "        env={}, args=_args )\n",
    "    \n",
    "    page = browser.new_page( )\n",
    "    page.set_viewport_size( {'width': 1024, 'height': 768} )\n",
    "    page.goto( 'https://bing.com' )\n",
    "\n",
    "    page.wait_for_timeout( 10000 )"
   ],
   "id": "d631d1de28a48f55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Use Computer",
   "id": "6f002157c8565135"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign Variables\n",
    "_model = 'computer-use-preview'\n",
    "_reasoning = { 'generate_summary': 'concise', }\n",
    "_truncation = 'auto'\n",
    "_tools = [\n",
    "\t{\n",
    "        'type': 'computer_use_preview',\n",
    "        'display_width': 1024,\n",
    "        'display_height': 768,\n",
    "        'environment': 'browser' # other possible values: 'mac', 'windows', 'ubuntu'\n",
    "    }\n",
    "]\n",
    "\n",
    "_input = [\n",
    "\t{\n",
    "            'role': 'user',\n",
    "            'content': 'Check the latest OpenAI news on bing.com.'\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create( model=_model, tools=_tools, input=_input,\n",
    "    reasoning=_reasoning, truncation='auto' )\n",
    "\n",
    "print( response.cleaned_lines )"
   ],
   "id": "1cfbca5363e7cd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Send Computer Use Request",
   "id": "7f93e2f19fe41874"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Send a request to create a Response with the **computer-use-preview** model equipped with the computer_use_preview tool.\n",
    "- This request should include details about your environment, along with an initial input prompt."
   ],
   "id": "d8aa79fb086aa0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign variables\n",
    "_model = 'computer-use-preview'\n",
    "_tools = [\n",
    "\t{\n",
    "        'type': 'computer_use_preview',\n",
    "        'display_width': 1024,\n",
    "        'display_height': 768,\n",
    "        'environment': 'browser' # other possible values: 'mac', 'windows', 'ubuntu'\n",
    "    }\n",
    "]\n",
    "\n",
    "_input = [\n",
    "\t{\n",
    "            'role': 'user',\n",
    "            'content': 'Check the latest OpenAI news on bing.com.'\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Create response\n",
    "response = client.responses.create( model=_model, tools=_tools, input=_input,\n",
    "    reasoning={ 'generate_summary': 'concise', }, truncation='auto' )\n",
    "\n",
    "print( response.cleaned_lines )"
   ],
   "id": "1669192c119728b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Execution Action",
   "id": "e04d112b001ed974"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Execute the corresponding actions on your computer or browser.\n",
    "- How you map a computer call to actions through code depends on your environment.\n",
    "- This code shows example implementations for the most common computer actions."
   ],
   "id": "c8a1a66fbcdc3ac9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def handle_model_action( page, action ):\n",
    "    '''\n",
    "    \n",
    "\t\tGiven a computer action (e.g., click, double_click, scroll, resources.),\n",
    "\t\texecute the corresponding operation on the Playwright page.\n",
    "\t\t\n",
    "    '''\n",
    "    action_type = action.type\n",
    "    try:\n",
    "        match action_type:\n",
    "            case 'click':\n",
    "                x, y = action.x, action.y\n",
    "                button = action.button\n",
    "                print( f\"Action: click at ({x}, {y}) with button '{button}' \" )\n",
    "                # Not handling things like middle click, resources.\n",
    "                if button != 'left' and button != 'right':\n",
    "                    button = 'left'\n",
    "                page.mouse.click( x, y, button=button )\n",
    "\n",
    "            case 'scroll':\n",
    "                x, y = action.x, action.y\n",
    "                scroll_x, scroll_y = action.scroll_x, action.scroll_y\n",
    "                print(f'Action: scroll at ({x}, {y}) with offsets (scroll_x={scroll_x}, scroll_y={scroll_y})')\n",
    "                page.mouse.move( x, y )\n",
    "                page.evaluate( f'window.scrollBy({scroll_x}, {scroll_y})' )\n",
    "\n",
    "            case 'keypress':\n",
    "                keys = action.keys\n",
    "                for k in keys:\n",
    "                    print( f\"Action: keypress '{k}' \" )\n",
    "                    # A simple mapping for common keys; expand as needed.\n",
    "                    if k.lower( ) == 'enter':\n",
    "                        page.keyboard.press( 'Enter' )\n",
    "                    elif k.lower( ) == 'space':\n",
    "                        page.keyboard.press( ' ' )\n",
    "                    else:\n",
    "                        page.keyboard.press( k )\n",
    "\n",
    "            case 'type':\n",
    "                text = action.text\n",
    "                print( f'Action: type documents: {text}' )\n",
    "                page.keyboard.type( text )\n",
    "\n",
    "            case 'wait':\n",
    "                print( f'Action: wait' )\n",
    "                time.sleep( 2 )\n",
    "\n",
    "            case 'screenshot':\n",
    "                # Nothing to do as screenshot is taken at each turn\n",
    "                print( f'Action: screenshot' )\n",
    "\n",
    "            # Handle other actions here\n",
    "\n",
    "            case _:\n",
    "                print( f'Unrecognized action: {action}' )\n",
    "\n",
    "    except Exception as e:\n",
    "        print( f'Error handling action {action}: {e}' )"
   ],
   "id": "ebe900fccd4c78c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Capture Screenshot",
   "id": "fe7ef876f73d6cca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- After executing the action, capture the updated state of the environment as a screenshot, which also differs depending on your environment.",
   "id": "6d03e32c9b40c799"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_screenshot( page ):\n",
    "    '''\n",
    "    \n",
    "    \tTake a full-page screenshot using Playwright and return the image bytes.\n",
    "    \t\n",
    "    '''\n",
    "    return page.screenshot()"
   ],
   "id": "33925edc5d07ae97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Repeating Loop",
   "id": "3517e91b75cfabb1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Once you have the screenshot, you can send it back to the model as a **computer_call_output** to get the next action.\n",
    "- Repeat these steps as long as you get a **computer_call** item in the response."
   ],
   "id": "c08830b946d8bad9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def computer_use_loop( instance, response ):\n",
    "    '''\n",
    "    \tRun the loop that executes computer actions until no 'computer_call' is found.\n",
    "    '''\n",
    "    while True:\n",
    "        computer_calls = [ item for item in response.output if item.type == 'computer_call' ]\n",
    "        if not computer_calls:\n",
    "            print( 'No computer call found. Output from model:' )\n",
    "            for item in response.output:\n",
    "                print( item )\n",
    "            break  # Exit when no computer calls are issued.\n",
    "\n",
    "        # We expect at most one computer call per response.\n",
    "        computer_call = computer_calls[ 0 ]\n",
    "        last_call_id = computer_call.call_id\n",
    "        action = computer_call.action\n",
    "\n",
    "        # Execute the action (function defined in step 3)\n",
    "        handle_model_action( instance, action )\n",
    "        time.sleep( 1 )  # Allow time for changes to take effect.\n",
    "\n",
    "        # Take a screenshot after the action (function defined in step 4)\n",
    "        screenshot_bytes = get_screenshot( instance )\n",
    "        screenshot_base64 = base64.b64encode( screenshot_bytes ).decode( 'utf-8' )\n",
    "\n",
    "        # Send the screenshot back as a computer_call_output\n",
    "        response = client.responses.create(\n",
    "            model='computer-use-preview',\n",
    "            previous_response_id=response.id,\n",
    "            tools=[\n",
    "                {\n",
    "                    'type': 'computer_use_preview',\n",
    "                    'display_width': 1024,\n",
    "                    'display_height': 768,\n",
    "                    'environment': 'browser'\n",
    "                }\n",
    "            ],\n",
    "            input=[\n",
    "                {\n",
    "                    'call_id': last_call_id,\n",
    "                    'type': 'computer_call_output',\n",
    "                    'cleaned': {\n",
    "                        'type': 'input_image',\n",
    "                        'image_url': f'values:image/png;base64,{screenshot_base64}'\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            truncation='auto'\n",
    "        )\n",
    "\n",
    "    return response"
   ],
   "id": "1da6090518887d73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Files API\n",
    "- Upload up to 100 pages and 32MB of total content in a single request to the API, across multiple file inputs.\n",
    "- Only models that support both text and image inputs, such as gpt-4o, gpt-4o-mini, or o1, can accept PDF files as input\n",
    "- Recommend using the user_data purpose for files you plan to use as model inputs.\n",
    "___"
   ],
   "id": "9ca883a9e1a75ea5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Upload\n",
    "- Upload a PDF using the Files API, then reference its file ID in an API request to the model."
   ],
   "id": "f929960a9efe33d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign vriables\n",
    "_messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'type': 'file',\n",
    "                    'file':\n",
    "\t                {\n",
    "                        'file_id': file.id,\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'type': 'documents',\n",
    "                    'documents': 'What is the first dragon in the book?',\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "]\n",
    "\n",
    "# Create File Request\n",
    "file = client.files.create( file=open( 'draconomicon.pdf', 'rb' ), purpose='user_data' )\n",
    "completion = client.chat.completions.create( model='gpt-4o', messages=_messages, )\n",
    "\n",
    "print( completion.choices[ 0 ].message.content )"
   ],
   "id": "f67de4bc69a2a23d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List",
   "id": "aa4daee5f20bbed3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "_files = client.files.list()\n",
    "\n",
    "for i in _files:\n",
    "\tprint( i )\n"
   ],
   "id": "fce6a758df7ecead",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retreive File",
   "id": "119481b90b81b060"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Reteive by file_id\n",
    "client.files.retrieve( 'file-abc123' )\n"
   ],
   "id": "965e3286ecc2d79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Reteive Contents",
   "id": "f69abf06c4eafe11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "content = client.files.content( 'file-abc123' )\n"
   ],
   "id": "88925f2c09a44d16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Upload",
   "id": "d382cf0af90b2de4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.files.create( file=open('mydata.jsonl', 'rb'), purpose='fine-tune' )\n"
   ],
   "id": "9f67d49ba88d38ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Base64-encoded files\n",
    "- You can send PDF file inputs as Base64-encoded inputs as well."
   ],
   "id": "6e99da7e11a87f50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "with open( 'draconomicon.pdf', 'rb' ) as f:\n",
    "    data = f.read( )\n",
    "\n",
    "base64_string = base64.b64encode( data ).decode( 'utf-8' )\n",
    "completion = client.chat.completions.create( model='gpt-4o',\n",
    "    messages=\n",
    "    [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'type': 'file',\n",
    "                    'file':\n",
    "\t                {\n",
    "                        'filename': 'draconomicon.pdf',\n",
    "                        'file_data': f'values:application/pdf;base64,{ base64_string }',\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'type': 'text',\n",
    "                    'documents': 'What is the first dragon in the book?',\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ].message.content )"
   ],
   "id": "9dedf86a63db689f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Retreival API\n",
    "- The Retrieval API allows you to perform semantic search over your data, which is a technique that surfaces semantically similar results — even when they match few or no keywords.\n",
    "- The Retrieval API is powered by vector stores, which serve as indices for your data.\n",
    "___"
   ],
   "id": "a50edf1ae3361954"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Upload",
   "id": "31252b9607a71e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "vector_store = client.vector_stores.create( name='Support FAQ' )\n",
    "client.vector_stores.files.upload_and_poll(  vector_store_id=vector_store.id,\n",
    "    file=open( 'customer_policies.txt', 'rb' ) )"
   ],
   "id": "6c18fd89469c0f54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search Stores",
   "id": "2fec5e4852fc5c27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create search\n",
    "user_query = 'What is the return policy?'\n",
    "results = client.vector_stores.search( vector_store_id=vector_store.id, query=user_query, )"
   ],
   "id": "9aab2bf7205e3bb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Semantic Search",
   "id": "89e5cbb85a08cdf6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "results = client.vector_stores.search( vector_store_id=vector_store.id,\n",
    "    query='How many woodchucks are allowed per passenger?', )"
   ],
   "id": "24d3b604818a4c4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Vector Store API\n",
    "- Vector stores are the containers that power semantic search for the Retrieval API and the Assistants API file search tool.\n",
    "- When you add a file to a vector store it will be automatically chunked, embedded, and indexed.\n",
    "___"
   ],
   "id": "be2cc49a73407a4a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### I. Vector Store Operations",
   "id": "ca588f7dcdb197e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create",
   "id": "ab17f992fe0c8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create vector store\n",
    "client.vector_stores.create( name='Support FAQ', file_ids=[ 'file_123' ] )"
   ],
   "id": "d94e42c2ac8099f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retrieve",
   "id": "1b0c4fa721cd030"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Retreive vector store\n",
    "client.vector_stores.retrieve( vector_store_id='vs_123' )"
   ],
   "id": "9406837b98028fd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Update",
   "id": "4edf82399108961f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Update vector store\n",
    "client.vector_stores.retrieve(  vector_store_id='vs_123' )"
   ],
   "id": "b749f3548bed8ac5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Delete",
   "id": "b7d769b3595f8e26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Delete vector store\n",
    "client.vector_stores.delete( vector_store_id='vs_123' )"
   ],
   "id": "8063dc3580e8020a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List",
   "id": "c2a44c35871c29c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List stores\n",
    "client.vector_stores.list( )"
   ],
   "id": "1bdeffc856f4ff0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### II. Vector File Operations",
   "id": "3578fa99af2f88cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create",
   "id": "3c40ae41d1ae8467"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create files for vector store\n",
    "client.vector_stores.files.create( vector_store_id='vs_123',\n",
    "    file_id='file_123',\n",
    "    attributes=\n",
    "    {\n",
    "        'region': 'US',\n",
    "        'category': 'Marketing',\n",
    "        'date': 1672531200\n",
    "    }\n",
    ")"
   ],
   "id": "984ffe86987d9272",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Upload",
   "id": "56f14ab34778d2cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.files.upload_and_poll( vector_store_id='vs_123',\n",
    "    file=open('customer_policies.txt', 'rb') )\n"
   ],
   "id": "ed29df05e7a77f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retreive",
   "id": "1336958964d59639"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.files.retrieve( vector_store_id='vs_123', file_id='file_123' )\n"
   ],
   "id": "f6c802de56bc052f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Update",
   "id": "5e74af88e92efca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Update file\n",
    "client.vector_stores.files.update( vector_store_id='vs_123',\n",
    "    file_id='file_123',\n",
    "    attributes=\n",
    "    {\n",
    "\t    'key': 'value'\n",
    "    }\n",
    ")\n"
   ],
   "id": "f443a34c5826ccce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Delete",
   "id": "3492950c03e4fa97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Delete file\n",
    "client.vector_stores.files.delete( vector_store_id='vs_123', file_id='file_123' )\n"
   ],
   "id": "e0be6eee50dc28f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List",
   "id": "c8c69370ca89033e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List files\n",
    "client.vector_stores.files.list( vector_store_id='vs_123' )\n"
   ],
   "id": "be5f037d2876f58d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### II. Vector Batch Operations",
   "id": "483a13c1a68c6672"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create",
   "id": "46890148f4fd4492"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.file_batches.create_and_poll( vector_store_id='vs_123',\n",
    "    file_ids=[ 'file_123', 'file_456' ] )\n"
   ],
   "id": "31c7761d9c3cf90f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retrieve",
   "id": "dad42758272e6fa2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.file_batches.retrieve( vector_store_id='vs_123', batch_id='vsfb_123' )\n"
   ],
   "id": "2492bf72c3ce319f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cancel",
   "id": "141a54906fa93785"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.file_batches.cancel( vector_store_id='vs_123', batch_id='vsfb_123' )\n"
   ],
   "id": "1bc11b59e12ed29a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List",
   "id": "ac479dc7694ce178"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.file_batches.list( vector_store_id='vs_123' )\n"
   ],
   "id": "8894cf9d1c7299b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Assistant API\n",
    "- Designed to help developers build powerful AI assistants capable of performing a variety of tasks.\n",
    "- Build AI assistants within your own applications.\n",
    "##### Supports the following tools:\n",
    "1. Code Interpreter\n",
    "2. File Search\n",
    "3. Function calling.\n",
    "___"
   ],
   "id": "9df6bbfe74f1da68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Assistant",
   "id": "7789133558f7399"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions='You are a personal math tutor. When asked a question, write and run Python code to answer the question.',\n",
    "    name='Math Tutor',\n",
    "    tools=[{'type': 'code_interpreter'}],\n",
    "    model='gpt-4o',\n",
    ")\n",
    "print( my_assistant )\n"
   ],
   "id": "79e8b17900a8609f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List Assistants",
   "id": "82a4101059ca8d08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_assistants = client.beta.assistants.list( order='desc', limit='20' )\n",
    "\n",
    "print( my_assistants.data )\n"
   ],
   "id": "3369688ba307f2d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retreive Assistant",
   "id": "24c75f00b49c0fa5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_assistant = client.beta.assistants.retrieve('asst_abc123')\n",
    "print(my_assistant)\n"
   ],
   "id": "e270cdaaeedd8fc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Update Assistant",
   "id": "69d2d0f1876ed9f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_updated_assistant = client.beta.assistants.update( 'asst_abc123',\n",
    "  instructions='You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.',\n",
    "  name='HR Helper',\n",
    "  tools=[{'type': 'file_search'}],\n",
    "  model='gpt-4o'\n",
    ")\n",
    "\n",
    "print( my_updated_assistant )\n"
   ],
   "id": "6a6a6aa07bfe1a45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Delete Assistant",
   "id": "2eedf073dcf80352"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "response = client.beta.assistants.delete('asst_abc123')\n",
    "print(response)\n"
   ],
   "id": "bec93c14671449b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### I. Threads",
   "id": "d3b53aefaed1b702"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create",
   "id": "decf426a6e9e82af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "empty_thread = client.beta.threads.create()\n",
    "print(empty_thread)\n"
   ],
   "id": "124407263bed255f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retreive",
   "id": "268461d8664a1afd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_thread = client.beta.threads.retrieve('thread_abc123')\n",
    "print(my_thread)\n"
   ],
   "id": "f1d01d205758758c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Update",
   "id": "db5a156c21b07875"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_updated_thread = client.beta.threads.update( 'thread_abc123',\n",
    "  metadata= { 'modified': 'true', 'user': 'abc123' } )\n",
    "\n",
    "print(my_updated_thread)\n"
   ],
   "id": "15d7587e415aeb1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Delete",
   "id": "f7574157ea64d69a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "response = client.beta.threads.delete( 'thread_abc123' )\n",
    "\n",
    "print(response)\n"
   ],
   "id": "2e76400ac172a239",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### II. Messages",
   "id": "d38f1c9b23d0a6f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create",
   "id": "53032868026c88dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create message\n",
    "thread_message = client.beta.threads.messages.create( 'thread_abc123',  role='user',\n",
    "  content='How does AI work? Explain it in simple terms.', )\n",
    "\n",
    "print(thread_message)\n"
   ],
   "id": "81d79cd2c1706312",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List",
   "id": "13656b055bff5d16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List messages in a thread\n",
    "thread_messages = client.beta.threads.messages.list( 'thread_abc123' )\n",
    "print(thread_messages.data)\n"
   ],
   "id": "7f0520e6a197fb69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retreive",
   "id": "bc76238baa324952"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Retreive messages from thread\n",
    "message = client.beta.threads.messages.retrieve( message_id='msg_abc123',\n",
    "\tthread_id='thread_abc123' )\n",
    "\n",
    "print( message )\n"
   ],
   "id": "52c0b73d716944e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Update",
   "id": "45611582952a3fb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Update messages in thread\n",
    "message = client.beta.threads.messages.update(\n",
    "  message_id='msg_abc12',\n",
    "  thread_id='thread_abc123',\n",
    "  metadata={\n",
    "    'modified': 'true',\n",
    "    'user': 'abc123',\n",
    "  },\n",
    "\n",
    ")\n",
    "print( message )\n"
   ],
   "id": "4b443485eec43e35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Delete",
   "id": "76e60dddc54098e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Delete messages in thread\n",
    "deleted_message = client.beta.threads.messages.delete(  message_id='msg_abc12',\n",
    "\tthread_id='thread_abc123', )\n",
    "\n",
    "print(deleted_message)"
   ],
   "id": "87d4179d0a84fb4e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
