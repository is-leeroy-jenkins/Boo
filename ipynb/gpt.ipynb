{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "<a href='https://colab.research.google.com/github/is-leeroy-jenkins/Boo/blob/main/ipynb/GPT.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>",
   "id": "6b5948d8e77a7699"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b752f6d30e042eaa"
  },
  {
   "metadata": {
    "id": "6f5de4ab069df199"
   },
   "cell_type": "markdown",
   "source": "###### Load Dependencies",
   "id": "6f5de4ab069df199"
  },
  {
   "metadata": {
    "id": "98ca47c4dd694371",
    "ExecuteTime": {
     "end_time": "2025-04-05T11:59:50.066271Z",
     "start_time": "2025-04-05T11:59:50.057751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from playwright.sync_api import sync_playwright\n",
    "import tiktoken\n",
    "import base64\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "id": "98ca47c4dd694371",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Responses API\n",
    "- Supports text and image inputs, and text outputs.\n",
    "- Create stateful interactions with the model, using the output of previous responses as input\n",
    "- Allow the model access to external systems and data using function calling\n",
    "___"
   ],
   "id": "e1313ea6ec4b98e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Text Input",
   "id": "20122a3e0c1383bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create(\n",
    "  model='gpt-4o',\n",
    "  input='Tell me a three sentence bedtime story about a unicorn.'\n",
    ")\n",
    "\n",
    "print( response.output_text )\n"
   ],
   "id": "4903eecfcf720bb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Image",
   "id": "fe1c21457de0ab2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o',\n",
    "    input=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                { 'type': 'input_text', 'text': 'what is in this image?' },\n",
    "                {\n",
    "                    'type': 'input_image',\n",
    "                    'image_url': 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg'\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print( response.output_text )"
   ],
   "id": "6ca8099721cee1ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Search Web",
   "id": "1a0c18c43ebfe9a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:48:42.093048Z",
     "start_time": "2025-04-04T15:48:34.559707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o',\n",
    "    tools=[{ 'type': 'web_search_preview' }],\n",
    "    input='What was a positive news story from today?',\n",
    ")\n",
    "\n",
    "print( response.output_text )"
   ],
   "id": "a624f0bd89a21fdb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On April 4, 2025, Russian President Vladimir Putin's investment envoy, Kirill Dmitriev, expressed optimism about improving U.S.-Russia relations following discussions with officials from President Donald Trump's administration. Dmitriev highlighted progress on issues such as Ukraine, Arctic cooperation, rare metals, and space exploration, including potential joint missions to Mars involving Elon Musk. He noted efforts to restore direct air travel and emphasized the importance of continued meetings to resolve outstanding issues. Dmitriev also credited recent U.S.-Russia talks in Saudi Arabia and support from U.S. envoy Steve Witkoff as instrumental in facilitating diplomatic progress, including ceasefires in energy sectors and ensuring safe navigation in the Black Sea. ([reuters.com](https://www.reuters.com/world/europe/putin-envoy-dmitriev-says-some-forces-trying-sow-discord-between-russia-us-2025-04-03/?utm_source=openai))\n",
      "\n",
      "Additionally, the Texas women's basketball team advanced to the NCAA Final Four for the first time in over two decades after defeating TCU. This achievement marks a significant milestone for the team and has been celebrated by fans and the university community. ([kutkutx.studio](https://kutkutx.studio/kut-news-now/kut-morning-newscast-for-april-4-2025-t-texas-advances-to-womens-final-four-for-first-time-in-over-two-decades?numpage=9&utm_source=openai))\n",
      "\n",
      "\n",
      "## Positive Developments on April 4, 2025:\n",
      "- [Putin envoy Dmitriev sees 'positive dynamic' in US-Russia relations](https://www.reuters.com/world/europe/putin-envoy-dmitriev-says-some-forces-trying-sow-discord-between-russia-us-2025-04-03/?utm_source=openai)\n",
      "- [KUT Morning Newscast for April 4, 2025: Texas advances to women’s Final Four for first time in over two decades. - KUT & KUTX Studios - Podcasts](https://kutkutx.studio/kut-news-now/kut-morning-newscast-for-april-4-2025-t-texas-advances-to-womens-final-four-for-first-time-in-over-two-decades?numpage=9&utm_source=openai) \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Search File",
   "id": "4106ee39d8e3a613"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[\n",
    "\t{\n",
    "      \"type\": \"file_search\",\n",
    "      \"vector_store_ids\": [\"vs_1234567890\"],\n",
    "      \"max_num_results\": 20\n",
    "    } ],\n",
    "\tinput=\"What are the attributes of an ancient brown dragon?\",\n",
    ")\n",
    "\n",
    "print( response.output_text )"
   ],
   "id": "a31ec26572e7af55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Stream",
   "id": "26eff0c7a53b5c62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4o\",\n",
    "  instructions=\"You are a helpful assistant.\",\n",
    "  input=\"Hello!\",\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "for event in response:\n",
    "  print(event)"
   ],
   "id": "853170b8b26c1eef"
  },
  {
   "metadata": {
    "id": "a9f52a9d4000c649"
   },
   "cell_type": "markdown",
   "source": [
    "# Completion API\n",
    "- Generates a model response from a list of messages comprising a conversation.\n",
    "- Parameter support can differ depending on the model used to generate the response\n",
    "___"
   ],
   "id": "a9f52a9d4000c649"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Ex. Completion Response\n",
    "- 'choices'\n",
    "- `completion.choices[ 0 ].message`\n",
    "- `response.choices[0].message.content`"
   ],
   "id": "c5fc32d1cf3f9952"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "[\n",
    "        {\n",
    "            \"index\": 0,\n",
    "            \"message\":\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Under the soft glow of the moon, Luna the unicorn danced through fields of twinkling stardust, leaving trails of dreams for every child asleep.\",\n",
    "                \"refusal\": null\n",
    "             },\n",
    "             \"logprobs\": null,\n",
    "             \"finish_reason\": \"stop\"\n",
    "        }\n",
    "]"
   ],
   "id": "ff49ede8849de01c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Completion",
   "id": "7f03d6a6cce47a8"
  },
  {
   "metadata": {
    "id": "42101fefd439757a",
    "outputId": "a17acaed-b8b2-4ceb-c9d3-14191b2f96c9",
    "ExecuteTime": {
     "end_time": "2025-04-04T15:51:28.691303Z",
     "start_time": "2025-04-04T15:51:20.668164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Completion\n",
    "completion = client.chat.completions.create(\n",
    "\tmodel='gpt-4o',\n",
    "\tmessages=\n",
    "\t[\n",
    "\t\t{ 'role': 'system', 'content': 'You are a helpful assistant.' },\n",
    "\t\t{ 'role': 'user', 'content': 'What is an appropriation?' }\n",
    "\t]\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ].message )"
   ],
   "id": "42101fefd439757a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='An appropriation is an authorization by a legislative body, typically a parliament or congress, to allocate a specific amount of money for a particular purpose or project. This allocation allows government agencies or departments to incur obligations and make payments out of government funds. Appropriations are part of the budgeting process and play a critical role in ensuring that government operations and services are funded appropriately.\\n\\nThere are different types of appropriations, including:\\n\\n1. **Annual Appropriations**: These are regular budgetary allocations made each fiscal year to fund ongoing operations and activities.\\n\\n2. **Supplemental Appropriations**: These are additional funds allocated outside the regular budget cycle, often to address unforeseen expenditures or emergencies.\\n\\n3. **Continuing Appropriations**: Sometimes known as continuing resolutions, these are temporary funds provided to keep government operations running when the regular appropriations process is delayed or incomplete.\\n\\n4. **Permanent Appropriations**: These are funds automatically available each year without requiring an annual legislative approval.\\n\\nOverall, the appropriation process is crucial for maintaining governmental accountability and ensuring that taxpayer money is used effectively and in alignment with legislative priorities.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "id": "aa8e8b3a885a7bab"
   },
   "cell_type": "markdown",
   "source": "#### Retreive Completions\n",
   "id": "aa8e8b3a885a7bab"
  },
  {
   "metadata": {
    "id": "67ffaed532fe0dc1",
    "outputId": "f8843a06-944f-45fe-cdbc-655f0201acbb"
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Completion\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "first_completion = client.chat.completions.retrieve( completion_id=first_id )\n",
    "print( first_completion )"
   ],
   "id": "67ffaed532fe0dc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "b530f9aee20cce11"
   },
   "cell_type": "markdown",
   "source": "#### View Message",
   "id": "b530f9aee20cce11"
  },
  {
   "metadata": {
    "id": "f2784968574ff7c8",
    "outputId": "46c97a49-2c63-4fcb-ae4a-698ce45aa2bd"
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Completion\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "first_completion = client.chat.completions.retrieve( completion_id=first_id )\n",
    "messages = client.chat.completions.messages.list( completion_id=first_id )\n",
    "print( messages )"
   ],
   "id": "f2784968574ff7c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "9c62391ecc6da73f"
   },
   "cell_type": "markdown",
   "source": "#### List Chats",
   "id": "9c62391ecc6da73f"
  },
  {
   "metadata": {
    "id": "f5a72eef452bbc22"
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Compmletion\n",
    "completions = client.chat.completions.list( )\n",
    "print( completions )\n"
   ],
   "id": "f5a72eef452bbc22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Upload File",
   "id": "a60864fd32fdc3d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create File Reqeust\n",
    "file = client.files.create(\n",
    "    file=open('draconomicon.pdf', 'rb'),\n",
    "    purpose='user_data'\n",
    ")\n",
    "\n",
    "# Create Completion\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'type': 'file',\n",
    "                    'file':\n",
    "\t\t\t\t\t{\n",
    "                        'file_id': file.id,\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'type': 'documents',\n",
    "                    'documents': 'What is the first dragon in the book?',\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "7a08718a9386339a"
  },
  {
   "metadata": {
    "id": "4a5f4620e53bab63"
   },
   "cell_type": "markdown",
   "source": "#### Update Completion",
   "id": "4a5f4620e53bab63"
  },
  {
   "metadata": {
    "id": "ee0f4929c2fa200b"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Completion\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "updated_completion = client.chat.completions.update( completion_id=first_id,\n",
    "\trequest_body={ 'metadata': { 'foo': 'bar' } } )\n",
    "print( updated_completion )"
   ],
   "id": "ee0f4929c2fa200b"
  },
  {
   "metadata": {
    "id": "e01ecd500ae773a5"
   },
   "cell_type": "markdown",
   "source": "#### Delete Completion",
   "id": "e01ecd500ae773a5"
  },
  {
   "metadata": {
    "id": "b69689f26fb50f5d"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Completion\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "delete_response = client.chat.completions.delete( completion_id=first_id )\n",
    "print( delete_response )"
   ],
   "id": "b69689f26fb50f5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Assistants API\n",
    "- Can call models and use tools to perform tasks..\n",
    "- An Assistant has instructions and can leverage models, tools, and files to respond to user queries.\n",
    "##### Tools:\n",
    "\n",
    "- Code Interpreter\n",
    "- File Search\n",
    "- Function calling\n",
    "___"
   ],
   "id": "cf57967b7d2bdcae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create",
   "id": "f196daeebbdcfc8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Math Tutor\",\n",
    "  instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}],\n",
    "  model=\"gpt-4o\",\n",
    ")"
   ],
   "id": "e43dfd90678d1468"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Add Thread",
   "id": "171960fd6f653e66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "thread = client.beta.threads.create()"
   ],
   "id": "7b2c84cdaded2e15"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Add Message",
   "id": "79bf02388a442d49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )"
   ],
   "id": "1431f1461a8c4518"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Run",
   "id": "c4121043e6ce790f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Please address the user as Jane Doe. The user has a premium account.\"\n",
    ")\n",
    "\n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(messages)\n",
    "else:\n",
    "  print(run.status)"
   ],
   "id": "e16c4467e5387ae7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Stream Run",
   "id": "a7fc0b27705d1ad2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "\n",
    "# First, we create a EventHandler class to define\n",
    "# how we want to handle the events in the response stream.\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "  @override\n",
    "  def on_text_created(self, text) -> None:\n",
    "    print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "\n",
    "  @override\n",
    "  def on_text_delta(self, delta, snapshot):\n",
    "    print(delta.value, end=\"\", flush=True)\n",
    "\n",
    "  def on_tool_call_created(self, tool_call):\n",
    "    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "  def on_tool_call_delta(self, delta, snapshot):\n",
    "    if delta.type == 'code_interpreter':\n",
    "      if delta.code_interpreter.input:\n",
    "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "      if delta.code_interpreter.outputs:\n",
    "        print(f\"\\n\\noutput >\", flush=True)\n",
    "        for output in delta.code_interpreter.outputs:\n",
    "          if output.type == \"logs\":\n",
    "            print(f\"\\n{output.logs}\", flush=True)\n",
    "\n",
    "# Then, we use the `stream` SDK helper\n",
    "# with the `EventHandler` class to create the Run\n",
    "# and stream the response.\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Please address the user as Jane Doe. The user has a premium account.\",\n",
    "  event_handler=EventHandler(),\n",
    ") as stream:\n",
    "  stream.until_done()"
   ],
   "id": "e9c17850e736a2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Speech API\n",
    "- The maximum input length is 4096 characters.\n",
    "- TTS models: tts-1, tts-1-hd or gpt-4o-mini-tts.\n",
    "___"
   ],
   "id": "8431ed1e58f0f686"
  },
  {
   "metadata": {
    "id": "f9aa6a88c6e6aae1"
   },
   "cell_type": "markdown",
   "source": [
    "#### Create Audio\n",
    "- Generates audio from the input text."
   ],
   "id": "f9aa6a88c6e6aae1"
  },
  {
   "metadata": {
    "id": "69bfd864f5e56ea6"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Speech\n",
    "speech_file_path = Path( __file__ ).parent  # 'speech.mp3'\n",
    "prompt = 'The quick brown fox jumped over the lazy dog.'\n",
    "response = openai.audio.speech.create( model='tts-1', voice='alloy', input=prompt )\n",
    "response.stream_to_file( speech_file_path )\n"
   ],
   "id": "69bfd864f5e56ea6"
  },
  {
   "metadata": {
    "id": "d30d80c36b8c36c0"
   },
   "cell_type": "markdown",
   "source": [
    "#### Create Transcription\n",
    "- Transcribes audio into the input language."
   ],
   "id": "d30d80c36b8c36c0"
  },
  {
   "metadata": {
    "id": "6d17f226244664f3"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Open Audio File 'speech.mp3'\n",
    "audio_file = open( 'speech.mp3', 'rb' )\n",
    "transcript = client.audio.transcriptions.create( model='whisper-1', file=audio_file )\n"
   ],
   "id": "6d17f226244664f3"
  },
  {
   "metadata": {
    "id": "4f50814639443330"
   },
   "cell_type": "markdown",
   "source": [
    "#### Create Translation\n",
    "- Translates audio into English."
   ],
   "id": "4f50814639443330"
  },
  {
   "metadata": {
    "id": "e247d4cab1abede9"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Translation\n",
    "audio_file = open( 'speech.mp3', 'rb' )\n",
    "transcript = client.audio.translations.create( model='whisper-1', file=audio_file )\n"
   ],
   "id": "e247d4cab1abede9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Audio Output from Model",
   "id": "db9292c49f790f99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Transcription\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4o-audio-preview',\n",
    "    modalities=[ 'documents', 'audio' ],\n",
    "    audio={ 'voice': 'alloy', 'format': 'wav' },\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Is a golden retriever a good family dog?'\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ] )\n",
    "\n",
    "# Convert to bytes\n",
    "wav_bytes = base64.b64decode( completion.choices[ 0 ].message.audio.data )\n",
    "with open( 'dog.wav', 'wb' ) as f:\n",
    "    f.write( wav_bytes )"
   ],
   "id": "d16102a40689ac3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Get Audio Input from Model",
   "id": "ffebc4a744ec0084"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Fetch the audio file and convert it to a base64 encoded string\n",
    "url = 'https://cdn.openai.com/API/docs/audio/alloy.wav'\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "wav_data = response.content\n",
    "encoded_string = base64.b64encode(wav_data).decode('utf-8')\n",
    "\n",
    "# Create Completion\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4o-audio-preview',\n",
    "    modalities=['documents', 'audio'],\n",
    "    audio={'voice': 'alloy', 'format': 'wav'},\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'type': 'documents',\n",
    "                    'documents': 'What is in this recording?'\n",
    "                },\n",
    "                {\n",
    "                    'type': 'input_audio',\n",
    "                    'input_audio': {\n",
    "                        'values': encoded_string,\n",
    "                        'format': 'wav'\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ],
   "id": "7eb6e08d0a64adbf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Embedding API\n",
    "- An embedding is a vector (list) of floating point numbers.\n",
    "- The distance between two vectors measures their relatedness.\n",
    "- Small distances suggest high relatedness and large distances suggest low relatedness.\n",
    "\n",
    "##### Use Cases:\n",
    "\n",
    "- **Search** (where results are ranked by relevance to a query string)\n",
    "- **Clustering** (where text strings are grouped by similarity)\n",
    "- **Recommendations** (where items with related text strings are recommended)\n",
    "- **Anomaly Detection** (where outliers with little relatedness are identified)\n",
    "- **Diversity Measurement** (where similarity distributions are analyzed)\n",
    "- **Classification** (where text strings are classified by their most similar label)\n",
    "___"
   ],
   "id": "5d758fcd668c7d93"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Tiktoken Use\n",
    "- Split a string into tokens with OpenAI's tokenizer"
   ],
   "id": "c73cd5782d03fbd8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Count Tokens",
   "id": "9fa508dba6204bf0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def num_tokens_from_string( string: str, encoding_name: str ) -> int:\n",
    "    '''Returns the number of tokens in a documents string.'''\n",
    "    encoding = tiktoken.get_encoding( encoding_name )\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string( 'tiktoken is great!', 'cl100k_base' )\n"
   ],
   "id": "e9130c33ecb9d7cd"
  },
  {
   "metadata": {
    "id": "6d39d0b28a5bcda2"
   },
   "cell_type": "markdown",
   "source": "#### Create Ada\n",
   "id": "6d39d0b28a5bcda2"
  },
  {
   "metadata": {
    "id": "6dc14e033c7dc0de"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.embeddings.create(\n",
    "\tmodel='documents-embedding-ada-002',\n",
    "\tinput='The food was delicious and the waiter...',\n",
    "\tencoding_format='float'\n",
    ")\n"
   ],
   "id": "6dc14e033c7dc0de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Small",
   "id": "4c6f36519f4f7022"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Embedding\n",
    "def get_embedding( text, model='documents-embedding-3-small' ):\n",
    "    text = text.replace( '\\n', ' ' )\n",
    "    return client.embeddings.create( input = [text], model=model ).data[0].embedding\n"
   ],
   "id": "cec4043c3e30fe6c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Large",
   "id": "4e829f943f3b14c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Embedding\n",
    "def get_embedding( text, model='documents-embedding-3-large' ):\n",
    "    text = text.replace( '\\n', ' ' )\n",
    "    return client.embeddings.create( input = [text], model=model ).data[0].embedding"
   ],
   "id": "dfaecb5d74f2b552"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Reducing Dimensions\n",
    "- Dynamically changing the dimensions enables very flexible usage.\n",
    "- When using a vector data store that only supports embeddings up to 1024 dimensions long, developers can now still use our best embedding model text-embedding-3-large and specify a value of 1024 for the dimensions API parameter, which will shorten the embedding down from 3072 dimensions, trading off some accuracy in exchange for the smaller vector size."
   ],
   "id": "252d5f7c74cc4644"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def normalize_l2( x ):\n",
    "    x = np.array( x )\n",
    "    if x.ndim == 1:\n",
    "        norm = np.linalg.norm( x )\n",
    "        if norm == 0:\n",
    "            return x\n",
    "        return x / norm\n",
    "    else:\n",
    "        norm = np.linalg.norm( x, 2, axis=1, keepdims=True )\n",
    "        return np.where( norm == 0, x, x / norm )\n",
    "\n",
    "\n",
    "response = client.embeddings.create( model='documents-embedding-3-small',\n",
    "\tinput='Testing 123', encoding_format='float' )\n",
    "\n",
    "cut_dim = response.data[ 0 ].embedding[ :256 ]\n",
    "norm_dim = normalize_l2( cut_dim )\n",
    "\n",
    "print( norm_dim )\n"
   ],
   "id": "cd2be06e97953ed2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question & Answer\n",
    "- There are many common cases where the model is not trained on data which contains key facts and information you want to make accessible when generating responses to a user query.\n",
    "- One way of solving this, as shown below, is to put additional information into the context window of the model.\n",
    "- This is effective in many use cases but leads to higher token costs."
   ],
   "id": "18cedeef5802e6d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Query\n",
    "query = f'''\n",
    "\tUse the below article on the 2022 Winter Olympics to answer the subsequent question.\n",
    "\tIf the answer cannot be found, write 'I don't know.'\n",
    "\n",
    "\tArticle:\n",
    "\t\\'\\'\\'\n",
    "\t{wikipedia_article_on_curling}\n",
    "\t\\'\\'\\'\n",
    "\n",
    "\tQuestion: Which athletes won the gold medal in curling at the 2022 Winter Olympics?\n",
    "'''\n",
    "\n",
    "# Create Response\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You answer questions about the 2022 Winter Olympics.'},\n",
    "        {'role': 'user', 'content': query},\n",
    "    ],\n",
    "    model=GPT_MODEL,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ],
   "id": "b7d3eb7c3c3f501d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Text Search\n",
    "- To retrieve the most relevant documents, use the cosine similarity between the embedding vectors of the query and each document, and return the highest scored documents.\n"
   ],
   "id": "490f4126e43a20b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def search_reviews(df, product_description, n=3, pprint=True):\n",
    "    embedding = get_embedding(product_description, model='documents-embedding-3-small')\n",
    "    df['similarities'] = df.ada_embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
    "    res = df.sort_values('similarities', ascending=False).head(n)\n",
    "    return res\n",
    "\n",
    "res = search_reviews(df, 'delicious beans', n=3)\n"
   ],
   "id": "655c96c5053f02e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Code Search\n",
    "- Code search works similarly to embedding-based text search.\n",
    "- We provide a method to extract Python functions from all the Python files in a given repository.\n",
    "- Each function is then indexed by the **text-embedding-3-small** model.\n"
   ],
   "id": "9e6a7002183f16a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "df['code_embedding'] = df['code'].apply(lambda x: get_embedding(x, model='documents-embedding-3-small'))\n",
    "\n",
    "def search_functions(df, code_query, n=3, pprint=True, n_lines=7):\n",
    "    embedding = get_embedding(code_query, model='documents-embedding-3-small')\n",
    "    df['similarities'] = df.code_embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = df.sort_values('similarities', ascending=False).head(n)\n",
    "    return res\n",
    "\n",
    "res = search_functions(df, 'Completions API tests', n=3)\n"
   ],
   "id": "89e1080cb9c56da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Recommendations\n",
    "- Because shorter distances between embedding vectors represent greater similarity, embeddings can be useful for recommendation.\n"
   ],
   "id": "df9cf5d43dadd6e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def recommendations_from_strings( strings: List[str], index_of_source_string: int,\n",
    "    model='documents-embedding-3-small' ) -> List[int]:\n",
    "    '''Return nearest neighbors of a given string.'''\n",
    "    # get embeddings for all strings\n",
    "    embeddings = [ embedding_from_string( string, model=model ) for string in strings ]\n",
    "\n",
    "    # get the embedding of the source string\n",
    "    query_embedding = embeddings[ index_of_source_string ]\n",
    "\n",
    "    # get distances between the source embedding and other embeddings (function from embeddings_utils.py)\n",
    "    distances = distances_from_embeddings( query_embedding, embeddings, distance_metric='cosine' )\n",
    "\n",
    "    # get indices of nearest neighbors (function from embeddings_utils.py)\n",
    "    indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances( distances )\n",
    "    return indices_of_nearest_neighbors\n"
   ],
   "id": "d9a2efb8520859a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Text Featurization\n",
    "- An embedding can be used as a general free-text feature encoder within a machine learning model.\n",
    "- Incorporating embeddings will improve the performance of any machine learning model, if some of the relevant inputs are free text.\n",
    "- An embedding can also be used as a categorical feature encoder within a ML model."
   ],
   "id": "ae136c71eb89d0c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( list( df.ada_embedding.values ), df.Score,\n",
    "\ttest_size=0.2, random_state=42 )\n"
   ],
   "id": "c9b6f47f9f4561c3"
  },
  {
   "metadata": {
    "id": "2fea58c5aac941f0"
   },
   "cell_type": "markdown",
   "source": [
    "# Tools API\n",
    "- File Search augments the Assistant with knowledge from outside its model\n",
    "- Code Interpreter allows Assistants to write and run Python code in a sandboxed execution environment\n",
    "- Function calling allows you to describe functions to the Assistants API then call them\n",
    "___"
   ],
   "id": "2fea58c5aac941f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Check Weather",
   "id": "83c4737551f06998"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "tools =[\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'get_weather',\n",
    "            'description': 'Gets the current weather for a given location',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'location': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'The city and state, e.g., San Francisco, CA',\n",
    "                    },\n",
    "                    'unit': {\n",
    "                        'type': 'string',\n",
    "                        'enum': ['celsius', 'fahrenheit']\n",
    "                    }\n",
    "                },\n",
    "                'required': ['location']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "\tmodel='gpt-4o',\n",
    "\tmessages=[ { 'role': 'user', 'content': 'What is the weather like in Paris today?' } ],\n",
    "\ttools=tools\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ].message.tool_calls )\n"
   ],
   "id": "765f26d1ce687f10"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Send Email",
   "id": "6a1ac27e37fac52d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign Variables\n",
    "_tools = [\n",
    "\t{\n",
    "\t\t'type': 'function',\n",
    "\t\t'function':\n",
    "\t\t{\n",
    "\t\t\t'name': 'send_email',\n",
    "\t\t\t'description': 'Send an email to a given recipient with a subject and message.',\n",
    "\t\t\t'parameters':\n",
    "\t\t\t{\n",
    "\t\t\t\t'type': 'object',\n",
    "\t\t\t\t'properties':\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t'to':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t'type': 'string',\n",
    "\t\t\t\t\t\t'description': 'The recipient email address.'\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t'subject':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t'type': 'string',\n",
    "\t\t\t\t\t\t'description': 'Email subject line.'\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t'body':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t'type': 'string',\n",
    "\t\t\t\t\t\t'description': 'Body of the email message.'\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t},\n",
    "\t\t\t\t'required': [ 'to', 'subject', 'body' ],\n",
    "\t\t\t\t'additionalProperties': False\n",
    "\t\t\t},\n",
    "\t\t\t'strict': True\n",
    "\t\t}\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Create Completion\n",
    "completion = client.chat.completions.create(\n",
    "\tmodel='gpt-4o',\n",
    "\tmessages=[ { 'role': 'user',\n",
    "\t             'content': 'Can you send an email to terryeppler@gmail.com saying hi?' } ],\n",
    "\ttools=_tools\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ].message.tool_calls )"
   ],
   "id": "f7244dda1767837e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Search Documents",
   "id": "523e0cf03638321b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign variables\n",
    "_tools = [\n",
    "\t{\n",
    "\t\t'type': 'function',\n",
    "\t\t'function':\n",
    "\t\t\t{\n",
    "\t\t\t\t'name': 'search_knowledge_base',\n",
    "\t\t\t\t'description': 'Query a knowledge base to retrieve relevant info on a topic.',\n",
    "\t\t\t\t'parameters':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t'type': 'object',\n",
    "\t\t\t\t\t\t'properties':\n",
    "\t\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\t'query':\n",
    "\t\t\t\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\t\t\t'type': 'string',\n",
    "\t\t\t\t\t\t\t\t\t\t'description': 'The user question or search query.'\n",
    "\t\t\t\t\t\t\t\t\t},\n",
    "\t\t\t\t\t\t\t\t'options':\n",
    "\t\t\t\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\t\t\t'type': 'object',\n",
    "\t\t\t\t\t\t\t\t\t\t'properties':\n",
    "\t\t\t\t\t\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'num_results':\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'type': 'number',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'description': 'Number of top results to return.'\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t},\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'domain_filter':\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'type':\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t[ 'string', 'null' ],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'description': 'Optional domain to narrow the search. Pass null if not needed.'\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t},\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'sort_by':\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'type':\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t[ 'string', 'null' ],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'enum':\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t[ 'relevance', 'date', 'popularity', 'alphabetical' ],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'description': 'How to sort results. Pass null if not needed.'\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\t\t\t\t\t},\n",
    "\t\t\t\t\t\t\t\t\t\t'required':\n",
    "\t\t\t\t\t\t\t\t\t\t[ 'num_results', 'domain_filter', 'sort_by' ],\n",
    "\t\t\t\t\t\t\t\t\t\t'additionalProperties': False\n",
    "\t\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\t},\n",
    "\t\t\t\t\t\t'required':\n",
    "\t\t\t\t\t\t[ 'query', 'options' ],\n",
    "\t\t\t\t\t\t'additionalProperties': False\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t'strict': True\n",
    "\t\t\t}\n",
    "\t}\n",
    "]\n",
    "\n",
    "_messages = [\n",
    "\t{\n",
    "\t\t'role': 'user',\n",
    "\t\t'content': 'Can you find information about ChatGPT in the AI knowledge base?'\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Create completion\n",
    "completion = client.chat.completions.create( model='gpt-4o', messages=_messages, tools=tools )\n",
    "\n",
    "print( completion.choices[ 0 ].message.tool_calls )"
   ],
   "id": "977000b1ed22ef92"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Search Web",
   "id": "de33e4e44a5bd66b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign variables\n",
    "_model = 'gpt-4o-search-preview'\n",
    "_message = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'What was a positive news story from today?',\n",
    "        } \n",
    "]\n",
    "\n",
    "# Create completion\n",
    "completion = client.chat.completions.create( model=_model, web_search_options={},\n",
    "    messages=_message )\n",
    "\n",
    "print( completion.choices[ 0 ].message.content )"
   ],
   "id": "33ceccafde8c557d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### File Search",
   "id": "dca98e676fedf65d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Step 1: Create a new Assistant with File Search Enabled\n",
    "assistant = client.beta.assistants.create(\n",
    "  name='Financial Analyst Assistant',\n",
    "  instructions='You are an expert financial analyst. Use you knowledge base to answer questions about audited financial statements.',\n",
    "  model='gpt-4o',\n",
    "  tools=[{'type': 'file_search'}],\n",
    ")\n",
    "\n",
    "# Step 2: Upload files and add them to a Vector Store\n",
    "vector_store = client.vector_stores.create( name='Financial Statements' )\n",
    "file_paths = [ 'edgar/goog-10k.pdf', 'edgar/brka-10k.txt' ]\n",
    "file_streams = [ open( path, 'rb' ) for path in file_paths ]\n",
    "file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "print( file_batch.status )\n",
    "print( file_batch.file_counts )\n",
    "\n",
    "# Step 3: Update the assistant to use the new Vector Store\n",
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={'file_search': {'vector_store_ids': [vector_store.id]}},\n",
    ")\n",
    "\n",
    "# Step 4: Create a thread\n",
    "message_file = client.files.create(\n",
    "  file=open('edgar/aapl-10k.pdf', 'rb'), purpose='assistants'\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': 'How many shares of AAPL were outstanding at the end of of October 2023?',\n",
    "      'attachments': [\n",
    "        { 'file_id': message_file.id, 'tools': [{'type': 'file_search'}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "print( thread.tool_resources.file_search )\n",
    "\n",
    "# Step 5: Create a run and check the output\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id, assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f'[{index}]')\n",
    "    if file_citation := getattr(annotation, 'file_citation', None):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f'[{index}] {cited_file.filename}')\n",
    "\n",
    "print(message_content.value)\n",
    "print('\\n'.join(citations))\n",
    "\n",
    "\n",
    "print(response)"
   ],
   "id": "b6b93701524b2804"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Use Browser",
   "id": "b4e58145c3fe0659"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign variables\n",
    "_args = [ '--disable-extensions', '--disable-file-system' ]\n",
    "\n",
    "with sync_playwright() as p:\n",
    "    browser = p.chromium.launch( headless=False, chromium_sandbox=True,\n",
    "        env={}, args=_args )\n",
    "    \n",
    "    page = browser.new_page( )\n",
    "    page.set_viewport_size( {'width': 1024, 'height': 768} )\n",
    "    page.goto( 'https://bing.com' )\n",
    "\n",
    "    page.wait_for_timeout( 10000 )"
   ],
   "id": "d631d1de28a48f55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Use Computer",
   "id": "6f002157c8565135"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign Variables\n",
    "_model = 'computer-use-preview'\n",
    "_reasoning = { 'generate_summary': 'concise', }\n",
    "_truncation = 'auto'\n",
    "_tools = [\n",
    "\t{\n",
    "        'type': 'computer_use_preview',\n",
    "        'display_width': 1024,\n",
    "        'display_height': 768,\n",
    "        'environment': 'browser' # other possible values: 'mac', 'windows', 'ubuntu'\n",
    "    }\n",
    "]\n",
    "\n",
    "_input = [\n",
    "\t{\n",
    "            'role': 'user',\n",
    "            'content': 'Check the latest OpenAI news on bing.com.'\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create( model=_model, tools=_tools, input=_input,\n",
    "    reasoning=_reasoning, truncation='auto' )\n",
    "\n",
    "print( response.output )"
   ],
   "id": "1cfbca5363e7cd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Send Computer Use Request",
   "id": "7f93e2f19fe41874"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Send a request to create a Response with the **computer-use-preview** model equipped with the computer_use_preview tool.\n",
    "- This request should include details about your environment, along with an initial input prompt."
   ],
   "id": "d8aa79fb086aa0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign variables\n",
    "_model = 'computer-use-preview'\n",
    "_tools = [\n",
    "\t{\n",
    "        'type': 'computer_use_preview',\n",
    "        'display_width': 1024,\n",
    "        'display_height': 768,\n",
    "        'environment': 'browser' # other possible values: 'mac', 'windows', 'ubuntu'\n",
    "    }\n",
    "]\n",
    "\n",
    "_input = [\n",
    "\t{\n",
    "            'role': 'user',\n",
    "            'content': 'Check the latest OpenAI news on bing.com.'\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Create response\n",
    "response = client.responses.create( model=_model, tools=_tools, input=_input,\n",
    "    reasoning={ 'generate_summary': 'concise', }, truncation='auto' )\n",
    "\n",
    "print( response.output )"
   ],
   "id": "1669192c119728b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Execution Action",
   "id": "e04d112b001ed974"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Execute the corresponding actions on your computer or browser.\n",
    "- How you map a computer call to actions through code depends on your environment.\n",
    "- This code shows example implementations for the most common computer actions."
   ],
   "id": "c8a1a66fbcdc3ac9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def handle_model_action( page, action ):\n",
    "    '''\n",
    "    \n",
    "\t\tGiven a computer action (e.g., click, double_click, scroll, resources.),\n",
    "\t\texecute the corresponding operation on the Playwright page.\n",
    "\t\t\n",
    "    '''\n",
    "    action_type = action.type\n",
    "    try:\n",
    "        match action_type:\n",
    "            case 'click':\n",
    "                x, y = action.x, action.y\n",
    "                button = action.button\n",
    "                print( f\"Action: click at ({x}, {y}) with button '{button}' \" )\n",
    "                # Not handling things like middle click, resources.\n",
    "                if button != 'left' and button != 'right':\n",
    "                    button = 'left'\n",
    "                page.mouse.click( x, y, button=button )\n",
    "\n",
    "            case 'scroll':\n",
    "                x, y = action.x, action.y\n",
    "                scroll_x, scroll_y = action.scroll_x, action.scroll_y\n",
    "                print(f'Action: scroll at ({x}, {y}) with offsets (scroll_x={scroll_x}, scroll_y={scroll_y})')\n",
    "                page.mouse.move( x, y )\n",
    "                page.evaluate( f'window.scrollBy({scroll_x}, {scroll_y})' )\n",
    "\n",
    "            case 'keypress':\n",
    "                keys = action.keys\n",
    "                for k in keys:\n",
    "                    print( f\"Action: keypress '{k}' \" )\n",
    "                    # A simple mapping for common keys; expand as needed.\n",
    "                    if k.lower( ) == 'enter':\n",
    "                        page.keyboard.press( 'Enter' )\n",
    "                    elif k.lower( ) == 'space':\n",
    "                        page.keyboard.press( ' ' )\n",
    "                    else:\n",
    "                        page.keyboard.press( k )\n",
    "\n",
    "            case 'type':\n",
    "                text = action.text\n",
    "                print( f'Action: type documents: {text}' )\n",
    "                page.keyboard.type( text )\n",
    "\n",
    "            case 'wait':\n",
    "                print( f'Action: wait' )\n",
    "                time.sleep( 2 )\n",
    "\n",
    "            case 'screenshot':\n",
    "                # Nothing to do as screenshot is taken at each turn\n",
    "                print( f'Action: screenshot' )\n",
    "\n",
    "            # Handle other actions here\n",
    "\n",
    "            case _:\n",
    "                print( f'Unrecognized action: {action}' )\n",
    "\n",
    "    except Exception as e:\n",
    "        print( f'Error handling action {action}: {e}' )"
   ],
   "id": "ebe900fccd4c78c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Capture Screenshot",
   "id": "fe7ef876f73d6cca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- After executing the action, capture the updated state of the environment as a screenshot, which also differs depending on your environment.",
   "id": "6d03e32c9b40c799"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_screenshot( page ):\n",
    "    '''\n",
    "    \n",
    "    \tTake a full-page screenshot using Playwright and return the image bytes.\n",
    "    \t\n",
    "    '''\n",
    "    return page.screenshot()"
   ],
   "id": "33925edc5d07ae97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a8ffd9479ab9a83e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Repeating Loop",
   "id": "3517e91b75cfabb1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Once you have the screenshot, you can send it back to the model as a **computer_call_output** to get the next action.\n",
    "- Repeat these steps as long as you get a **computer_call** item in the response."
   ],
   "id": "c08830b946d8bad9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def computer_use_loop( instance, response ):\n",
    "    '''\n",
    "    \tRun the loop that executes computer actions until no 'computer_call' is found.\n",
    "    '''\n",
    "    while True:\n",
    "        computer_calls = [ item for item in response.output if item.type == 'computer_call' ]\n",
    "        if not computer_calls:\n",
    "            print( 'No computer call found. Output from model:' )\n",
    "            for item in response.output:\n",
    "                print( item )\n",
    "            break  # Exit when no computer calls are issued.\n",
    "\n",
    "        # We expect at most one computer call per response.\n",
    "        computer_call = computer_calls[ 0 ]\n",
    "        last_call_id = computer_call.call_id\n",
    "        action = computer_call.action\n",
    "\n",
    "        # Execute the action (function defined in step 3)\n",
    "        handle_model_action( instance, action )\n",
    "        time.sleep( 1 )  # Allow time for changes to take effect.\n",
    "\n",
    "        # Take a screenshot after the action (function defined in step 4)\n",
    "        screenshot_bytes = get_screenshot( instance )\n",
    "        screenshot_base64 = base64.b64encode( screenshot_bytes ).decode( 'utf-8' )\n",
    "\n",
    "        # Send the screenshot back as a computer_call_output\n",
    "        response = client.responses.create(\n",
    "            model='computer-use-preview',\n",
    "            previous_response_id=response.id,\n",
    "            tools=[\n",
    "                {\n",
    "                    'type': 'computer_use_preview',\n",
    "                    'display_width': 1024,\n",
    "                    'display_height': 768,\n",
    "                    'environment': 'browser'\n",
    "                }\n",
    "            ],\n",
    "            input=[\n",
    "                {\n",
    "                    'call_id': last_call_id,\n",
    "                    'type': 'computer_call_output',\n",
    "                    'output': {\n",
    "                        'type': 'input_image',\n",
    "                        'image_url': f'values:image/png;base64,{screenshot_base64}'\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            truncation='auto'\n",
    "        )\n",
    "\n",
    "    return response"
   ],
   "id": "1da6090518887d73"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create VectorStore",
   "id": "acb748ad7151f482"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a vector store caled 'Financial Statements'\n",
    "vector_store = client.vector_stores.create(name='Financial Statements')\n",
    "\n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = ['edgar/goog-10k.pdf', 'edgar/brka-10k.txt']\n",
    "file_streams = [open(path, 'rb') for path in file_paths]\n",
    "\n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ],
   "id": "b1ae27e26b7fd06d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Files API\n",
    "- Upload up to 100 pages and 32MB of total content in a single request to the API, across multiple file inputs.\n",
    "- Only models that support both text and image inputs, such as gpt-4o, gpt-4o-mini, or o1, can accept PDF files as input\n",
    "- Recommend using the user_data purpose for files you plan to use as model inputs.\n",
    "___"
   ],
   "id": "9ca883a9e1a75ea5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Upload\n",
    "- Upload a PDF using the Files API, then reference its file ID in an API request to the model."
   ],
   "id": "f929960a9efe33d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign vriables\n",
    "_messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'type': 'file',\n",
    "                    'file':\n",
    "\t                {\n",
    "                        'file_id': file.id,\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'type': 'documents',\n",
    "                    'documents': 'What is the first dragon in the book?',\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "]\n",
    "\n",
    "# Create File Request\n",
    "file = client.files.create( file=open( 'draconomicon.pdf', 'rb' ), purpose='user_data' )\n",
    "completion = client.chat.completions.create( model='gpt-4o', messages=_messages, )\n",
    "\n",
    "print( completion.choices[ 0 ].message.content )"
   ],
   "id": "f67de4bc69a2a23d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### List",
   "id": "aa4daee5f20bbed3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:20:16.554306Z",
     "start_time": "2025-04-05T08:20:15.882878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "_files = client.files.list()\n",
    "\n",
    "for i in _files:\n",
    "\tprint( i )\n"
   ],
   "id": "fce6a758df7ecead",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Create client\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m client \u001B[38;5;241m=\u001B[39m \u001B[43mOpenAI\u001B[49m( )\n\u001B[0;32m      3\u001B[0m client\u001B[38;5;241m.\u001B[39mapi_key \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetenv( \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOPENAI_API_KEY\u001B[39m\u001B[38;5;124m'\u001B[39m )\n\u001B[0;32m      5\u001B[0m _files \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mfiles\u001B[38;5;241m.\u001B[39mlist()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'OpenAI' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Retreive File",
   "id": "119481b90b81b060"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Reteive by file_id\n",
    "client.files.retrieve( 'file-abc123' )\n"
   ],
   "id": "965e3286ecc2d79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Reteive Contents",
   "id": "f69abf06c4eafe11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "content = client.files.content( 'file-abc123' )\n"
   ],
   "id": "88925f2c09a44d16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Upload",
   "id": "d382cf0af90b2de4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.files.create( file=open('mydata.jsonl', 'rb'), purpose='fine-tune' )\n"
   ],
   "id": "9f67d49ba88d38ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3efe7dc5e48266e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "96e522e64848135f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Base64-encoded files\n",
    "- You can send PDF file inputs as Base64-encoded inputs as well."
   ],
   "id": "6e99da7e11a87f50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "with open( 'draconomicon.pdf', 'rb' ) as f:\n",
    "    data = f.read( )\n",
    "\n",
    "base64_string = base64.b64encode( data ).decode( 'utf-8' )\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'type': 'file',\n",
    "                    'file':\n",
    "\t                {\n",
    "                        'filename': 'draconomicon.pdf',\n",
    "                        'file_data': f'values:application/pdf;base64,{base64_string}',\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'type': 'documents',\n",
    "                    'documents': 'What is the first dragon in the book?',\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ].message.content )"
   ],
   "id": "9dedf86a63db689f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Retreival API\n",
    "- The Retrieval API allows you to perform semantic search over your data, which is a technique that surfaces semantically similar results — even when they match few or no keywords.\n",
    "- The Retrieval API is powered by vector stores, which serve as indices for your data.\n",
    "___"
   ],
   "id": "a50edf1ae3361954"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Upload",
   "id": "31252b9607a71e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "vector_store = client.vector_stores.create( name='Support FAQ' )\n",
    "client.vector_stores.files.upload_and_poll(  vector_store_id=vector_store.id,\n",
    "    file=open( 'customer_policies.txt', 'rb' ) )"
   ],
   "id": "6c18fd89469c0f54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Search Stores",
   "id": "2fec5e4852fc5c27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create search\n",
    "user_query = 'What is the return policy?'\n",
    "results = client.vector_stores.search( vector_store_id=vector_store.id, query=user_query, )"
   ],
   "id": "9aab2bf7205e3bb9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Semantic Search",
   "id": "89e5cbb85a08cdf6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "results = client.vector_stores.search( vector_store_id=vector_store.id,\n",
    "    query='How many woodchucks are allowed per passenger?', )"
   ],
   "id": "24d3b604818a4c4c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "93af0ae928fe219f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "# Initialize the client\n",
    "data_client = DataAPIClient( 'YOUR_TOKEN' )\n",
    "url = 'https://f9c2ce0a-d399-4670-8989-302798d48696-westus3.apps.astra.datastax.com'\n",
    "db = data_client.get_database_by_api_endpoint( url )\n",
    "\n",
    "print( f'Connected to Astra DB: {db.list_collection_names( )}' )"
   ],
   "id": "cb376e9f1b7edb26"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Vector Store API\n",
    "- Vector stores are the containers that power semantic search for the Retrieval API and the Assistants API file search tool.\n",
    "- When you add a file to a vector store it will be automatically chunked, embedded, and indexed.\n",
    "- ___"
   ],
   "id": "be2cc49a73407a4a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### I. Vector Store Operations",
   "id": "ca588f7dcdb197e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create",
   "id": "ab17f992fe0c8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create vector store\n",
    "client.vector_stores.create( name='Support FAQ', file_ids=[ 'file_123' ] )"
   ],
   "id": "d94e42c2ac8099f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Retrieve",
   "id": "1b0c4fa721cd030"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Retreive vector store\n",
    "client.vector_stores.retrieve( vector_store_id='vs_123' )"
   ],
   "id": "9406837b98028fd1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Update",
   "id": "4edf82399108961f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Update vector store\n",
    "client.vector_stores.retrieve(  vector_store_id='vs_123' )"
   ],
   "id": "b749f3548bed8ac5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Delete",
   "id": "b7d769b3595f8e26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Delete vector store\n",
    "client.vector_stores.delete( vector_store_id='vs_123' )"
   ],
   "id": "8063dc3580e8020a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### List",
   "id": "c2a44c35871c29c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List stores\n",
    "client.vector_stores.list( )"
   ],
   "id": "1bdeffc856f4ff0a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### II. Vector File Operations",
   "id": "3578fa99af2f88cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create",
   "id": "3c40ae41d1ae8467"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create files for vector store\n",
    "client.vector_stores.files.create(\n",
    "    vector_store_id='vs_123',\n",
    "    file_id='file_123',\n",
    "    attributes={\n",
    "        'region': 'US',\n",
    "        'category': 'Marketing',\n",
    "        'date': 1672531200      # Jan 1, 2023\n",
    "    }\n",
    ")"
   ],
   "id": "984ffe86987d9272"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Upload",
   "id": "56f14ab34778d2cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.files.upload_and_poll( vector_store_id='vs_123',\n",
    "    file=open('customer_policies.txt', 'rb') )\n"
   ],
   "id": "ed29df05e7a77f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Retreive",
   "id": "1336958964d59639"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.files.retrieve( vector_store_id='vs_123', file_id='file_123' )\n"
   ],
   "id": "f6c802de56bc052f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Update",
   "id": "5e74af88e92efca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Update file\n",
    "client.vector_stores.files.update(\n",
    "    vector_store_id='vs_123',\n",
    "    file_id='file_123',\n",
    "    attributes={'key': 'value'}\n",
    ")\n"
   ],
   "id": "f443a34c5826ccce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Delete",
   "id": "3492950c03e4fa97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Delete file\n",
    "client.vector_stores.files.delete( vector_store_id='vs_123', file_id='file_123' )\n"
   ],
   "id": "e0be6eee50dc28f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### List",
   "id": "c8c69370ca89033e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List files\n",
    "client.vector_stores.files.list( vector_store_id='vs_123' )\n"
   ],
   "id": "be5f037d2876f58d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### II. Vector Batch Operations",
   "id": "483a13c1a68c6672"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create",
   "id": "46890148f4fd4492"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.file_batches.create_and_poll( vector_store_id='vs_123',\n",
    "    file_ids=['file_123', 'file_456'] )\n"
   ],
   "id": "31c7761d9c3cf90f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Retrieve",
   "id": "dad42758272e6fa2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.file_batches.retrieve( vector_store_id='vs_123', batch_id='vsfb_123' )\n"
   ],
   "id": "2492bf72c3ce319f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Cancel",
   "id": "141a54906fa93785"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.file_batches.cancel( vector_store_id='vs_123', batch_id='vsfb_123' )\n"
   ],
   "id": "1bc11b59e12ed29a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### List",
   "id": "ac479dc7694ce178"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.file_batches.list( vector_store_id='vs_123' )\n"
   ],
   "id": "8894cf9d1c7299b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Assistant API\n",
    "- Designed to help developers build powerful AI assistants capable of performing a variety of tasks.\n",
    "- Build AI assistants within your own applications.\n",
    "##### Supports the following tools:\n",
    "1. Code Interpreter\n",
    "2. File Search\n",
    "3. Function calling.\n",
    "___"
   ],
   "id": "9df6bbfe74f1da68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create assistant",
   "id": "7789133558f7399"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions='You are a personal math tutor. When asked a question, write and run Python code to answer the question.',\n",
    "    name='Math Tutor',\n",
    "    tools=[{'type': 'code_interpreter'}],\n",
    "    model='gpt-4o',\n",
    ")\n",
    "print(my_assistant)\n"
   ],
   "id": "79e8b17900a8609f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### List Assistants",
   "id": "82a4101059ca8d08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_assistants = client.beta.assistants.list(\n",
    "    order='desc',\n",
    "    limit='20',\n",
    ")\n",
    "print(my_assistants.data)\n"
   ],
   "id": "3369688ba307f2d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Retreive Assistant",
   "id": "24c75f00b49c0fa5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_assistant = client.beta.assistants.retrieve('asst_abc123')\n",
    "print(my_assistant)\n"
   ],
   "id": "e270cdaaeedd8fc9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Update Assistant",
   "id": "69d2d0f1876ed9f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_updated_assistant = client.beta.assistants.update(\n",
    "  'asst_abc123',\n",
    "  instructions='You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.',\n",
    "  name='HR Helper',\n",
    "  tools=[{'type': 'file_search'}],\n",
    "  model='gpt-4o'\n",
    ")\n",
    "\n",
    "print(my_updated_assistant)\n"
   ],
   "id": "6a6a6aa07bfe1a45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Delete Assistant",
   "id": "2eedf073dcf80352"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "response = client.beta.assistants.delete('asst_abc123')\n",
    "print(response)\n"
   ],
   "id": "bec93c14671449b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### I. Threads",
   "id": "d3b53aefaed1b702"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create",
   "id": "decf426a6e9e82af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "empty_thread = client.beta.threads.create()\n",
    "print(empty_thread)\n"
   ],
   "id": "124407263bed255f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Retreive",
   "id": "268461d8664a1afd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_thread = client.beta.threads.retrieve('thread_abc123')\n",
    "print(my_thread)\n"
   ],
   "id": "f1d01d205758758c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Update",
   "id": "db5a156c21b07875"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_updated_thread = client.beta.threads.update(\n",
    "  'thread_abc123',\n",
    "  metadata={\n",
    "    'modified': 'true',\n",
    "    'user': 'abc123'\n",
    "  }\n",
    ")\n",
    "print(my_updated_thread)\n"
   ],
   "id": "15d7587e415aeb1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Delete",
   "id": "f7574157ea64d69a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "response = client.beta.threads.delete('thread_abc123')\n",
    "print(response)\n"
   ],
   "id": "2e76400ac172a239"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### II. Messages",
   "id": "d38f1c9b23d0a6f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create",
   "id": "53032868026c88dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create message\n",
    "thread_message = client.beta.threads.messages.create( 'thread_abc123',  role='user',\n",
    "  content='How does AI work? Explain it in simple terms.', )\n",
    "\n",
    "print(thread_message)\n"
   ],
   "id": "81d79cd2c1706312"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### List",
   "id": "13656b055bff5d16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List messages in a thread\n",
    "thread_messages = client.beta.threads.messages.list( 'thread_abc123' )\n",
    "print(thread_messages.data)\n"
   ],
   "id": "7f0520e6a197fb69"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Retreive",
   "id": "bc76238baa324952"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Retreive messages from thread\n",
    "message = client.beta.threads.messages.retrieve(\n",
    "  message_id='msg_abc123',\n",
    "  thread_id='thread_abc123',\n",
    ")\n",
    "print(message)\n"
   ],
   "id": "52c0b73d716944e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Update",
   "id": "45611582952a3fb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Update messages in thread\n",
    "message = client.beta.threads.messages.update(\n",
    "  message_id='msg_abc12',\n",
    "  thread_id='thread_abc123',\n",
    "  metadata={\n",
    "    'modified': 'true',\n",
    "    'user': 'abc123',\n",
    "  },\n",
    "\n",
    ")\n",
    "print(message)\n"
   ],
   "id": "4b443485eec43e35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Delete",
   "id": "76e60dddc54098e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Delete messages in thread\n",
    "deleted_message = client.beta.threads.messages.delete(  message_id='msg_abc12',\n",
    "\tthread_id='thread_abc123', )\n",
    "\n",
    "print(deleted_message)\n"
   ],
   "id": "87d4179d0a84fb4e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
