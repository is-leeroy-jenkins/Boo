{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "<a href='https://colab.research.google.com/github/is-leeroy-jenkins/Boo/blob/main/ipynb/GPT.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>",
   "id": "6b5948d8e77a7699"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b752f6d30e042eaa"
  },
  {
   "metadata": {
    "id": "6f5de4ab069df199"
   },
   "cell_type": "markdown",
   "source": "###### Load Dependencies",
   "id": "6f5de4ab069df199"
  },
  {
   "metadata": {
    "id": "98ca47c4dd694371",
    "ExecuteTime": {
     "end_time": "2025-04-10T15:02:17.935556Z",
     "start_time": "2025-04-10T15:02:14.707798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from playwright.sync_api import sync_playwright\n",
    "from agents import Agent, Runner\n",
    "import tiktoken\n",
    "import base64\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from static import GptRequests, GptRoles, GptLanguages\n",
    "from booger import Error, ErrorDialog, ChatWindow, FileDialog, FileBrowser\n",
    "from importlib import reload"
   ],
   "id": "98ca47c4dd694371",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "id": "a9f52a9d4000c649"
   },
   "cell_type": "markdown",
   "source": [
    "# Completion API\n",
    "- Generates a model response from a list of messages comprising a conversation.\n",
    "- Parameter support can differ depending on the model used to generate the response\n",
    "___"
   ],
   "id": "a9f52a9d4000c649"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Message Format",
   "id": "615d70c29cbb0f55"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "messages=\\\n",
    "[\n",
    "    {\n",
    "        'role': 'system',\n",
    "\t    'content': 'SYSTEM_INSTRUCTIONS'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "\t    'content': 'USER_MESSAGE_CONTENT'\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "\t    'content': 'ASSISTANT_MESSAGE_CONTENT'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "\t    'content': 'USER_MESSAGE_CONTENT'\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "\t    'content': 'ASSISTANT_MESSAGE_CONTENT'\n",
    "    }\n",
    "]"
   ],
   "id": "869c2f8153b2e688"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Instructions",
   "id": "de1833a47bb6083b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:46:27.642903Z",
     "start_time": "2025-04-10T14:46:27.635098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_instructions = r'''\n",
    "You are the most knowledgeable Budget Analyst in the federal government who provides detailed responses based on your vast knowledge of federal appropriations.\n",
    "Your responses to questions about federal finance are complete, transparent, and very detailed using an academic format.\n",
    "Your vast knowledge of and experience in Data Science makes you the best Data Analyst in the world. You are proficient in C#, Python, SQL, C++, JavaScript, and VBA.\n",
    "You use US federal budget data from OMB, whitehouse.gov, or data.gov for any ad hoc data sets in examples you.\n",
    "You do your analysis in Python and visualizations with matplotlib or seaborn. You are famous for the accuracy of your responses so you verify all your answers.\n",
    "Your name is Bubba.\n",
    "'''"
   ],
   "id": "9306b9d08c3acdbe",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Prompt",
   "id": "68ea5ca4ca76c023"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:46:30.544492Z",
     "start_time": "2025-04-10T14:46:30.535452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_propmt = r'''\n",
    "What was a positive news story from today?\n",
    "'''"
   ],
   "id": "7e983b2de2c9e9fe",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### System Message",
   "id": "ea0f9e739b9932b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "{\n",
    "    'role': 'system',\n",
    "    'content': system_instructions\n",
    "}"
   ],
   "id": "8771302c7428ffff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### User Message",
   "id": "5cc765fa41e12425"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "    'role': 'user',\n",
    "    'content': user_prompt\n",
    "}"
   ],
   "id": "183c7e7e355ae75b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Developer Message",
   "id": "38d6e256e900377a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "    'role': 'developer',\n",
    "    'content': user_prompt\n",
    "}"
   ],
   "id": "df3f64a5d869e778"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Tool Message",
   "id": "945c8321c1afe808"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "    'role': 'tool',\n",
    "    'content': user_prompt\n",
    "}"
   ],
   "id": "68028f73e6f05fab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Response Format\n",
    "- 'choices'\n",
    "- `completion.choices[ 0 ].message`"
   ],
   "id": "c5fc32d1cf3f9952"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "[\n",
    "    {\n",
    "        'index': 0,\n",
    "        'message':\n",
    "        {\n",
    "            'role': 'assistant',\n",
    "            'content': 'Under the soft glow of the moon, Luna the unicorn danced through fields of twinkling stardust, leaving trails of dreams for every child asleep.',\n",
    "            'refusal': null\n",
    "         },\n",
    "         'logprobs': null,\n",
    "         'finish_reason': 'stop'\n",
    "    }\n",
    "]"
   ],
   "id": "ff49ede8849de01c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Completion API\n",
    "- Generates a model response from a list of messages comprising a conversation.\n",
    "- Parameter support can differ depending on the model used to generate the response\n",
    "___"
   ],
   "id": "c32d56638423da1f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create",
   "id": "7f03d6a6cce47a8"
  },
  {
   "metadata": {
    "id": "42101fefd439757a",
    "outputId": "a17acaed-b8b2-4ceb-c9d3-14191b2f96c9",
    "ExecuteTime": {
     "end_time": "2025-04-09T14:41:06.195014Z",
     "start_time": "2025-04-09T14:40:56.437322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Completion\n",
    "completion = client.chat.completions.create(\n",
    "\tmodel='gpt-4o',\n",
    "\tmessages=\n",
    "\t[\n",
    "\t\t{\n",
    "\t\t\t'role': 'system',\n",
    "\t\t\t'content': 'You are a helpful assistant.'\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t'role': 'user',\n",
    "\t\t\t'content': 'What is a Treasury Symbol?'\n",
    "\t\t}\n",
    "\t]\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ].message )"
   ],
   "id": "42101fefd439757a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='A Treasury Symbol is a code used within the United States Department of the Treasury for accounting and financial management purposes. It generally refers to the \"Treasury Account Symbol\" (TAS), which is a critical part of the federal government\\'s accounting system. The Treasury Account Symbol is used to identify individual appropriation, fund, and receipt accounts maintained by the Department of the Treasury. \\n\\nThe TAS is made up of various codes that provide information about:\\n\\n1. **Agency Identifier**: The specific government agency or department that manages the account.\\n2. **Bureau Identifier**: Further specifies which bureau or component within the agency is responsible for the account.\\n3. **Fiscal Year Code**: Indicates the fiscal year for which the funds are available.\\n4. **Main Account Code**: Identifies the main purpose of the account.\\n5. **Sub-Account Code**: Provides more detailed information about the account.\\n\\nThese symbols are essential for tracking government spending, ensuring financial control, and maintaining accountability within the federal financial management system. They are used extensively in federal financial reporting and help in organizing the complex data related to public finances.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[])\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "id": "aa8e8b3a885a7bab"
   },
   "cell_type": "markdown",
   "source": [
    "### Retreive\n",
    "- ( store=True )\n"
   ],
   "id": "aa8e8b3a885a7bab"
  },
  {
   "metadata": {
    "id": "67ffaed532fe0dc1",
    "outputId": "f8843a06-944f-45fe-cdbc-655f0201acbb"
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Completion\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "first_completion = client.chat.completions.retrieve( completion_id=first_id )\n",
    "print( first_completion )"
   ],
   "id": "67ffaed532fe0dc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "b530f9aee20cce11"
   },
   "cell_type": "markdown",
   "source": "### View",
   "id": "b530f9aee20cce11"
  },
  {
   "metadata": {
    "id": "f2784968574ff7c8",
    "outputId": "46c97a49-2c63-4fcb-ae4a-698ce45aa2bd"
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Completion\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "first_completion = client.chat.completions.retrieve( completion_id=first_id )\n",
    "messages = client.chat.completions.messages.list( completion_id=first_id )\n",
    "print( messages )"
   ],
   "id": "f2784968574ff7c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "9c62391ecc6da73f"
   },
   "cell_type": "markdown",
   "source": "### List",
   "id": "9c62391ecc6da73f"
  },
  {
   "metadata": {
    "id": "f5a72eef452bbc22",
    "ExecuteTime": {
     "end_time": "2025-04-09T14:36:28.273892Z",
     "start_time": "2025-04-09T14:36:24.718037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Compmletion\n",
    "completions = client.chat.completions.list( )\n",
    "print( completions )\n"
   ],
   "id": "f5a72eef452bbc22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[ChatCompletion](data=[ChatCompletion(id='chatcmpl-BIjZyMyT9NqmSUfzVLoBpGaOQi2GP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Capital inquiry answered.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1743804810, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=None, request_id='req_3643368cbe028d2db6d2264e89e53118', tool_choice=None, seed=6966577916535662517, top_p=0.4000000059604645, temperature=0.699999988079071, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format=None), ChatCompletion(id='chatcmpl-BIjZyGNQRYelvD1TYkMuVMre3SoO0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The capital of France is Paris.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1743804810, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=None, request_id='req_e4df001da59b88a623baca1e6973c7ef', tool_choice=None, seed=1115423518260727959, top_p=0.4000000059604645, temperature=0.699999988079071, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format=None), ChatCompletion(id='chatcmpl-BIdc991yFpaYLmdIRFVE5e8NVA0qZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='An appropriation is an authorization by a legislative body, typically a parliament or congress, to allocate a specific amount of money for a particular purpose or project. This allocation allows government agencies or departments to incur obligations and make payments out of government funds. Appropriations are part of the budgeting process and play a critical role in ensuring that government operations and services are funded appropriately.\\n\\nThere are different types of appropriations, including:\\n\\n1. **Annual Appropriations**: These are regular budgetary allocations made each fiscal year to fund ongoing operations and activities.\\n\\n2. **Supplemental Appropriations**: These are additional funds allocated outside the regular budget cycle, often to address unforeseen expenditures or emergencies.\\n\\n3. **Continuing Appropriations**: Sometimes known as continuing resolutions, these are temporary funds provided to keep government operations running when the regular appropriations process is delayed or incomplete.\\n\\n4. **Permanent Appropriations**: These are funds automatically available each year without requiring an annual legislative approval.\\n\\nOverall, the appropriation process is crucial for maintaining governmental accountability and ensuring that taxpayer money is used effectively and in alignment with legislative priorities.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1743781881, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_898ac29719', usage=CompletionUsage(completion_tokens=227, prompt_tokens=23, total_tokens=250, completion_tokens_details=None, prompt_tokens_details=None), request_id='req_fb7070d0428d3ee154148cb78f25ecb6', tool_choice=None, seed=5145250467338064129, top_p=1.0, temperature=1.0, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format=None), ChatCompletion(id='chatcmpl-BH7Ygml5BGRawQt0JrmdOnQH1orrQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='An appropriation is a legislative act or measure that authorizes the expenditure of government funds for specific purposes. It involves the allocation of a specific amount of money from the public treasury to finance government activities, programs, or operations. \\n\\nAppropriations are typically made through legislation passed by the legislative branch of the government, such as Congress in the United States. These appropriations bills specify how much money will be made available and outline how it is to be spent by various government departments and agencies. The process ensures that government spending is controlled and monitored, safeguarding against unnecessary or unauthorized expenditures.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1743420330, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_898ac29719', usage=CompletionUsage(completion_tokens=117, prompt_tokens=23, total_tokens=140, completion_tokens_details=None, prompt_tokens_details=None), request_id='req_54a40829c55adc2638b647f59bec7b15', tool_choice=None, seed=6828386728514064892, top_p=1.0, temperature=1.0, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format=None), ChatCompletion(id='chatcmpl-BGoDR3tCJ3RnU8Dv4Gy7iqg6r9epp', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Certainly! The Anti-Deficiency Act, codified in Public Law 97-258, is a cornerstone of federal financial management, aiming to ensure fiscal responsibility and accountability within federal agencies. Here’s a detailed summary of its key components and implications:\\n\\n', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1743345977, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_de57b65c90', usage=CompletionUsage(completion_tokens=50, prompt_tokens=15424, total_tokens=15474, completion_tokens_details=None, prompt_tokens_details=None), request_id='req_60bfdac7274eaebeabdc9813ea24f00c', tool_choice=None, seed=3130033556828139688, top_p=0.9, temperature=0.8, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'text', 'json_schema': None}), ChatCompletion(id='chatcmpl-BGoBfxzuu5N8EHNzkJWtfgjPT5way', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Certainly! \"Principles of Federal Appropriations Law,\" commonly known as the \"Red Book,\" is a comprehensive guide published by the Government Accountability Office (GAO) that outlines the legal framework governing federal appropriations. Volume One of this publication provides an in-depth exploration of the foundational principles of appropriations law. Below is a detailed summary of the key concepts and topics covered in Volume One:\\n\\n', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1743345867, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_de57b65c90', usage=CompletionUsage(completion_tokens=79, prompt_tokens=15425, total_tokens=15504, completion_tokens_details=None, prompt_tokens_details=None), request_id='req_aad1123cb51993ad128719638d7333d4', tool_choice=None, seed=3533685213898442552, top_p=0.9, temperature=0.8, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'text', 'json_schema': None}), ChatCompletion(id='chatcmpl-BGoAub2DWZbc0vHp4g8i5s8o2iPP0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Certainly! The Anti-Deficiency Act (ADA), codified in Public Law 97-258, is a critical piece of legislation that governs the financial management of federal agencies in the United States. The Act is designed to ensure that federal agencies operate within the budgetary limits set by Congress, thereby promoting fiscal responsibility and accountability. Below are the main points of the ADA and examples of how it can be applied:\\n\\n', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1743345820, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_de57b65c90', usage=CompletionUsage(completion_tokens=83, prompt_tokens=15477, total_tokens=15560, completion_tokens_details=None, prompt_tokens_details=None), request_id='req_48e028a3a6f0e5085d756023766df1e9', tool_choice=None, seed=-9080041646734409344, top_p=0.9, temperature=0.8, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'text', 'json_schema': None}), ChatCompletion(id='chatcmpl-BGo9KhcBdLo3zqANwWBFwLnmJ6tuh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Certainly! The Anti-Deficiency Act (ADA), codified as Public Law 97-258, is a critical piece of legislation that governs the financial management of federal agencies in the United States. Its primary purpose is to ensure that federal spending is conducted in a manner that is fiscally responsible and in accordance with the appropriations provided by Congress. Below are the main points of the Anti-Deficiency Act, along with three examples of how it can be applied:\\n\\n', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1743345722, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_de57b65c90', usage=CompletionUsage(completion_tokens=94, prompt_tokens=15440, total_tokens=15534, completion_tokens_details=None, prompt_tokens_details=None), request_id='req_c3ca6a9490c1d14d629b11f7473749ee', tool_choice=None, seed=-8416101526804079526, top_p=0.9, temperature=0.8, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'text', 'json_schema': None}), ChatCompletion(id='chatcmpl-BEyd8hPkZYuag3Cg0s8Sm1bXYp6Uj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1742909354, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_6ec83003ad', usage=None, request_id='req_173feb64d810a9eafd3df109d7471359', tool_choice=None, seed=576111287854330196, top_p=1.0, temperature=0.7, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format=None), ChatCompletion(id='chatcmpl-BDZfmULEyGtM7vAQQC2xAV1dRNmAl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"reasoning\":[{\"description\":\"The expert answer is analyzed first to verify that it includes all the details that can be compared against the submitted answer. This provides a baseline to measure consistency and completeness with the submitted answer.\",\"conclusion\":\"The expert answer is detailed, providing specific appropriations under Public Law 110-252.\"},{\"description\":\"The submitted answer is read to check whether it contains the same details as the expert answer. This includes examining each section and the budget amounts to compare them directly with the expert answer.\",\"conclusion\":\"The submitted answer contains all the same details as the expert answer. Every budget account and amount specified is present in both answers, with no discrepancies or omissions.\"}],\"result\":\"C\"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1742575090, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_83df987f64', usage=CompletionUsage(completion_tokens=145, prompt_tokens=10074, total_tokens=10219, completion_tokens_details=None, prompt_tokens_details=None), request_id='3629ffb7cb8b875682497a2a545ff207', tool_choice=None, seed=-7045600917988429098, top_p=1.0, temperature=1.0, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'json_schema', 'json_schema': {'name': 'answer_comparison', 'strict': True, 'description': None, 'json_schema': {'type': 'object', 'properties': {'reasoning': {'type': 'array', 'description': 'A sequence of steps outlining the reasoning process.', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'Detailed description of the reasoning in this step.'}, 'conclusion': {'type': 'string', 'description': 'The outcome or conclusion of this step.'}}, 'required': ['description', 'conclusion'], 'additionalProperties': False}}, 'result': {'type': 'string', 'description': 'The comparison result based on the relationship between the submitted answer and the expert answer.', 'enum': ['A', 'B', 'C', 'D', 'E']}}, 'required': ['reasoning', 'result'], 'additionalProperties': False}}}), ChatCompletion(id='chatcmpl-BDZfmWENK5OKFubAEqWtmWZJ8ka0x', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"reasoning\":[{\"description\":\"The submitted answer begins with the same introductory overview of the \\\\\"Federal Trust Fund Accounting Guide,\\\\\" emphasizing its purpose and general scope in managing federal trust funds.\",\"conclusion\":\"The introduction is consistent in both answers.\"},{\"description\":\"Both answers detail the same key sections and points, including purpose and scope, definition and structure, accounting standards, fund management, financial reporting, auditing, special considerations, and case studies.\",\"conclusion\":\"The content of both the submitted and expert answers is essentially identical.\"},{\"description\":\"Both answers end with similar implications and uses, highlighting consistency, accuracy, and the guide\\'s role as a resource for financial officers.\",\"conclusion\":\"The conclusions drawn in both answers match.\"}],\"result\":\"C\"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1742575090, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_83df987f64', usage=CompletionUsage(completion_tokens=151, prompt_tokens=22208, total_tokens=22359, completion_tokens_details=None, prompt_tokens_details=None), request_id='6ded944087482ed3e2eaf12baace2e0c', tool_choice=None, seed=99837876295173901, top_p=1.0, temperature=1.0, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'json_schema', 'json_schema': {'name': 'answer_comparison', 'strict': True, 'description': None, 'json_schema': {'type': 'object', 'properties': {'reasoning': {'type': 'array', 'description': 'A sequence of steps outlining the reasoning process.', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'Detailed description of the reasoning in this step.'}, 'conclusion': {'type': 'string', 'description': 'The outcome or conclusion of this step.'}}, 'required': ['description', 'conclusion'], 'additionalProperties': False}}, 'result': {'type': 'string', 'description': 'The comparison result based on the relationship between the submitted answer and the expert answer.', 'enum': ['A', 'B', 'C', 'D', 'E']}}, 'required': ['reasoning', 'result'], 'additionalProperties': False}}}), ChatCompletion(id='chatcmpl-BDZfmUWr5BZzn37GTrEXj9wn42hvi', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"reasoning\":[{\"description\":\"The submitted answer and the expert answer start by introducing Public Law 115-141 and its purpose: providing comprehensive funding for various federal departments and agencies for fiscal year 2018 through a combined omnibus bill covering multiple budget accounts.\",\"conclusion\":\"The introductions in both answers are identical.\"},{\"description\":\"Both answers offer a detailed breakdown of funding allocations across different departments and agencies. Each section presents the same budget accounts with the corresponding funding amounts, such as Agricultural Research Service, Animal and Plant Health Inspection Service, Department of Defense\\'s Military Personnel, Operation and Maintenance, Procurement, Research, Development, Test, and Evaluation, Department of Education, Department of Health and Human Services, and more.\",\"conclusion\":\"The detailed breakdown of appropriations is identical in both answers.\"},{\"description\":\"Both answers conclude with a summary that highlights the reflection of federal spending priorities and the suggestion to refer to the full text of the law or appropriations committee reports for further details.\",\"conclusion\":\"The concluding summaries in both answers are identical.\"}],\"result\":\"C\"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1742575090, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_83df987f64', usage=CompletionUsage(completion_tokens=215, prompt_tokens=22419, total_tokens=22634, completion_tokens_details=None, prompt_tokens_details=None), request_id='214e948029c417d7ccb4956696bc6ce3', tool_choice=None, seed=163276556914000304, top_p=1.0, temperature=1.0, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'json_schema', 'json_schema': {'name': 'answer_comparison', 'strict': True, 'description': None, 'json_schema': {'type': 'object', 'properties': {'reasoning': {'type': 'array', 'description': 'A sequence of steps outlining the reasoning process.', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'Detailed description of the reasoning in this step.'}, 'conclusion': {'type': 'string', 'description': 'The outcome or conclusion of this step.'}}, 'required': ['description', 'conclusion'], 'additionalProperties': False}}, 'result': {'type': 'string', 'description': 'The comparison result based on the relationship between the submitted answer and the expert answer.', 'enum': ['A', 'B', 'C', 'D', 'E']}}, 'required': ['reasoning', 'result'], 'additionalProperties': False}}}), ChatCompletion(id='chatcmpl-BDZfmhOGNiFuCgK4sAubkmakgBEJK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"reasoning\":[{\"description\":\"Both the submitted answer and the expert answer provide a detailed summary of OMB Circular A-11 Section 120, focusing on the administrative control of funds within federal agencies. The main aspects covered include purpose, legal framework, requirements for agencies, control mechanisms, monitoring and reporting, consequences of violations, and training and compliance.\",\"conclusion\":\"The submitted answer contains all the same details as the expert answer.\"}],\"result\":\"C\"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1742575090, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_83df987f64', usage=CompletionUsage(completion_tokens=94, prompt_tokens=19261, total_tokens=19355, completion_tokens_details=None, prompt_tokens_details=None), request_id='5f8b4b02e33849efe86de448bdd0646c', tool_choice=None, seed=-59969876241983792, top_p=1.0, temperature=1.0, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'json_schema', 'json_schema': {'name': 'answer_comparison', 'strict': True, 'description': None, 'json_schema': {'type': 'object', 'properties': {'reasoning': {'type': 'array', 'description': 'A sequence of steps outlining the reasoning process.', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'Detailed description of the reasoning in this step.'}, 'conclusion': {'type': 'string', 'description': 'The outcome or conclusion of this step.'}}, 'required': ['description', 'conclusion'], 'additionalProperties': False}}, 'result': {'type': 'string', 'description': 'The comparison result based on the relationship between the submitted answer and the expert answer.', 'enum': ['A', 'B', 'C', 'D', 'E']}}, 'required': ['reasoning', 'result'], 'additionalProperties': False}}}), ChatCompletion(id='chatcmpl-BDZfmmj416WbP27d216xvkefImtvC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"reasoning\":[{\"description\":\"Both the submitted and expert answers correctly identify Public Law 112-25 as the \\'Budget Control Act of 2011\\' and state that it does not directly allocate funds to budget accounts like a typical appropriations act.\",\"conclusion\":\"The basic understanding of the law aligns between both answers.\"},{\"description\":\"Both answers list similar components of Public Law 112-25, specifically the increase in the debt ceiling, deficit reduction measures, discretionary spending caps, sequestration mechanism, and the vote on a balanced budget amendment.\",\"conclusion\":\"The key components listed in both answers are consistent.\"},{\"description\":\"Both answers discuss the impact of Public Law 112-25 on appropriations by highlighting the law\\'s role in influencing future spending rather than outlining specific budget account allocations.\",\"conclusion\":\"The impact on appropriations is described consistently in both answers.\"}],\"result\":\"C\"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1742575090, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_83df987f64', usage=CompletionUsage(completion_tokens=181, prompt_tokens=14525, total_tokens=14706, completion_tokens_details=None, prompt_tokens_details=None), request_id='caed58c93a1b90c826cca1be2f6dfd57', tool_choice=None, seed=-5000314050734261977, top_p=1.0, temperature=1.0, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'json_schema', 'json_schema': {'name': 'answer_comparison', 'strict': True, 'description': None, 'json_schema': {'type': 'object', 'properties': {'reasoning': {'type': 'array', 'description': 'A sequence of steps outlining the reasoning process.', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'Detailed description of the reasoning in this step.'}, 'conclusion': {'type': 'string', 'description': 'The outcome or conclusion of this step.'}}, 'required': ['description', 'conclusion'], 'additionalProperties': False}}, 'result': {'type': 'string', 'description': 'The comparison result based on the relationship between the submitted answer and the expert answer.', 'enum': ['A', 'B', 'C', 'D', 'E']}}, 'required': ['reasoning', 'result'], 'additionalProperties': False}}}), ChatCompletion(id='chatcmpl-BDZfm8FEnHILkQofgf4wb4Dir950i', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"reasoning\":[{\"description\":\"Compare the introductory part of both answers. Both describe the \\\\\"Principles of Federal Appropriations Law\\\\\" as a comprehensive guide by the GAO, often referred to as the \\\\\"Red Book,\\\\\" and its emphasis on legal use of appropriated funds. Volume One establishes the legal foundation of federal appropriations.\",\"conclusion\":\"Both introductions are identical and accurate.\"},{\"description\":\"Analyze the detailed breakdown of Volume One provided in both answers. They each cover the purpose and scope, key concepts of appropriations (including purpose, time, and amount), the legal framework, common issues and resolutions, the role of the GAO, and interpretative guidance.\",\"conclusion\":\"The breakdown in both submitted and expert answers is accurately detailed and identical.\"},{\"description\":\"Assess the implications and use sections in both summaries. Both versions discuss fiscal accountability, aid to policymakers and agency officials, and the role of the Red Book as a training resource.\",\"conclusion\":\"Implications and uses in both answers are correctly and similarly stated.\"},{\"description\":\"Consider the overall structure and depth of both answers. Both answers follow the same structure and provide the same level of detail.\",\"conclusion\":\"The overall structure and content in both answers are exactly the same and factual.\"}],\"result\":\"C\"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1742575090, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_83df987f64', usage=CompletionUsage(completion_tokens=259, prompt_tokens=17432, total_tokens=17691, completion_tokens_details=None, prompt_tokens_details=None), request_id='5638b049268359259faac26ddd2c11be', tool_choice=None, seed=-6823699682527554489, top_p=1.0, temperature=1.0, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'json_schema', 'json_schema': {'name': 'answer_comparison', 'strict': True, 'description': None, 'json_schema': {'type': 'object', 'properties': {'reasoning': {'type': 'array', 'description': 'A sequence of steps outlining the reasoning process.', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'Detailed description of the reasoning in this step.'}, 'conclusion': {'type': 'string', 'description': 'The outcome or conclusion of this step.'}}, 'required': ['description', 'conclusion'], 'additionalProperties': False}}, 'result': {'type': 'string', 'description': 'The comparison result based on the relationship between the submitted answer and the expert answer.', 'enum': ['A', 'B', 'C', 'D', 'E']}}, 'required': ['reasoning', 'result'], 'additionalProperties': False}}}), ChatCompletion(id='chatcmpl-BDZfmoPRa2l001yCzjcc1xsmg4Cj1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"reasoning\":[{\"description\":\"Both the submitted and expert answers summarize the Government Performance and Results Act (GPRA) of 1993. They both outline the purpose of GPRA, its objectives, the strategic planning and performance plans, and the importance of performance reporting.\",\"conclusion\":\"The submitted answer covers the same content as the expert answer.\"},{\"description\":\"The submitted answer, like the expert answer, details the accountability and transparency aspect of GPRA, its impact on budgeting, and its role in continuous improvement process.\",\"conclusion\":\"The submitted answer is consistent with the expert answer regarding accountability, budgeting, and continuous improvement.\"},{\"description\":\"The language and organization of both answers are similar, covering the key components such as strategic planning, performance plans, reporting, and transparency in similar amounts of detail.\",\"conclusion\":\"The submitted answer contains all the same details as the expert answer.\"}],\"result\":\"C\"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1742575090, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_83df987f64', usage=CompletionUsage(completion_tokens=184, prompt_tokens=25567, total_tokens=25751, completion_tokens_details=None, prompt_tokens_details=None), request_id='934a141a1fc7b4fd591bee66c98b1726', tool_choice=None, seed=8071882463463369285, top_p=1.0, temperature=1.0, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'json_schema', 'json_schema': {'name': 'answer_comparison', 'strict': True, 'description': None, 'json_schema': {'type': 'object', 'properties': {'reasoning': {'type': 'array', 'description': 'A sequence of steps outlining the reasoning process.', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'Detailed description of the reasoning in this step.'}, 'conclusion': {'type': 'string', 'description': 'The outcome or conclusion of this step.'}}, 'required': ['description', 'conclusion'], 'additionalProperties': False}}, 'result': {'type': 'string', 'description': 'The comparison result based on the relationship between the submitted answer and the expert answer.', 'enum': ['A', 'B', 'C', 'D', 'E']}}, 'required': ['reasoning', 'result'], 'additionalProperties': False}}}), ChatCompletion(id='chatcmpl-BDZfmUR8qZb567s6qBbSG1XExowxb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"reasoning\":[{\"description\":\"Compare the headers and structure of the submitted and expert answers to ensure they match.\",\"conclusion\":\"The structure and headers in both answers match perfectly.\"},{\"description\":\"Check the detailed fund allocations by department in the submitted answer against the expert answer.\",\"conclusion\":\"All specific budget allocations for each department match exactly between the submitted and expert answers.\"},{\"description\":\"Examine whether there are any differences or inaccuracies in the allocations or department-specific information.\",\"conclusion\":\"There are no differences or inaccuracies; both answers contain the same comprehensive details for each department and account.\"}],\"result\":\"C\"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1742575090, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_83df987f64', usage=CompletionUsage(completion_tokens=124, prompt_tokens=23460, total_tokens=23584, completion_tokens_details=None, prompt_tokens_details=None), request_id='d889bbbae84dbcfaa2461c142aef99f6', tool_choice=None, seed=6625028365471258596, top_p=1.0, temperature=1.0, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'json_schema', 'json_schema': {'name': 'answer_comparison', 'strict': True, 'description': None, 'json_schema': {'type': 'object', 'properties': {'reasoning': {'type': 'array', 'description': 'A sequence of steps outlining the reasoning process.', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'Detailed description of the reasoning in this step.'}, 'conclusion': {'type': 'string', 'description': 'The outcome or conclusion of this step.'}}, 'required': ['description', 'conclusion'], 'additionalProperties': False}}, 'result': {'type': 'string', 'description': 'The comparison result based on the relationship between the submitted answer and the expert answer.', 'enum': ['A', 'B', 'C', 'D', 'E']}}, 'required': ['reasoning', 'result'], 'additionalProperties': False}}}), ChatCompletion(id='chatcmpl-BDZfmAlQWLe4SrqVIpEXcogKXRPnK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"reasoning\":[{\"description\":\"Review the submitted answer and the expert answer to identify any differences in content or detail.\",\"conclusion\":\"The submitted answer and the expert answer are identical in content and structure.\"},{\"description\":\"Consider whether there are any additional details, discrepancies, or omitted information between the submitted answer and the expert answer.\",\"conclusion\":\"There are no differences between the submitted answer and the expert answer.\"}],\"result\":\"C\"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1742575090, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_83df987f64', usage=CompletionUsage(completion_tokens=89, prompt_tokens=7815, total_tokens=7904, completion_tokens_details=None, prompt_tokens_details=None), request_id='1b5a8539ae8c06a20e84b8dc50a6dbb0', tool_choice=None, seed=3659711909118820280, top_p=1.0, temperature=1.0, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'json_schema', 'json_schema': {'name': 'answer_comparison', 'strict': True, 'description': None, 'json_schema': {'type': 'object', 'properties': {'reasoning': {'type': 'array', 'description': 'A sequence of steps outlining the reasoning process.', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'Detailed description of the reasoning in this step.'}, 'conclusion': {'type': 'string', 'description': 'The outcome or conclusion of this step.'}}, 'required': ['description', 'conclusion'], 'additionalProperties': False}}, 'result': {'type': 'string', 'description': 'The comparison result based on the relationship between the submitted answer and the expert answer.', 'enum': ['A', 'B', 'C', 'D', 'E']}}, 'required': ['reasoning', 'result'], 'additionalProperties': False}}}), ChatCompletion(id='chatcmpl-BDZfmo4NPOK1g6NEhfrBOA9nb3oOU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"reasoning\":[{\"description\":\"The submitted answer and the expert answer start in the same manner, indicating progression to Section F for time series analysis. Both mention focusing on autoregressive models like ARIMA and the Holt-Winters method for forecasting future account balances.\",\"conclusion\":\"The introductions of both answers are identical.\"},{\"description\":\"Both the submitted and expert answers provide the same code for implementing an ARIMA model for time series forecasting. This includes importing libraries, setting the date index, splitting the data, fitting the model, forecasting, calculating RMSE, and plotting the results.\",\"conclusion\":\"The ARIMA model sections in both answers are identical in methodology and explanation.\"},{\"description\":\"Both answers proceed to discuss the Holt-Winters method for capturing seasonality in time series. The implementation details, including importing the necessary library, fitting the model, forecasting, calculating RMSE, and plotting results, are exactly the same.\",\"conclusion\":\"The Holt-Winters method sections in both answers are identical.\"},{\"description\":\"Both answers include a summary of Section F, describing the usage and advantages of ARIMA and Holt-Winters methods, along with recommendations about their application depending on the presence of seasonality and model accuracy measured by RMSE.\",\"conclusion\":\"The summaries and recommendations in both answers are identical.\"}],\"result\":\"C\"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1742575090, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_83df987f64', usage=CompletionUsage(completion_tokens=270, prompt_tokens=7604, total_tokens=7874, completion_tokens_details=None, prompt_tokens_details=None), request_id='1bb9ea329f2e5465c5e5296926e13612', tool_choice=None, seed=-224246685955035634, top_p=1.0, temperature=1.0, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'json_schema', 'json_schema': {'name': 'answer_comparison', 'strict': True, 'description': None, 'json_schema': {'type': 'object', 'properties': {'reasoning': {'type': 'array', 'description': 'A sequence of steps outlining the reasoning process.', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'Detailed description of the reasoning in this step.'}, 'conclusion': {'type': 'string', 'description': 'The outcome or conclusion of this step.'}}, 'required': ['description', 'conclusion'], 'additionalProperties': False}}, 'result': {'type': 'string', 'description': 'The comparison result based on the relationship between the submitted answer and the expert answer.', 'enum': ['A', 'B', 'C', 'D', 'E']}}, 'required': ['reasoning', 'result'], 'additionalProperties': False}}}), ChatCompletion(id='chatcmpl-BDZStCHp7r4gT2kWAmFEFvHMhwQb6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I apologize for the confusion earlier. Let's go through the steps of a comprehensive data analysis process for a hypothetical dataset. Since I cannot execute code or access files directly, I'll provide a full script example that you can run in your Python environment. This script includes data loading, normalization, anomaly detection, trend analysis, and statistical tests. \\n\\n```python\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom scipy import stats\\nfrom sklearn.preprocessing import StandardScaler\\n\\n\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1742574291, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_6ec83003ad', usage=CompletionUsage(completion_tokens=104, prompt_tokens=15924, total_tokens=16028, completion_tokens_details=None, prompt_tokens_details=None), request_id='req_9ecf15e094fd712e9a3e1141c9f5c480', tool_choice=None, seed=-5207629990889323185, top_p=0.9, temperature=0.8, presence_penalty=0.0, frequency_penalty=0.0, input_user=None, tools=None, metadata={}, response_format={'type': 'text', 'json_schema': None})], has_more=True, object='list', first_id='chatcmpl-BIjZyMyT9NqmSUfzVLoBpGaOQi2GP', last_id='chatcmpl-BDZStCHp7r4gT2kWAmFEFvHMhwQb6')\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Upload",
   "id": "a60864fd32fdc3d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create File Reqeust\n",
    "file = client.files.create(\n",
    "    file=open( 'draconomicon.pdf', 'rb' ),\n",
    "    purpose='user_data'\n",
    ")\n",
    "\n",
    "# Create Completion\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'type': 'file',\n",
    "                    'file':\n",
    "\t\t\t\t\t{\n",
    "                        'file_id': file.id,\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'type': 'documents',\n",
    "                    'documents': 'What is the first dragon in the book?',\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ].message.conten )"
   ],
   "id": "7a08718a9386339a"
  },
  {
   "metadata": {
    "id": "4a5f4620e53bab63"
   },
   "cell_type": "markdown",
   "source": "### Update",
   "id": "4a5f4620e53bab63"
  },
  {
   "metadata": {
    "id": "ee0f4929c2fa200b"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Completion\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "updated_completion = client.chat.completions.update( completion_id=first_id,\n",
    "\trequest_body={ 'metadata': { 'foo': 'bar' } } )\n",
    "print( updated_completion )"
   ],
   "id": "ee0f4929c2fa200b"
  },
  {
   "metadata": {
    "id": "e01ecd500ae773a5"
   },
   "cell_type": "markdown",
   "source": "### Delete",
   "id": "e01ecd500ae773a5"
  },
  {
   "metadata": {
    "id": "b69689f26fb50f5d"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Completion\n",
    "completions = client.chat.completions.list( )\n",
    "first_id = completions[ 0 ].id\n",
    "delete_response = client.chat.completions.delete( completion_id=first_id )\n",
    "print( delete_response )"
   ],
   "id": "b69689f26fb50f5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Assistants API\n",
    "- Can call models and use tools to perform tasks..\n",
    "- An Assistant has instructions and can leverage models, tools, and files to respond to user queries.\n",
    "##### Tools:\n",
    "\n",
    "- Code Interpreter\n",
    "- File Search\n",
    "- Function calling\n",
    "___"
   ],
   "id": "cf57967b7d2bdcae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List",
   "id": "bcd06265a483bf31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List Assistants\n",
    "my_assistants = client.beta.assistants.list(\n",
    "    order=\"desc\",\n",
    "    limit=\"20\",\n",
    ")\n",
    "\n",
    "print( my_assistants.data )\n"
   ],
   "id": "f4aecd7c552cb7a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retreive",
   "id": "6d834cf52ff8b8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Retrieve Assistant\n",
    "my_assistant = client.beta.assistants.retrieve( \"asst_abc123\" )\n",
    "print( my_assistant )\n"
   ],
   "id": "63c219971e2ea6f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Code",
   "id": "f196daeebbdcfc8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name='Bro',\n",
    "  instructions='You are a computer programming tutor. Write and run code to answer programming questions.',\n",
    "  tools=[{'type': 'code_interpreter'}],\n",
    "  model='gpt-4o' )"
   ],
   "id": "e43dfd90678d1468"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Completion Response",
   "id": "f9a71fde78686a9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  'id': 'asst_abc123',\n",
    "  'object': 'assistant',\n",
    "  'created_at': 1698984975,\n",
    "  'name': 'Bro',\n",
    "  'description': null,\n",
    "  'model': 'gpt-4o',\n",
    "  'instructions': 'You are a personal math tutor. When asked a question, write and run Python code to answer the question.',\n",
    "  'tools': [ { 'type': 'code_interpreter' } ],\n",
    "  'metadata': {},\n",
    "  'top_p': 1.0,\n",
    "  'temperature': 1.0,\n",
    "  'response_format': 'auto'\n",
    "}\n"
   ],
   "id": "21309453c380e615"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search File",
   "id": "e9647261dfbbcf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Assistant\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are an HR bot, and you have access to files to answer employee questions about company policies.\",\n",
    "    name=\"HR Helper\",\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    "    tool_resources={\"file_search\": {\"vector_store_ids\": [\"vs_123\"]}},\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "print( my_assistant )\n"
   ],
   "id": "5e2ac2f2d5112372"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Search Response",
   "id": "8fbf93636d28a239"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "      'id': 'asst_abc123',\n",
    "      'object': 'assistant',\n",
    "      'created_at': 1699009403,\n",
    "      'name': 'HR Helper',\n",
    "      'description': null,\n",
    "      'model': 'gpt-4o',\n",
    "      'instructions': 'You are an HR bot, and you have access to files to answer employee questions about company policies.',\n",
    "      'tools': [ { 'type': 'file_search' } ],\n",
    "      'tool_resources':\n",
    "      {\n",
    "            'file_search':\n",
    "             {\n",
    "                 'vector_store_ids': ['vs_123', ]\n",
    "             }\n",
    "      },\n",
    "      'metadata': {},\n",
    "      'top_p': 1.0,\n",
    "      'temperature': 1.0,\n",
    "      'response_format': 'auto'\n",
    "}\n"
   ],
   "id": "53bfdf9bf3430865"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Add Thread",
   "id": "171960fd6f653e66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "thread = client.beta.threads.create()"
   ],
   "id": "7b2c84cdaded2e15"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Add Message",
   "id": "79bf02388a442d49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Thread Message\n",
    "thread_message = client.beta.threads.messages.create( 'thread_abc123',\n",
    "  role='user', content='How does AI work? Explain it in simple terms.' )\n",
    "\n",
    "print( thread_message )"
   ],
   "id": "1431f1461a8c4518"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Run",
   "id": "c4121043e6ce790f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll( thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions='Please address the user as Jane Doe. The user has a premium account.'\n",
    ")\n",
    "\n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list( thread_id=thread.id )\n",
    "  print( messages )\n",
    "else:\n",
    "  print( run.status )"
   ],
   "id": "e16c4467e5387ae7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Stream Run",
   "id": "a7fc0b27705d1ad2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "\n",
    "# First, we create a EventHandler class to define\n",
    "# how we want to handle the events in the response stream.\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "  @override\n",
    "  def on_text_created(self, text) -> None:\n",
    "    print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "\n",
    "  @override\n",
    "  def on_text_delta(self, delta, snapshot):\n",
    "    print(delta.value, end=\"\", flush=True)\n",
    "\n",
    "  def on_tool_call_created(self, tool_call):\n",
    "    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "  def on_tool_call_delta(self, delta, snapshot):\n",
    "    if delta.type == 'code_interpreter':\n",
    "      if delta.code_interpreter.input:\n",
    "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "      if delta.code_interpreter.outputs:\n",
    "        print(f\"\\n\\ncleaned_lines >\", flush=True)\n",
    "        for output in delta.code_interpreter.outputs:\n",
    "          if output.type == \"logs\":\n",
    "            print(f\"\\n{output.logs}\", flush=True)\n",
    "\n",
    "# We use the `stream` SDK helper with the `EventHandler` class to create the Run and stream the response.\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Please address the user as Jane Doe. The user has a premium account.\",\n",
    "  event_handler=EventHandler( ),\n",
    ") as stream:\n",
    "    stream.until_done( )"
   ],
   "id": "e9c17850e736a2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Responses API\n",
    "- Supports text and image inputs, and text outputs.\n",
    "- Create stateful interactions with the model, using the output of previous responses as input\n",
    "- Allow the model access to external systems and data using function calling\n",
    "___"
   ],
   "id": "5e660c6eee645c84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Response Format\n",
    "- `choices`\n",
    "- `response.choices[0].message.content`"
   ],
   "id": "9bdbdd5c13fac74e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "[\n",
    "    {\n",
    "        'index': 0,\n",
    "        'message':\n",
    "        {\n",
    "            'role': 'assistant',\n",
    "            'content': 'Under the soft glow of the moon, Luna the unicorn danced through fields of twinkling stardust, leaving trails of dreams for every child asleep.',\n",
    "            'refusal': null\n",
    "         },\n",
    "         'logprobs': null,\n",
    "         'finish_reason': 'stop'\n",
    "    }\n",
    "]"
   ],
   "id": "739bd06fefd0330f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Text Input",
   "id": "1d43eab9f7fed9a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "response = client.responses.create( model='gpt-4o',\n",
    "    input='Write a five-sentence bedtime story about a unicorn.' )\n",
    "\n",
    "print( response.output_text )"
   ],
   "id": "fe09382204be383"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analyze Image",
   "id": "3196d2e307ea1d96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o',\n",
    "    input=\n",
    "    [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content':\n",
    "\t        [\n",
    "                { 'type': 'input_text',\n",
    "                  'text': 'what is in this image?'\n",
    "                },\n",
    "                {\n",
    "                    'type': 'input_image',\n",
    "                    'image_url': 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg'\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")"
   ],
   "id": "c300ef2d71abf6ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search Web",
   "id": "30ccfb9d748f46e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create( model='gpt-4o',\n",
    "    tools=[ { 'type': 'web_search_preview' } ],\n",
    "    input='What was a positive news story from today?' )\n",
    "\n",
    "print( response.output_text )"
   ],
   "id": "215ae5508d20ae18"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Web Result Format",
   "id": "100a9921e534d030"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "[\n",
    "  {\n",
    "    'type': 'web_search_call',\n",
    "    'id': 'ws_67c9fa0502748190b7dd390736892e100be649c1a5ff9609',\n",
    "    'status': 'completed'\n",
    "  },\n",
    "  {\n",
    "    'id': 'msg_67c9fa077e288190af08fdffda2e34f20be649c1a5ff9609',\n",
    "    'type': 'message',\n",
    "    'status': 'completed',\n",
    "    'role': 'assistant',\n",
    "    'content': [\n",
    "      {\n",
    "        'type': 'output_text',\n",
    "        'text': 'On March 6, 2025, several news...',\n",
    "        'annotations':\n",
    "        [\n",
    "          {\n",
    "            'type': 'url_citation',\n",
    "            'start_index': 2606,\n",
    "            'end_index': 2758,\n",
    "            'url': 'https://...',\n",
    "            'title': 'Title...'\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]"
   ],
   "id": "26b5b63e663b1f21"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Function Schema",
   "id": "552d7c5a7428e999"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "    'type': 'function',\n",
    "    'function':\n",
    "    {\n",
    "        'name': 'get_weather',\n",
    "        'description': 'Retrieves current weather for the given location.',\n",
    "        'parameters':\n",
    "        {\n",
    "            'type': 'object',\n",
    "            'properties':\n",
    "            {\n",
    "                'location':\n",
    "                {\n",
    "                    'type': 'string',\n",
    "                    'description': 'City and country e.g. Bogotá, Colombia'\n",
    "                },\n",
    "                'units':\n",
    "                {\n",
    "                    'type': 'string',\n",
    "                    'enum':\n",
    "                    [\n",
    "                        'celsius',\n",
    "                        'fahrenheit'\n",
    "                    ],\n",
    "                    'description': 'Units the temperature will be returned in.'\n",
    "                }\n",
    "            },\n",
    "            'required':\n",
    "            [\n",
    "                'location',\n",
    "                'units'\n",
    "            ],\n",
    "            'additionalProperties': false\n",
    "        },\n",
    "\n",
    "        'strict': true\n",
    "    }\n",
    "}"
   ],
   "id": "808f4f4c33740712"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search File",
   "id": "375251096d932918"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create(\n",
    "\tmodel='gpt-4o',\n",
    "\ttools=[\n",
    "\t\t{\n",
    "\t\t\t'type': 'file_search',\n",
    "\t\t\t'vector_store_ids': [ 'vs_1234567890' ],\n",
    "\t\t\t'max_num_results': 20\n",
    "\t\t} ],\n",
    "\tinput='What are the attributes of an ancient brown dragon?',\n",
    ")\n",
    "\n",
    "print( response.output_text )"
   ],
   "id": "1389523d89aa40e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Stream",
   "id": "ae413b8def87fdcc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create(\n",
    "\tmodel='gpt-4o',\n",
    "\tinstructions='You are a helpful assistant.',\n",
    "\tinput='Hello!',\n",
    "\tstream=True\n",
    ")\n",
    "\n",
    "for event in response:\n",
    "\tprint( event )"
   ],
   "id": "b7befa491ffdc9f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Speech API\n",
    "- The maximum input length is 4096 characters.\n",
    "- TTS models: tts-1, tts-1-hd or gpt-4o-mini-tts.\n",
    "___"
   ],
   "id": "8431ed1e58f0f686"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7dbcc7e444d420fc"
  },
  {
   "metadata": {
    "id": "f9aa6a88c6e6aae1"
   },
   "cell_type": "markdown",
   "source": [
    "### Stream\n",
    "- Generates audio from the input text."
   ],
   "id": "f9aa6a88c6e6aae1"
  },
  {
   "metadata": {
    "id": "69bfd864f5e56ea6"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Speech\n",
    "speech_file_path = Path( __file__ ).parent  # 'speech.mp3'\n",
    "prompt = 'The quick brown fox jumped over the lazy dog.'\n",
    "response = client.audio.speech.create( model='tts-1-hd', voice='alloy', input=prompt )\n",
    "response.stream_to_file( speech_file_path )\n"
   ],
   "id": "69bfd864f5e56ea6"
  },
  {
   "metadata": {
    "id": "d30d80c36b8c36c0"
   },
   "cell_type": "markdown",
   "source": [
    "### Transcribe\n",
    "- Transcribes audio into the input language."
   ],
   "id": "d30d80c36b8c36c0"
  },
  {
   "metadata": {
    "id": "6d17f226244664f3"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Open Audio File 'speech.mp3'\n",
    "audio_file = open( 'speech.mp3', 'rb' )\n",
    "transcript = client.audio.transcriptions.create( model='whisper-1', file=audio_file )\n"
   ],
   "id": "6d17f226244664f3"
  },
  {
   "metadata": {
    "id": "4f50814639443330"
   },
   "cell_type": "markdown",
   "source": [
    "### Translate\n",
    "- Translates audio into English."
   ],
   "id": "4f50814639443330"
  },
  {
   "metadata": {
    "id": "e247d4cab1abede9"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Translation\n",
    "audio_file = open( 'speech.mp3', 'rb' )\n",
    "translation = client.audio.translations.create( model='whisper-1', file=audio_file )\n"
   ],
   "id": "e247d4cab1abede9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generate",
   "id": "db9292c49f790f99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Transcription\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4o-audio-preview',\n",
    "    modalities=[ 'texxt', 'audio' ],\n",
    "    audio={ 'voice': 'alloy', 'format': 'wav' },\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Is a golden retriever a good family dog?'\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ] )\n",
    "\n",
    "# Convert to bytes\n",
    "wav_bytes = base64.b64decode( completion.choices[ 0 ].message.audio.data )\n",
    "with open( 'dog.wav', 'wb' ) as f:\n",
    "    f.write( wav_bytes )"
   ],
   "id": "d16102a40689ac3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analyze",
   "id": "ffebc4a744ec0084"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Fetch the audio file and convert it to a base64 encoded string\n",
    "url = 'https://cdn.openai.com/API/docs/audio/alloy.wav'\n",
    "response = requests.get( url )\n",
    "response.raise_for_status()\n",
    "wav_data = response.content\n",
    "encoded_string = base64.b64encode( wav_data ).decode( 'utf-8' )\n",
    "\n",
    "# Create Completion\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4o-audio-preview',\n",
    "    modalities=['documents', 'audio'],\n",
    "    audio={'voice': 'alloy', 'format': 'wav'},\n",
    "    messages=\n",
    "    [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content':\n",
    "\t        [\n",
    "                {\n",
    "                    'type': 'text',\n",
    "                    'documents': 'What is in this recording?'\n",
    "                },\n",
    "                {\n",
    "                    'type': 'input_audio',\n",
    "                    'input_audio':\n",
    "                    {\n",
    "                        'values': encoded_string,\n",
    "                        'format': 'wav'\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print( completion.choices[0].message )"
   ],
   "id": "7eb6e08d0a64adbf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Embedding API\n",
    "- An embedding is a vector (list) of floating point numbers.\n",
    "- The distance between two vectors measures their relatedness.\n",
    "- Small distances suggest high relatedness and large distances suggest low relatedness.\n",
    "\n",
    "##### Use Cases:\n",
    "\n",
    "- **Search** (where results are ranked by relevance to a query string)\n",
    "- **Clustering** (where text strings are grouped by similarity)\n",
    "- **Recommendations** (where items with related text strings are recommended)\n",
    "- **Anomaly Detection** (where outliers with little relatedness are identified)\n",
    "- **Diversity Measurement** (where similarity distributions are analyzed)\n",
    "- **Classification** (where text strings are classified by their most similar label)\n",
    "___"
   ],
   "id": "5d758fcd668c7d93"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Count Tokens",
   "id": "9fa508dba6204bf0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def num_tokens_from_string( string: str, encoding_name: str ) -> int:\n",
    "    '''Returns the number of tokens in a documents string.'''\n",
    "    encoding = tiktoken.get_encoding( encoding_name )\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string( 'tiktoken is great!', 'cl100k_base' )\n"
   ],
   "id": "e9130c33ecb9d7cd"
  },
  {
   "metadata": {
    "id": "6d39d0b28a5bcda2"
   },
   "cell_type": "markdown",
   "source": "### Create Ada\n",
   "id": "6d39d0b28a5bcda2"
  },
  {
   "metadata": {
    "id": "6dc14e033c7dc0de"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.embeddings.create(\n",
    "\tmodel='text-embedding-ada-002',\n",
    "\tinput='The food was delicious and the waiter...',\n",
    "\tencoding_format='float'\n",
    ")\n"
   ],
   "id": "6dc14e033c7dc0de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Small",
   "id": "4c6f36519f4f7022"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Embedding\n",
    "def get_embedding( text, model='text-embedding-3-small' ):\n",
    "    text = text.replace( '\\n', ' ' )\n",
    "    return client.embeddings.create( input = [text], model=model ).data[0].embedding\n"
   ],
   "id": "cec4043c3e30fe6c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Large",
   "id": "4e829f943f3b14c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Embedding\n",
    "def get_embedding( text, model='text-embedding-3-large' ):\n",
    "    text = text.replace( '\\n', ' ' )\n",
    "    return client.embeddings.create( input=[ text ], model=model ).data[ 0 ].embedding"
   ],
   "id": "dfaecb5d74f2b552"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Reduce Dimensions\n",
    "- Dynamically changing the dimensions enables very flexible usage.\n",
    "- When using a vector data store that only supports embeddings up to 1024 dimensions long, developers can now still use our best embedding model text-embedding-3-large and specify a value of 1024 for the dimensions API parameter, which will shorten the embedding down from 3072 dimensions, trading off some accuracy in exchange for the smaller vector size."
   ],
   "id": "252d5f7c74cc4644"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def normalize_l2( x ):\n",
    "    x = np.array( x )\n",
    "    if x.ndim == 1:\n",
    "        norm = np.linalg.norm( x )\n",
    "        if norm == 0:\n",
    "            return x\n",
    "        return x / norm\n",
    "    else:\n",
    "        norm = np.linalg.norm( x, 2, axis=1, keepdims=True )\n",
    "        return np.where( norm == 0, x, x / norm )\n",
    "\n",
    "\n",
    "response = client.embeddings.create( model='documents-embedding-3-small',\n",
    "\tinput='Testing 123', encoding_format='float' )\n",
    "\n",
    "cut_dim = response.data[ 0 ].embedding[ :256 ]\n",
    "norm_dim = normalize_l2( cut_dim )\n",
    "\n",
    "print( norm_dim )\n"
   ],
   "id": "cd2be06e97953ed2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question  Answer\n",
    "- There are many common cases where the model is not trained on data which contains key facts and information you want to make accessible when generating responses to a user query.\n",
    "- One way of solving this, as shown below, is to put additional information into the context window of the model.\n",
    "- This is effective in many use cases but leads to higher token costs."
   ],
   "id": "18cedeef5802e6d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Query\n",
    "query = f'''\n",
    "\n",
    "\tUse the below article on the 2022 Winter Olympics to answer the subsequent question.\n",
    "\tIf the answer cannot be found, write 'I don't know.'\n",
    "\n",
    "\tArticle:\n",
    "\t\\'\\'\\'\n",
    "\t{wikipedia_article_on_curling}\n",
    "\t\\'\\'\\'\n",
    "\n",
    "\tQuestion: Which athletes won the gold medal in curling at the 2022 Winter Olympics?\n",
    "\n",
    "'''\n",
    "\n",
    "# Create Response\n",
    "response = client.chat.completions.create(\n",
    "    messages=\n",
    "    [\n",
    "        {\n",
    "\t        'role': 'system',\n",
    "\t        'content': system_instructions\n",
    "        },\n",
    "        {\n",
    "\t        'role': 'user',\n",
    "\t        'content': user_propmt\n",
    "        },\n",
    "    ],\n",
    "    model=GPT_MODEL,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ],
   "id": "b7d3eb7c3c3f501d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Text Search\n",
    "- To retrieve the most relevant documents, use the cosine similarity between the embedding vectors of the query and each document, and return the highest scored documents.\n"
   ],
   "id": "490f4126e43a20b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def search_reviews( df, product_description, n=3, pprint=True ):\n",
    "    embedding = get_embedding( product_description, model='text-embedding-3-small' )\n",
    "    df['similarities'] = df.ada_embedding.apply( lambda x: cosine_similarity( x, embedding ) )\n",
    "    res = df.sort_values( 'similarities', ascending=False).head( n )\n",
    "    return res\n",
    "\n",
    "res = search_reviews( df, 'delicious beans', n=3 )\n"
   ],
   "id": "655c96c5053f02e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Code Search\n",
    "- Code search works similarly to embedding-based text search.\n",
    "- We provide a method to extract Python functions from all the Python files in a given repository.\n",
    "- Each function is then indexed by the `text-embedding-3-small` model.\n"
   ],
   "id": "9e6a7002183f16a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "df['code_embedding'] = df['code'].apply(lambda x: get_embedding(x, model='text-embedding-3-small'))\n",
    "\n",
    "def search_functions(df, code_query, n=3, pprint=True, n_lines=7):\n",
    "    embedding = get_embedding(code_query, model='text-embedding-3-small')\n",
    "    df['similarities'] = df.code_embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = df.sort_values('similarities', ascending=False).head(n)\n",
    "    return res\n",
    "\n",
    "res = search_functions(df, 'Completions API tests', n=3)\n"
   ],
   "id": "89e1080cb9c56da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Recommendation\n",
    "- Shorter distances between embedding vectors represent greater similarity,"
   ],
   "id": "df9cf5d43dadd6e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def recommendations_from_strings( strings: List[str], index_of_source_string: int,\n",
    "    model='text-embedding-3-small' ) -> List[int]:\n",
    "    '''Return nearest neighbors of a given string.'''\n",
    "    # get embeddings for all strings\n",
    "    embeddings = [ embedding_from_string( string, model=model ) for string in strings ]\n",
    "\n",
    "    # get the embedding of the source string\n",
    "    query_embedding = embeddings[ index_of_source_string ]\n",
    "    distances = distances_from_embeddings( query_embedding, embeddings, distance_metric='cosine' )\n",
    "\n",
    "    # get indices of nearest neighbors (function from embeddings_utils.py)\n",
    "    indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances( distances )\n",
    "    return indices_of_nearest_neighbors\n"
   ],
   "id": "d9a2efb8520859a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Text Featurization\n",
    "- An embedding can be used as a general free-text feature encoder within a machine learning model.\n",
    "- Incorporating embeddings will improve the performance of any machine learning model, if some of the relevant inputs are free text.\n",
    "- An embedding can also be used as a categorical feature encoder within a ML model."
   ],
   "id": "ae136c71eb89d0c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "data = list( df.ada_embedding.values )\n",
    "X_train, X_test, y_train, y_test = train_test_split( data, df.Score, test_size=0.2, random_state=42 )\n"
   ],
   "id": "c9b6f47f9f4561c3"
  },
  {
   "metadata": {
    "id": "2fea58c5aac941f0"
   },
   "cell_type": "markdown",
   "source": [
    "# Tools API\n",
    "- File Search augments the Assistant with knowledge from outside its model\n",
    "- Code Interpreter allows Assistants to write and run Python code in a sandboxed execution environment\n",
    "- Function calling allows you to describe functions to the Assistants API then call them\n",
    "___"
   ],
   "id": "2fea58c5aac941f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get Weather",
   "id": "83c4737551f06998"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function':\n",
    "        {\n",
    "            'name': 'get_weather',\n",
    "            'description': 'Gets the current weather for a given location',\n",
    "            'parameters':\n",
    "            {\n",
    "                'type': 'object',\n",
    "                'properties':\n",
    "                {\n",
    "                    'location':\n",
    "                    {\n",
    "                        'type': 'string',\n",
    "                        'description': 'The city and state, e.g., San Francisco, CA',\n",
    "                    },\n",
    "                    'unit':\n",
    "                    {\n",
    "                        'type': 'string',\n",
    "                        'enum': [ 'celsius', 'fahrenheit' ]\n",
    "                    }\n",
    "                },\n",
    "                'required': [ 'location' ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create( model='gpt-4o',\n",
    "\tmessages=[ { 'role': 'user', 'content': 'What is the weather like in Paris today?' } ],\n",
    "\ttools=tools )\n",
    "\n",
    "print( completion.choices[ 0 ].message.tool_calls )\n"
   ],
   "id": "765f26d1ce687f10"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Send Email",
   "id": "6a1ac27e37fac52d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign Variables\n",
    "tools = [\n",
    "\t{\n",
    "\t\t'type': 'function',\n",
    "\t\t'function':\n",
    "\t\t{\n",
    "\t\t\t'name': 'send_email',\n",
    "\t\t\t'description': 'Send an email to a given recipient with a subject and message.',\n",
    "\t\t\t'parameters':\n",
    "\t\t\t{\n",
    "\t\t\t\t'type': 'object',\n",
    "\t\t\t\t'properties':\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t'to':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t'type': 'string',\n",
    "\t\t\t\t\t\t'description': 'The recipient email address.'\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t'subject':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t'type': 'string',\n",
    "\t\t\t\t\t\t'description': 'Email subject line.'\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t'body':\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t'type': 'string',\n",
    "\t\t\t\t\t\t'description': 'Body of the email message.'\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t},\n",
    "\t\t\t\t'required': [ 'to', 'subject', 'body' ],\n",
    "\t\t\t\t'additionalProperties': False\n",
    "\t\t\t},\n",
    "\t\t\t'strict': True\n",
    "\t\t}\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Create Completion\n",
    "completion = client.chat.completions.create( model='gpt-4o',\n",
    "\tmessages=[ { 'role': 'user', 'content': 'Can you send an email to terryeppler@gmail.com saying hi?' } ],\n",
    "\ttools=_tools )\n",
    "\n",
    "print( completion.choices[ 0 ].message.tool_calls )"
   ],
   "id": "f7244dda1767837e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search Documents",
   "id": "523e0cf03638321b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign variables\n",
    "_tools = [\n",
    "{\n",
    "\t\t'type': 'function',\n",
    "\t\t'function':\n",
    "        {\n",
    "\t\t\t\t'name': 'search_knowledge_base',\n",
    "\t\t\t\t'description': 'Query a knowledge base to retrieve relevant info on a topic.',\n",
    "\t\t\t\t'parameters':\n",
    "                {\n",
    "\t\t\t\t\t\t'type': 'object',\n",
    "\t\t\t\t\t\t'properties':\n",
    "                        {\n",
    "\t\t\t\t\t\t\t\t'query':\n",
    "                                {\n",
    "                                    'type': 'string',\n",
    "                                    'description': 'The user question or search query.'\n",
    "                                },\n",
    "\t\t\t\t\t\t\t\t'options':\n",
    "                                {\n",
    "\t\t\t\t\t\t\t\t\t\t'type': 'object',\n",
    "\t\t\t\t\t\t\t\t\t\t'properties':\n",
    "                                        {\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'num_results':\n",
    "                                                {\n",
    "                                                    'type': 'number',\n",
    "                                                    'description': 'Number of top results to return.'\n",
    "                                                },\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'domain_filter':\n",
    "                                                {\n",
    "                                                    'type':\n",
    "                                                    [ 'string', 'null' ],\n",
    "                                                    'description': 'Optional domain to narrow the search. Pass null if not needed.'\n",
    "                                                },\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'sort_by':\n",
    "                                                {\n",
    "                                                    'type':\n",
    "                                                    [ 'string', 'null' ],\n",
    "                                                    'enum':\n",
    "                                                    [ 'relevance', 'date', 'popularity', 'alphabetical' ],\n",
    "                                                    'description': 'How to sort results. Pass null if not needed.'\n",
    "                                                }\n",
    "                                        },\n",
    "\t\t\t\t\t\t\t\t\t\t'required': [ 'num_results', 'domain_filter', 'sort_by' ],\n",
    "\t\t\t\t\t\t\t\t\t\t'additionalProperties': False\n",
    "                                }\n",
    "                        },\n",
    "\t\t\t\t\t\t'required': [ 'query', 'options' ],\n",
    "\t\t\t\t\t\t'additionalProperties': False\n",
    "                },\n",
    "\t\t\t\t'strict': True\n",
    "        }\n",
    "}\n",
    "]\n",
    "\n",
    "messages = \\\n",
    "[\n",
    "\t{\n",
    "\t\t'role': 'user',\n",
    "\t\t'content': 'Can you find information about ChatGPT in the AI knowledge base?'\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Create completion\n",
    "completion = client.chat.completions.create( model='gpt-4o', messages=_messages, tools=tools )\n",
    "\n",
    "print( completion.choices[ 0 ].message.tool_calls )"
   ],
   "id": "977000b1ed22ef92"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search Web Tool",
   "id": "de33e4e44a5bd66b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:48:48.465164Z",
     "start_time": "2025-04-10T14:48:44.411218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create Message\n",
    "_message = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': user_propmt,\n",
    "        } \n",
    "]\n",
    "\n",
    "# Create completion\n",
    "\n",
    "completion = client.chat.completions.create( model='gpt-4o-search-preview', web_search_options={},\n",
    "    messages=_message )\n",
    "\n",
    "print( completion.choices[ 0 ].message.content )"
   ],
   "id": "33ceccafde8c557d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of April 10, 2025, one notable positive news story is the successful demonstration of the world's smallest pacemaker by scientists at Northwestern University. This groundbreaking device measures just 3.5 millimeters in length, making it small enough to fit inside the tip of a syringe for non-invasive injection into the body. Designed for temporary use, the pacemaker can biodegrade within a predetermined number of days, tailored to a patient's specific needs. This innovation represents a significant advancement in medical technology, offering a less invasive and more adaptable solution for patients requiring temporary cardiac pacing. ([en.wikipedia.org](https://en.wikipedia.org/wiki/2025_in_science?utm_source=openai)) \n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### File Search Tool",
   "id": "dca98e676fedf65d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Step 1: Create a new Assistant with File Search Enabled\n",
    "assistant = client.beta.assistants.create(\n",
    "  name='Financial Analyst Assistant',\n",
    "  instructions='You are an expert financial analyst. Use you knowledge base to answer questions about audited financial statements.',\n",
    "  model='gpt-4o',\n",
    "  tools=[{'type': 'file_search'}],\n",
    ")\n",
    "\n",
    "# Step 2: Upload files and add them to a Vector Store\n",
    "vector_store = client.vector_stores.create( name='Financial Statements' )\n",
    "file_paths = [ 'edgar/goog-10k.pdf', 'edgar/brka-10k.txt' ]\n",
    "file_streams = [ open( path, 'rb' ) for path in file_paths ]\n",
    "file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "print( file_batch.status )\n",
    "print( file_batch.file_counts )\n",
    "\n",
    "# Step 3: Update the assistant to use the new Vector Store\n",
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={'file_search': {'vector_store_ids': [vector_store.id]}},\n",
    ")\n",
    "\n",
    "# Step 4: Create a thread\n",
    "message_file = client.files.create(\n",
    "  file=open('edgar/aapl-10k.pdf', 'rb'), purpose='assistants'\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': 'How many shares of AAPL were outstanding at the end of of October 2023?',\n",
    "      'attachments': [\n",
    "        { 'file_id': message_file.id, 'tools': [{'type': 'file_search'}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "print( thread.tool_resources.file_search )\n",
    "\n",
    "# Step 5: Create a run and check the cleaned_lines\n",
    "run = client.beta.threads.runs.create_and_poll( thread_id=thread.id,\n",
    "\tassistant_id=assistant.id )\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace( annotation.text, f'[{index}]' )\n",
    "    if file_citation := getattr( annotation, 'file_citation', None ):\n",
    "        cited_file = client.files.retrieve( file_citation.file_id )\n",
    "        citations.append( f'[{index}] {cited_file.filename}' )\n",
    "\n",
    "print( message_content.value )\n",
    "print('\\n'.join( citations ) )\n",
    "\n",
    "\n",
    "print( response )"
   ],
   "id": "b6b93701524b2804"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Use Browser",
   "id": "b4e58145c3fe0659"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign variables\n",
    "_args = [ '--disable-extensions', '--disable-file-system' ]\n",
    "\n",
    "with sync_playwright() as p:\n",
    "    browser = p.chromium.launch( headless=False, chromium_sandbox=True,\n",
    "        env={}, args=_args )\n",
    "    \n",
    "    page = browser.new_page( )\n",
    "    page.set_viewport_size( {'width': 1024, 'height': 768} )\n",
    "    page.goto( 'https://bing.com' )\n",
    "\n",
    "    page.wait_for_timeout( 10000 )"
   ],
   "id": "d631d1de28a48f55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Use Computer",
   "id": "6f002157c8565135"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign Variables\n",
    "_model = 'computer-use-preview'\n",
    "_reasoning = { 'generate_summary': 'concise', }\n",
    "_truncation = 'auto'\n",
    "_tools = [\n",
    "\t{\n",
    "        'type': 'computer_use_preview',\n",
    "        'display_width': 1024,\n",
    "        'display_height': 768,\n",
    "        'environment': 'browser' # other possible values: 'mac', 'windows', 'ubuntu'\n",
    "    }\n",
    "]\n",
    "\n",
    "_input = [\n",
    "\t{\n",
    "            'role': 'user',\n",
    "            'content': 'Check the latest OpenAI news on bing.com.'\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Create Response\n",
    "response = client.responses.create( model=_model, tools=_tools, input=_input,\n",
    "    reasoning=_reasoning, truncation='auto' )\n",
    "\n",
    "print( response.cleaned_lines )"
   ],
   "id": "1cfbca5363e7cd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Send Computer Use Request",
   "id": "7f93e2f19fe41874"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Send a request to create a Response with the **computer-use-preview** model equipped with the computer_use_preview tool.\n",
    "- This request should include details about your environment, along with an initial input prompt."
   ],
   "id": "d8aa79fb086aa0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign variables\n",
    "_model = 'computer-use-preview'\n",
    "_tools = [\n",
    "\t{\n",
    "        'type': 'computer_use_preview',\n",
    "        'display_width': 1024,\n",
    "        'display_height': 768,\n",
    "        'environment': 'browser' # other possible values: 'mac', 'windows', 'ubuntu'\n",
    "    }\n",
    "]\n",
    "\n",
    "_input = [\n",
    "\t{\n",
    "            'role': 'user',\n",
    "            'content': 'Check the latest OpenAI news on bing.com.'\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Create response\n",
    "response = client.responses.create( model=_model, tools=_tools, input=_input,\n",
    "    reasoning={ 'generate_summary': 'concise', }, truncation='auto' )\n",
    "\n",
    "print( response.cleaned_lines )"
   ],
   "id": "1669192c119728b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Execution Action",
   "id": "e04d112b001ed974"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Execute the corresponding actions on your computer or browser.\n",
    "- How you map a computer call to actions through code depends on your environment.\n",
    "- This code shows example implementations for the most common computer actions."
   ],
   "id": "c8a1a66fbcdc3ac9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def handle_model_action( page, action ):\n",
    "    '''\n",
    "    \n",
    "\t\tGiven a computer action (e.g., click, double_click, scroll, resources.),\n",
    "\t\texecute the corresponding operation on the Playwright page.\n",
    "\t\t\n",
    "    '''\n",
    "    action_type = action.type\n",
    "    try:\n",
    "        match action_type:\n",
    "            case 'click':\n",
    "                x, y = action.x, action.y\n",
    "                button = action.button\n",
    "                print( f\"Action: click at ({x}, {y}) with button '{button}' \" )\n",
    "                # Not handling things like middle click, resources.\n",
    "                if button != 'left' and button != 'right':\n",
    "                    button = 'left'\n",
    "                page.mouse.click( x, y, button=button )\n",
    "\n",
    "            case 'scroll':\n",
    "                x, y = action.x, action.y\n",
    "                scroll_x, scroll_y = action.scroll_x, action.scroll_y\n",
    "                print(f'Action: scroll at ({x}, {y}) with offsets (scroll_x={scroll_x}, scroll_y={scroll_y})')\n",
    "                page.mouse.move( x, y )\n",
    "                page.evaluate( f'window.scrollBy({scroll_x}, {scroll_y})' )\n",
    "\n",
    "            case 'keypress':\n",
    "                keys = action.keys\n",
    "                for k in keys:\n",
    "                    print( f\"Action: keypress '{k}' \" )\n",
    "                    # A simple mapping for common keys; expand as needed.\n",
    "                    if k.lower( ) == 'enter':\n",
    "                        page.keyboard.press( 'Enter' )\n",
    "                    elif k.lower( ) == 'space':\n",
    "                        page.keyboard.press( ' ' )\n",
    "                    else:\n",
    "                        page.keyboard.press( k )\n",
    "\n",
    "            case 'type':\n",
    "                text = action.text\n",
    "                print( f'Action: type documents: {text}' )\n",
    "                page.keyboard.type( text )\n",
    "\n",
    "            case 'wait':\n",
    "                print( f'Action: wait' )\n",
    "                time.sleep( 2 )\n",
    "\n",
    "            case 'screenshot':\n",
    "                # Nothing to do as screenshot is taken at each turn\n",
    "                print( f'Action: screenshot' )\n",
    "\n",
    "            # Handle other actions here\n",
    "\n",
    "            case _:\n",
    "                print( f'Unrecognized action: {action}' )\n",
    "\n",
    "    except Exception as e:\n",
    "        print( f'Error handling action {action}: {e}' )"
   ],
   "id": "ebe900fccd4c78c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Capture Screenshot",
   "id": "fe7ef876f73d6cca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- After executing the action, capture the updated state of the environment as a screenshot, which also differs depending on your environment.",
   "id": "6d03e32c9b40c799"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_screenshot( page ):\n",
    "    '''\n",
    "    \n",
    "    \tTake a full-page screenshot using Playwright and return the image bytes.\n",
    "    \t\n",
    "    '''\n",
    "    return page.screenshot()"
   ],
   "id": "33925edc5d07ae97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Repeating Loop",
   "id": "3517e91b75cfabb1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Once you have the screenshot, you can send it back to the model as a **computer_call_output** to get the next action.\n",
    "- Repeat these steps as long as you get a **computer_call** item in the response."
   ],
   "id": "c08830b946d8bad9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "def computer_use_loop( instance, response ):\n",
    "    '''\n",
    "    \tRun the loop that executes computer actions until no 'computer_call' is found.\n",
    "    '''\n",
    "    while True:\n",
    "        computer_calls = [ item for item in response.output if item.type == 'computer_call' ]\n",
    "        if not computer_calls:\n",
    "            print( 'No computer call found. Output from model:' )\n",
    "            for item in response.output:\n",
    "                print( item )\n",
    "            break  # Exit when no computer calls are issued.\n",
    "\n",
    "        # We expect at most one computer call per response.\n",
    "        computer_call = computer_calls[ 0 ]\n",
    "        last_call_id = computer_call.call_id\n",
    "        action = computer_call.action\n",
    "\n",
    "        # Execute the action (function defined in step 3)\n",
    "        handle_model_action( instance, action )\n",
    "        time.sleep( 1 )  # Allow time for changes to take effect.\n",
    "\n",
    "        # Take a screenshot after the action (function defined in step 4)\n",
    "        screenshot_bytes = get_screenshot( instance )\n",
    "        screenshot_base64 = base64.b64encode( screenshot_bytes ).decode( 'utf-8' )\n",
    "\n",
    "        # Send the screenshot back as a computer_call_output\n",
    "        response = client.responses.create(\n",
    "            model='computer-use-preview',\n",
    "            previous_response_id=response.id,\n",
    "            tools=[\n",
    "                {\n",
    "                    'type': 'computer_use_preview',\n",
    "                    'display_width': 1024,\n",
    "                    'display_height': 768,\n",
    "                    'environment': 'browser'\n",
    "                }\n",
    "            ],\n",
    "            input=[\n",
    "                {\n",
    "                    'call_id': last_call_id,\n",
    "                    'type': 'computer_call_output',\n",
    "                    'cleaned_lines': {\n",
    "                        'type': 'input_image',\n",
    "                        'image_url': f'values:image/png;base64,{screenshot_base64}'\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            truncation='auto'\n",
    "        )\n",
    "\n",
    "    return response"
   ],
   "id": "1da6090518887d73"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Files API\n",
    "- Upload up to 100 pages and 32MB of total content in a single request to the API, across multiple file inputs.\n",
    "- Only models that support both text and image inputs, such as gpt-4o, gpt-4o-mini, or o1, can accept PDF files as input\n",
    "- Recommend using the user_data purpose for files you plan to use as model inputs.\n",
    "___"
   ],
   "id": "9ca883a9e1a75ea5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Upload\n",
    "- Upload a PDF using the Files API, then reference its file ID in an API request to the model."
   ],
   "id": "f929960a9efe33d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Assign vriables\n",
    "_messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'type': 'file',\n",
    "                    'file':\n",
    "\t                {\n",
    "                        'file_id': file.id,\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'type': 'documents',\n",
    "                    'documents': 'What is the first dragon in the book?',\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "]\n",
    "\n",
    "# Create File Request\n",
    "file = client.files.create( file=open( 'draconomicon.pdf', 'rb' ), purpose='user_data' )\n",
    "completion = client.chat.completions.create( model='gpt-4o', messages=_messages, )\n",
    "\n",
    "print( completion.choices[ 0 ].message.content )"
   ],
   "id": "f67de4bc69a2a23d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List",
   "id": "aa4daee5f20bbed3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "_files = client.files.list()\n",
    "\n",
    "for i in _files:\n",
    "\tprint( i )\n"
   ],
   "id": "fce6a758df7ecead",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retreive File",
   "id": "119481b90b81b060"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Reteive by file_id\n",
    "client.files.retrieve( 'file-abc123' )\n"
   ],
   "id": "965e3286ecc2d79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Reteive Contents",
   "id": "f69abf06c4eafe11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "content = client.files.content( 'file-abc123' )\n"
   ],
   "id": "88925f2c09a44d16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Upload",
   "id": "d382cf0af90b2de4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.files.create( file=open('mydata.jsonl', 'rb'), purpose='fine-tune' )\n"
   ],
   "id": "9f67d49ba88d38ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Base64-encoded files\n",
    "- You can send PDF file inputs as Base64-encoded inputs as well."
   ],
   "id": "6e99da7e11a87f50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "with open( 'draconomicon.pdf', 'rb' ) as f:\n",
    "    data = f.read( )\n",
    "\n",
    "base64_string = base64.b64encode( data ).decode( 'utf-8' )\n",
    "completion = client.chat.completions.create( model='gpt-4o',\n",
    "    messages=\n",
    "    [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'type': 'file',\n",
    "                    'file':\n",
    "\t                {\n",
    "                        'filename': 'draconomicon.pdf',\n",
    "                        'file_data': f'values:application/pdf;base64,{ base64_string }',\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'type': 'text',\n",
    "                    'documents': 'What is the first dragon in the book?',\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print( completion.choices[ 0 ].message.content )"
   ],
   "id": "9dedf86a63db689f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Retreival API\n",
    "- The Retrieval API allows you to perform semantic search over your data, which is a technique that surfaces semantically similar results — even when they match few or no keywords.\n",
    "- The Retrieval API is powered by vector stores, which serve as indices for your data.\n",
    "___"
   ],
   "id": "a50edf1ae3361954"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Upload",
   "id": "31252b9607a71e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "vector_store = client.vector_stores.create( name='Support FAQ' )\n",
    "client.vector_stores.files.upload_and_poll(  vector_store_id=vector_store.id,\n",
    "    file=open( 'customer_policies.txt', 'rb' ) )"
   ],
   "id": "6c18fd89469c0f54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search Stores",
   "id": "2fec5e4852fc5c27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create search\n",
    "user_query = 'What is the return policy?'\n",
    "results = client.vector_stores.search( vector_store_id=vector_store.id, query=user_query, )"
   ],
   "id": "9aab2bf7205e3bb9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Semantic Search",
   "id": "89e5cbb85a08cdf6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "results = client.vector_stores.search( vector_store_id=vector_store.id,\n",
    "    query='How many woodchucks are allowed per passenger?', )"
   ],
   "id": "24d3b604818a4c4c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Vector Store API\n",
    "- Vector stores are the containers that power semantic search for the Retrieval API and the Assistants API file search tool.\n",
    "- When you add a file to a vector store it will be automatically chunked, embedded, and indexed.\n",
    "___"
   ],
   "id": "be2cc49a73407a4a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### I. Vector Store Operations",
   "id": "ca588f7dcdb197e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create",
   "id": "ab17f992fe0c8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create vector store\n",
    "client.vector_stores.create( name='Support FAQ', file_ids=[ 'file_123' ] )"
   ],
   "id": "d94e42c2ac8099f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retrieve",
   "id": "1b0c4fa721cd030"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Retreive vector store\n",
    "client.vector_stores.retrieve( vector_store_id='vs_123' )"
   ],
   "id": "9406837b98028fd1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Update",
   "id": "4edf82399108961f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Update vector store\n",
    "client.vector_stores.retrieve(  vector_store_id='vs_123' )"
   ],
   "id": "b749f3548bed8ac5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Delete",
   "id": "b7d769b3595f8e26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Delete vector store\n",
    "client.vector_stores.delete( vector_store_id='vs_123' )"
   ],
   "id": "8063dc3580e8020a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List",
   "id": "c2a44c35871c29c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List stores\n",
    "client.vector_stores.list( )"
   ],
   "id": "1bdeffc856f4ff0a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### II. Vector File Operations",
   "id": "3578fa99af2f88cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create",
   "id": "3c40ae41d1ae8467"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create files for vector store\n",
    "client.vector_stores.files.create( vector_store_id='vs_123',\n",
    "    file_id='file_123',\n",
    "    attributes=\n",
    "    {\n",
    "        'region': 'US',\n",
    "        'category': 'Marketing',\n",
    "        'date': 1672531200\n",
    "    }\n",
    ")"
   ],
   "id": "984ffe86987d9272"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Upload",
   "id": "56f14ab34778d2cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.files.upload_and_poll( vector_store_id='vs_123',\n",
    "    file=open('customer_policies.txt', 'rb') )\n"
   ],
   "id": "ed29df05e7a77f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retreive",
   "id": "1336958964d59639"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.files.retrieve( vector_store_id='vs_123', file_id='file_123' )\n"
   ],
   "id": "f6c802de56bc052f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Update",
   "id": "5e74af88e92efca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Update file\n",
    "client.vector_stores.files.update( vector_store_id='vs_123',\n",
    "    file_id='file_123',\n",
    "    attributes=\n",
    "    {\n",
    "\t    'key': 'value'\n",
    "    }\n",
    ")\n"
   ],
   "id": "f443a34c5826ccce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Delete",
   "id": "3492950c03e4fa97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Delete file\n",
    "client.vector_stores.files.delete( vector_store_id='vs_123', file_id='file_123' )\n"
   ],
   "id": "e0be6eee50dc28f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List",
   "id": "c8c69370ca89033e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List files\n",
    "client.vector_stores.files.list( vector_store_id='vs_123' )\n"
   ],
   "id": "be5f037d2876f58d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### II. Vector Batch Operations",
   "id": "483a13c1a68c6672"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create",
   "id": "46890148f4fd4492"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.file_batches.create_and_poll( vector_store_id='vs_123',\n",
    "    file_ids=[ 'file_123', 'file_456' ] )\n"
   ],
   "id": "31c7761d9c3cf90f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retrieve",
   "id": "dad42758272e6fa2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.file_batches.retrieve( vector_store_id='vs_123', batch_id='vsfb_123' )\n"
   ],
   "id": "2492bf72c3ce319f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cancel",
   "id": "141a54906fa93785"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.file_batches.cancel( vector_store_id='vs_123', batch_id='vsfb_123' )\n"
   ],
   "id": "1bc11b59e12ed29a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List",
   "id": "ac479dc7694ce178"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "client.vector_stores.file_batches.list( vector_store_id='vs_123' )\n"
   ],
   "id": "8894cf9d1c7299b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Assistant API\n",
    "- Designed to help developers build powerful AI assistants capable of performing a variety of tasks.\n",
    "- Build AI assistants within your own applications.\n",
    "##### Supports the following tools:\n",
    "1. Code Interpreter\n",
    "2. File Search\n",
    "3. Function calling.\n",
    "___"
   ],
   "id": "9df6bbfe74f1da68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Assistant",
   "id": "7789133558f7399"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions='You are a personal math tutor. When asked a question, write and run Python code to answer the question.',\n",
    "    name='Math Tutor',\n",
    "    tools=[{'type': 'code_interpreter'}],\n",
    "    model='gpt-4o',\n",
    ")\n",
    "print( my_assistant )\n"
   ],
   "id": "79e8b17900a8609f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List Assistants",
   "id": "82a4101059ca8d08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_assistants = client.beta.assistants.list( order='desc', limit='20' )\n",
    "\n",
    "print( my_assistants.data )\n"
   ],
   "id": "3369688ba307f2d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retreive Assistant",
   "id": "24c75f00b49c0fa5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_assistant = client.beta.assistants.retrieve('asst_abc123')\n",
    "print(my_assistant)\n"
   ],
   "id": "e270cdaaeedd8fc9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Update Assistant",
   "id": "69d2d0f1876ed9f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_updated_assistant = client.beta.assistants.update( 'asst_abc123',\n",
    "  instructions='You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.',\n",
    "  name='HR Helper',\n",
    "  tools=[{'type': 'file_search'}],\n",
    "  model='gpt-4o'\n",
    ")\n",
    "\n",
    "print( my_updated_assistant )\n"
   ],
   "id": "6a6a6aa07bfe1a45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Delete Assistant",
   "id": "2eedf073dcf80352"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "response = client.beta.assistants.delete('asst_abc123')\n",
    "print(response)\n"
   ],
   "id": "bec93c14671449b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### I. Threads",
   "id": "d3b53aefaed1b702"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create",
   "id": "decf426a6e9e82af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "empty_thread = client.beta.threads.create()\n",
    "print(empty_thread)\n"
   ],
   "id": "124407263bed255f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retreive",
   "id": "268461d8664a1afd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_thread = client.beta.threads.retrieve('thread_abc123')\n",
    "print(my_thread)\n"
   ],
   "id": "f1d01d205758758c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Update",
   "id": "db5a156c21b07875"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "my_updated_thread = client.beta.threads.update( 'thread_abc123',\n",
    "  metadata= { 'modified': 'true', 'user': 'abc123' } )\n",
    "\n",
    "print(my_updated_thread)\n"
   ],
   "id": "15d7587e415aeb1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Delete",
   "id": "f7574157ea64d69a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "response = client.beta.threads.delete( 'thread_abc123' )\n",
    "\n",
    "print(response)\n"
   ],
   "id": "2e76400ac172a239"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### II. Messages",
   "id": "d38f1c9b23d0a6f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create",
   "id": "53032868026c88dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Create message\n",
    "thread_message = client.beta.threads.messages.create( 'thread_abc123',  role='user',\n",
    "  content='How does AI work? Explain it in simple terms.', )\n",
    "\n",
    "print(thread_message)\n"
   ],
   "id": "81d79cd2c1706312"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### List",
   "id": "13656b055bff5d16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# List messages in a thread\n",
    "thread_messages = client.beta.threads.messages.list( 'thread_abc123' )\n",
    "print(thread_messages.data)\n"
   ],
   "id": "7f0520e6a197fb69"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retreive",
   "id": "bc76238baa324952"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Retreive messages from thread\n",
    "message = client.beta.threads.messages.retrieve( message_id='msg_abc123',\n",
    "\tthread_id='thread_abc123' )\n",
    "\n",
    "print( message )\n"
   ],
   "id": "52c0b73d716944e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Update",
   "id": "45611582952a3fb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Update messages in thread\n",
    "message = client.beta.threads.messages.update(\n",
    "  message_id='msg_abc12',\n",
    "  thread_id='thread_abc123',\n",
    "  metadata={\n",
    "    'modified': 'true',\n",
    "    'user': 'abc123',\n",
    "  },\n",
    "\n",
    ")\n",
    "print( message )\n"
   ],
   "id": "4b443485eec43e35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Delete",
   "id": "76e60dddc54098e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create client\n",
    "client = OpenAI( )\n",
    "client.api_key = os.getenv( 'OPENAI_API_KEY' )\n",
    "\n",
    "# Delete messages in thread\n",
    "deleted_message = client.beta.threads.messages.delete(  message_id='msg_abc12',\n",
    "\tthread_id='thread_abc123', )\n",
    "\n",
    "print(deleted_message)\n"
   ],
   "id": "87d4179d0a84fb4e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
