{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Load Dependencies",
   "id": "8819573d033ef6e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import os"
   ],
   "id": "b2f0a6bf941286b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Set API Key",
   "id": "973b45eed4562cfc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "apikey = os.getenv( 'GEMINI_API_KEY' )\n",
    "client = genai.Client( api_key=apikey )\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"Explain how AI works\",\n",
    ")\n",
    "\n",
    "print( response.text )"
   ],
   "id": "b2b527260eaff554"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Structured Output",
   "id": "1e482487f4ac07f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompt = \"\"\"List a few popular cookie recipes in JSON format.\n",
    "\n",
    "Use this JSON schema:\n",
    "\n",
    "Recipe = {'recipe_name': str, 'ingredients': list[str]}\n",
    "Return: list[Recipe]\"\"\"\n",
    "\n",
    "client = genai.Client(api_key=\"GEMINI_API_KEY\")\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents=prompt,\n",
    ")\n",
    "\n",
    "# Use the response as a JSON string.\n",
    "print(response.text)"
   ],
   "id": "5eee808360c022f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Content",
   "id": "3443af551503d408"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google import genai\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents='Tell me a story in 300 words.'\n",
    ")\n",
    "print(response.text)\n",
    "\n",
    "print(response.model_dump_json(\n",
    "    exclude_none=True, indent=4))"
   ],
   "id": "a4d31e1449e785a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Image",
   "id": "699ab74d5f6efafd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google import genai\n",
    "from PIL import Image\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents=[\n",
    "        'Tell me a story based on this image',\n",
    "        Image.open(image_path)\n",
    "    ]\n",
    ")\n",
    "print(response.text)"
   ],
   "id": "21ce0c81711c3aec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Stream",
   "id": "474692a978a5e522"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "for chunk in client.models.generate_content_stream(\n",
    "  model='gemini-2.0-flash',\n",
    "  contents='Tell me a story in 300 words.'\n",
    "):\n",
    "    print(chunk.text)"
   ],
   "id": "6c6751d3531fc618"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Chat",
   "id": "84aff2138e9cf692"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "chat = client.chats.create(model='gemini-2.0-flash')\n",
    "\n",
    "response = chat.send_message(\n",
    "    message='Tell me a story in 100 words')\n",
    "response = chat.send_message(\n",
    "    message='What happened after that?')"
   ],
   "id": "a46e07420b43734a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Function",
   "id": "97b33bfd699f258b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Get the current whether in a given location.\n",
    "\n",
    "    Args:\n",
    "        location: required, The city and state, e.g. San Franciso, CA\n",
    "        unit: celsius or fahrenheit\n",
    "    \"\"\"\n",
    "    print(f'Called with: {location=}')\n",
    "    return \"23C\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "   model='gemini-2.0-flash',\n",
    "   contents=\"What is the weather like in Boston?\",\n",
    "   config=types.GenerateContentConfig(\n",
    "       tools=[get_current_weather],\n",
    "       automatic_function_calling={'disable': True},\n",
    "   ),\n",
    ")\n",
    "\n",
    "function_call = response.candidates[0].content.parts[0].function_call"
   ],
   "id": "6a40dc9f83073feb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "client = genai.Client()\n",
    "\n",
    "def get_current_weather(city: str) -> str:\n",
    "    return \"23C\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "   model='gemini-2.0-flash',\n",
    "   contents=\"What is the weather like in Boston?\",\n",
    "   config=types.GenerateContentConfig(\n",
    "       tools=[get_current_weather]\n",
    "   ),\n",
    ")"
   ],
   "id": "7390655a657341fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Execute Code",
   "id": "4d5e7893dc8e814c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents='What is the sum of the first 50 prime numbers? Generate and run '\n",
    "             'code for the calculation, and make sure you get all 50.',\n",
    "    config=types.GenerateContentConfig(\n",
    "        tools=[types.Tool(code_execution=types.ToolCodeExecution)],\n",
    "    ),\n",
    ")"
   ],
   "id": "90404bb1b465e368"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Upload File",
   "id": "cb402e03812e9c2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import requests\n",
    "import pathlib\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "# Download file\n",
    "response = requests.get(\n",
    "    'https://storage.googleapis.com/generativeai-downloads/data/a11.txt')\n",
    "pathlib.Path('a11.txt').write_text(response.text)\n",
    "\n",
    "my_file = client.files.upload(file='a11.txt')\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents=[\n",
    "        'Can you summarize this file:',\n",
    "        my_file\n",
    "    ]\n",
    ")\n",
    "print(response.text)"
   ],
   "id": "594f9e9ff28a824"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### List Files",
   "id": "a15b8e91b3c048af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google import genai\n",
    "client = genai.Client()\n",
    "\n",
    "for file in client.files.list():\n",
    "    print(file.name)\n",
    "\n",
    "file = client.files.get(name=file.name)"
   ],
   "id": "deea4c887fdb34db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Delete File",
   "id": "63ea05e2cba636e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pathlib\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "pathlib.Path('dummy.txt').write_text(dummy)\n",
    "dummy_file = client.files.upload(file='dummy.txt')\n",
    "\n",
    "response = client.files.delete(name=dummy_file.name)"
   ],
   "id": "5cb2bab4f86facca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Cache Context",
   "id": "cbbc4f13b335121f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import requests\n",
    "import pathlib\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "# Check which models support caching.\n",
    "for m in client.models.list():\n",
    "  for action in m.supported_actions:\n",
    "    if action == \"createCachedContent\":\n",
    "      print(m.name)\n",
    "      break\n",
    "\n",
    "# Download file\n",
    "response = requests.get(\n",
    "    'https://storage.googleapis.com/generativeai-downloads/data/a11.txt')\n",
    "pathlib.Path('a11.txt').write_text(response.text)\n",
    "\n",
    "\n",
    "# Upload file\n",
    "document = client.files.upload(file='a11.txt')\n",
    "\n",
    "# Create cache\n",
    "model='gemini-1.5-flash-001'\n",
    "apollo_cache = client.caches.create(\n",
    "      model=model,\n",
    "      config={\n",
    "          'contents': [document],\n",
    "          'system_instruction': 'You are an expert at analyzing transcripts.',\n",
    "      },\n",
    "  )\n",
    "\n",
    "# Generate response\n",
    "response = client.models.generate_content(\n",
    "    model=model,\n",
    "    contents='Find a lighthearted moment from this transcript',\n",
    "    config=types.GenerateContentConfig(\n",
    "        cached_content=apollo_cache.name,\n",
    "    )\n",
    ")"
   ],
   "id": "3054ca33bd960ec4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
