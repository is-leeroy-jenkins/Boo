import os
from langchain.chat_models import ChatOpenAI
from langchain.sql_database import SQLDatabase
from langchain.agents import initialize_agent, Tool
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.agents.agent_types import AgentType
from langchain.chains import RetrievalQA
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import TextLoader, PyPDFLoader, CSVLoader, UnstructuredHTMLLoader
from langchain.memory import ConversationBufferMemory
from typing import List
from Booger import Error, ErrorDialog


class Fetch:
	
	def __init__( self, db_uri: str, doc_paths: List[ str ], model: str = 'gpt-4o',
	              temperature: float = 0.2 ):
		'''
		Initializes the Fetch system.
		:param db_uri: URI for the SQLite database
		:param doc_paths: List of file paths to documents (txt, pdf, csv, html)
		:param model: OpenAI model to use (default: gpt-4)
		:param temperature: LLM temperature setting for creativity
		'''
		self.llm = ChatOpenAI( model=model, temperature=temperature, streaming=True )
		self.db_uri = db_uri
		self.doc_paths = doc_paths
		
		# Setup memory to retain conversational context
		self.memory = ConversationBufferMemory( memory_key='chat_history', return_messages=True )
		
		# Initialize tools for SQL, Document QA, and optional APIs
		self.sql_tool = self._init_sql_tool( )
		self.doc_tool = self._init_doc_tool( )
		self.api_tools = self._init_api_tools( )
		
		# Combine all tools into a unified agent
		self.agent = initialize_agent(
			tools=[ self.sql_tool, self.doc_tool ] + self.api_tools,
			llm=self.llm,
			memory=self.memory,
			agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,
			verbose=True
		)
	
	
	def _init_sql_tool( self ) -> Tool:
		'''
		Sets up SQL querying tool using LangChain's SQLDatabaseToolkit.
		:return: Tool configured for SQL querying
		'''
		try:
			db = SQLDatabase.from_uri( self.db_uri )
			toolkit = SQLDatabaseToolkit( db=db, llm=self.llm )
			base_tool = toolkit.get_tools( )[ 0 ]
			return Tool(
				name='SQLDatabase',
				func=base_tool.func,
				description='Use this to query structured data like employee records, or payroll'
			)
		except Exception as e:
			_exc = Error( e )
			_exc.module = 'Chaingle'
			_exc.cause = 'Fetch'
			_exc.method = '_init_sql_tool( self ) -> Tool'
			_err = ErrorDialog( _exc )
			_err.show( )
	
	
	def _load_documents( self ):
		'''
		Detects and loads supported documents (TXT, PDF, CSV, HTML) from paths.
		:return: List of loaded documents
		'''
		try:
			all_docs = [ ]
			for path in self.doc_paths:
				ext = os.path.splitext( path )[ -1 ].lower( )
				if ext == '.pdf':
					loader = PyPDFLoader( path )
				elif ext == '.csv':
					loader = CSVLoader( path )
				elif ext in [ '.html', '.htm' ]:
					loader = UnstructuredHTMLLoader( path )
				else:
					loader = TextLoader( path )
				docs = loader.load( )
				all_docs.extend( docs )
			return all_docs
		except Exception as e:
			_exc = Error( e )
			_exc.module = 'Chaingle'
			_exc.cause = 'Fetch'
			_exc.method = '_load_documents( self )'
			_err = ErrorDialog( _exc )
			_err.show( )
	
	
	def _init_doc_tool( self ) -> Tool:
		'''
		Creates document retrieval tool using FAISS + OpenAI Embeddings.
		:return: Tool configured for document-based Q&A
		'''
		try:
			raw_docs = self._load_documents( )
			chunks = (RecursiveCharacterTextSplitter( chunk_size=500, chunk_overlap=50 )
			          .split_documents( raw_docs ) )
			embeddings = OpenAIEmbeddings( )
			vectordb = FAISS.from_documents( chunks, embeddings )
			retriever = vectordb.as_retriever( )
			qa_chain = RetrievalQA.from_chain_type( llm=self.llm, retriever=retriever )
			name = 'DocumentQA'
			func = qa_chain.run
			description = 'Use this to answer questions from uploaded documents'
			return Tool( name, func, description )
		except Exception as e:
			_exc = Error( e )
			_exc.module = 'Chaingle'
			_exc.cause = 'Fetch'
			_exc.method = '_init_doc_tool( self ) -> Tool:'
			_err = ErrorDialog( _exc )
			_err.show( )
	
	
	def _init_api_tools( self ) -> List[ Tool ]:
		'''
		Placeholder for future external API-based tools like SerpAPI, weather, or finance.
		:return: List of external tool integrations (currently empty)
		'''
		try:
			return [ ]
		except Exception as e:
			_exc = Error( e )
			_exc.module = 'Chaingle'
			_exc.cause = 'Fetch'
			_exc.method = '_init_api_tools( self ) -> List[ Tool ]'
			_err = ErrorDialog( _exc )
			_err.show( )
	
	
	def query( self, question: str ) -> str:
		'''
		Passes a natural language question to the LangChain agent.
		:param question: User query
		:return: Answer generated by the appropriate tool
		'''
		try:
			if question is None:
				_msg = "The object 'question' does not exist or is None!"
				raise Exception( _msg )
			else:
				return self.agent.run( question )
		except Exception as e:
			_exc = Error( e )
			_exc.module = 'Chaingle'
			_exc.cause = 'Fetch'
			_exc.method = 'query( self, question: str ) -> str'
			_err = ErrorDialog( _exc )
			_err.show( )
	
	
	def chat_history( self ) -> List[ str ]:
		'''
		Returns formatted conversation history.
		:return: List of strings showing previous user and AI messages
		'''
		return [ f'{msg.type.upper( )}: {msg.content}' for msg in
		         self.memory.chat_memory.messages ]
